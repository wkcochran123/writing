\chapter{Informational Strain}
\label{chap:strain}


At the end of the previous chapter, we identified \emph{informational stress}
as the bookkeeping rule that maintains the invariance of the informational
interval under maximal propagation.  Stress describes how distinguishability
is transported without contradiction.  Informational strain is the natural
complement of this idea.  It measures the failure of that transport to close.

Strain arises when locally admissible refinements cannot be assembled into a
globally coherent history without additional adjustment.  In the discrete
domain, this adjustment is the residue of non-closure.  In the smooth shadow,
it appears as curvature.  Informational strain is therefore the measure of
non-integrability of refinement: the discrepancy recorded when a closed cycle
of informational updates fails to return to its initial state.

\section{Historical Review: Curvature as Non--Closure}

Classically, curvature has always been understood as non-closure.  Gauss 
demonstrated that curvature can be detected intrinsically, without reference
to an embedding~\cite{gauss1828}.  Riemann characterized curvature as the commutator of two
infinitesimal transports~\cite{riemann1854}.  Einstein showed that curvature arises wherever a
tensorial quantity must be conserved consistently across overlapping regions~\cite{einstein1915}.

In each case, curvature is the minimal correction needed when parallel
transport around a loop does not return the original value.  Informational
strain is the discrete analogue of this principle.  It measures the mismatch
generated by transporting informational refinements around a closed cycle.
In the smooth shadow, this mismatch becomes curvature of the informational
gauge.

\begin{definition}[Cross Product~\cite{heaviside1893}]\label{def:realcross}
Let $u,v \in \mathbb{R}^3$ be vectors in Euclidean space.  The \emph{cross
product} $u \times v$ is the unique vector in $\mathbb{R}^3$ satisfying
\[
u \times v \;\perp\; u,\qquad
u \times v \;\perp\; v,
\]
with magnitude
\[
\|u \times v\| = \|u\|\,\|v\|\,\sin\theta,
\]
where $\theta$ is the angle between $u$ and $v$, and oriented so that
$\{u,v,u \times v\}$ forms a right--handed triple.

In coordinates,
\[
u \times v =
\begin{pmatrix}
u_2 v_3 - u_3 v_2 \\
u_3 v_1 - u_1 v_3 \\
u_1 v_2 - u_2 v_1
\end{pmatrix}.
\]

\end{definition}

\section{Galerkin Projection and Rotational Residue}
\label{sec:galerkin}

The Galerkin method arises in this framework not as a numerical convenience,
but as a structural necessity.  Refinement updates act on the informational
record as finite operators.  When these updates are examined in the dense
limit, they admit a decomposition into components that either preserve
alignment with admissible test functions or deviate from it.

Let $\{\phi_i\}$ denote a finite admissible test basis associated with a
refinement scale.  The Galerkin projection $\Pi_G$ of an update operator $R$
is defined by the bilinear pairing
\[
\langle \phi_i, \Pi_G R \, \phi_j \rangle
= \langle \phi_i, R \, \phi_j \rangle,
\]
for all admissible test functions.  By construction, this pairing is
\emph{symmetric}: it records only the component of $R$ that aligns with the
test space.  Any antisymmetric contribution is annihilated by the projection.

This is not a defect of the method, but its defining feature.  Galerkin
schemes measure only what can be stabilized by symmetric bilinear forms.
They are blind to rotational discrepancy because such discrepancy does not
alter energy--like functionals.  The kernel of $\Pi_G$ therefore contains all
antisymmetric residues of refinement.

The informational cross product formalizes precisely this residue.  Given
two admissible refinement updates $R_a$ and $R_b$, their antisymmetric
difference,
\[
R_a R_b - R_b R_a,
\]
records the part of their interaction that twists rather than stretches the
informational record.  This antisymmetric object lies entirely in the kernel
of the Galerkin projection and cannot be detected by any symmetric test
space.

The Galerkin norm may therefore be generalized as a restriction of the full
informational norm:
\[
\| R \|_G = \| \tfrac{1}{2}(R + R^{\ast}) \|,
\]
where only the symmetric component contributes.  The complementary part,
\[
\tfrac{1}{2}(R - R^{\ast}),
\]
remains unmeasured by Galerkin methods.

This unmeasured component is not arbitrary.  It is structured and necessary:
it is the directional residue that prevents the refinement algebra from
closing under symmetric detection.  The Galerkin cross product is defined as
this missing component — the discrete analogue of curl.

In this sense, the Galerkin projection supplies elasticity without rotation,
while the informational cross product supplies rotation without elasticity.
Together they complete the refinement algebra.  The cross product therefore
identifies the direction that Galerkin methods must omit and supplies the
missing basis vector required for closure of the discrete refinement cycle.

In the smooth shadow, this discrete residue becomes the classical curl
operator.  What appears in continuum physics as local rotation is, in the
informational framework, nothing more than the part of refinement that lies
in the kernel of every symmetric projection.


\begin{definition}[Galerkin Cross Product]\label{def:galerkin-cross}
Let $V$ be a finite-dimensional trial space and let $W \subseteq V$ be a
Galerkin test space.  Let $B(\cdot,\cdot)$ denote the bilinear form
representing the symmetric part of the refinement update in the smooth 
shadow.  The \emph{Galerkin cross product} is the unique vector 
$u \times_G v \in V$ satisfying
\[
B(u \times_G v,\, w) = 0 \qquad \text{for all } w \in W,
\]
and
\[
u \times_G v \;\notin\; W.
\]

\NB{The Galerkin cross product spans the component of the update that lies in
the kernel of the symmetric bilinear form.  This component cannot be captured 
by the Galerkin projection and represents the antisymmetric part of the 
refinement operator.}

Concretely, if the update operator $\Psi$ on refinements admits a decomposition
\[
\Psi(e)\Psi(f) = S + A,
\]
where $S$ is symmetric with respect to $B(\cdot,\cdot)$ and $A$ is 
antisymmetric, then
\[
u \times_G v
\]
is the unique vector in the range of $A$ orthogonal (in the Galerkin sense) to
all test functions.  In the dense limit, $u \times_G v$ converges to the 
classical cross product in $\mathbb{R}^3$ and the antisymmetric part $A$ 
reduces to the curl operator of the associated vector field.
\end{definition}

\begin{proposition}[Recovery of the Classical Cross Product]
\label{prop:recover-cross-product}
\NB{This result uses only Proposition~\ref{prop:antisymmetry} 
(anti--symmetry of information propagation), 
Proposition~\ref{prop:commute-uncorrelant} (commutativity of uncorrelant 
events), and the Reciprocity Dual of Proposition~\ref{prop:reciprocity}.  
No geometric assumptions are made.}

Let $\mathsf{X} : V \times V \to V$ denote the generalized antisymmetric
bilinear operator induced by the Informational Interaction Operator of
Definition~\ref{def:interaction}.  Let $W \subset V$ be any three--dimensional
informational subspace that is stable under Martin--Kolmogorov refinement
(Definition~\ref{def:martin}).  Then the restriction
\[
\mathsf{X}|_{W\times W} : W \times W \to W
\]
is uniquely isomorphic to the classical cross product on $\mathbb{R}^3$.
Explicitly, for any basis $\{\mathbf{e}_1,\mathbf{e}_2,\mathbf{e}_3\}$ of $W$
compatible with the reciprocity map,
\[
u \,\mathsf{X}\, v \;=\;
\begin{vmatrix}
\mathbf{e}_1 & \mathbf{e}_2 & \mathbf{e}_3 \\
u_1 & u_2 & u_3 \\
v_1 & v_2 & v_3
\end{vmatrix},
\]
where $u = u_i \mathbf{e}_i$ and $v = v_i \mathbf{e}_i$.

\paragraph{Interpretation.}
The familiar $u \times v$ is not assumed.  It is the unique refinement--stable
Galerkin limit of the informational antisymmetry when restricted to any
three--frame permitted by the axioms of measurement.
\end{proposition}

\begin{proofsketch}{recover-cross-product}
On the three--dimensional informational subspace $W \subset V$, the
informational metric $g$ of Chapter~5 provides a positive--definite bilinear
form and hence an identification of $W$ with $\mathbb{R}^3$ up to isometry.
The antisymmetric operator $\mathsf{X}$ is bilinear and satisfies
\[
\mathsf{X}(u,v) = -\mathsf{X}(v,u)
\]
by Proposition~\ref{prop:antisymmetry}.  The Reciprocity Dual
(Proposition~\ref{prop:reciprocity}) and Definition~\ref{def:interaction}
ensure that $\mathsf{X}$ is compatible with refinement: if $u$ and $v$ are
refinement directions, then $\mathsf{X}(u,v)$ is again a refinement direction
in $W$.

On a three--dimensional inner product space $(W,g)$, any antisymmetric
bilinear map
\[
\mathsf{X} : W \times W \to W
\]
is determined uniquely (up to a fixed scalar and orientation) by the
requirement that $g(\mathsf{X}(u,v),w)$ define a volume form.  Informational
minimality fixes the normalization and orientation: adding any extra scale
or reversing orientation would introduce unobserved structure, contradicting
the Axiom of Boltzmann and the countable refinement structure.

Thus there exists a basis
$\{\mathbf{e}_1,\mathbf{e}_2,\mathbf{e}_3\}$ of $W$ compatible with the
reciprocity map such that, in these coordinates, $\mathsf{X}$ has exactly the
coordinate expression of the classical cross product on $\mathbb{R}^3$.  This
yields the determinant formula in the statement and completes the
identification.
\end{proofsketch}


\section{Communication~\cite{shannon1948}}
Before any notion of force, field, or medium, there is a simpler problem:
What portion of a refinement can survive being written down, carried across a
distance, and reconstructed elsewhere?

Every physical theory assumes that something can be transmitted.  Light,
sound, voltage, or particles are taken to be the carriers, and attention is
focused on their propagation.  In the present framework, the carrier is
irrelevant.  What matters is that only a restricted part of any refinement
sequence can be stabilized as a record.

Two observers do not share the full informational act of refinement.  They
share only what can be projected into a common admissible basis.  The act of
projection destroys structure: it removes precisely those components that do
not align symmetrically with the shared test space.  The remainder is not an
approximation of the original update; it is a different object altogether.
It is the message.

This distinction precedes physics.  It is not a consequence of bandwidth,
noise, attenuation, or engineering limitations.  It follows from the axioms:
only symmetric, Galerkin-detectable structure can appear in any stable
record.  Anything else exists only as internal strain.

The earliest large-scale demonstration of this principle appears in wireless
telegraphy.  In Marconi's transmissions, the physical carrier was
electromagnetic, but the deeper phenomenon was informational: what survived
across the Atlantic was not a waveform, but a projection.  The receiver did
not reconstruct the sender's refinement.  It recovered only the part that
could be stabilized in its own admissible basis.

The following phenomenon isolates that principle in its pure form.
It does not depend on radio technology, nor even on electromagnetism.  It
depends only on the fact that refinement must be made communicable by
projection before it can become a message.


\begin{phenomenon}[The Message Effect\cite{ciarlet1978,marconi1901,strang1973}]
Consider two laboratories, $A$ and $B$, separated by a large distance.  At
$A$, a discrete refinement sequence is encoded as a modulation of an
electromagnetic carrier.  At $B$, a detector records only those components of
this modulation that admit stable representation in a fixed decoding basis.

The transmitter at $A$ is free to introduce arbitrary refinements into the
signal: phase shifts, amplitude variations, and timing distortions.  The
receiver at $B$, however, can only register the symmetric components of that
refinement relative to its local basis.  Any antisymmetric structure in the
transmission lies in the kernel of the decoding projection and is therefore
unrecordable.

As the transmission distance is increased, attenuation and noise grow, but the
core phenomenon persists independently of physical degradation: only the
Galerkin-detectable component of the refinement survives as message.  What is
received is not the full act of refinement performed at $A$, but its
projected shadow.

The experiment demonstrates the Message Effect: a message is not what is
sent, but what can be stably projected into a shared admissible basis.  No
receiver ever recovers the full refinement of the sender.  The unobserved
residue — the informational cross component — remains real, but necessarily
unsayable.

Viewed this way, communication between observers can be modeled as a Galerkin projection
onto a shared test space.  Each observer records local refinement updates of
the informational record, but agreement is possible only on those components
that admit a common representation in the chosen basis.  The bilinear forms
that define the Galerkin method respond solely to the symmetric component
of an update: they measure alignment with the test space and ignore any
antisymmetric twist.

The informational cross product records exactly this antisymmetric residue of
two refinement updates -- the part that twists rather than stretches the record.
From the Galerkin point of view, this residue lies in the kernel of the
projection and is therefore invisible to every symmetric measurement.  This
is not a numerical defect but a structural feature: symmetric forms cannot
measure rotation.  What cannot be seen in the Galerkin norm cannot be
communicated through that channel.

In this framework, curl is not a primitive geometric object.  It is the
abstraction of refinement itself: the formal recognition that a countable
increment may be inserted into a closed refinement cycle without violating
the admissibility of the record.

A Galerkin projection enforces communicability.  Only symmetric components
of an update admit stable representation in a shared basis, and therefore
only these components can be exchanged between observers or preserved under
global bookkeeping.  What survives communication is not the full update, but
its compressible shadow.

The informational cross product isolates what is lost under this
compression.  It is not a force, torque, or dynamical quantity.  It is the
certificate that two admissible refinement steps do not close when composed.
The failure of closure is not an error: it is the necessary room in which a
new distinguishable increment can be inserted.

This is the role of curl in the smooth shadow.

Curl is the formal statement that a closed loop of refinement admits a
countable defect:
\[
\oint R \cdot d\ell \;\neq\; 0.
\]
This defect is not continuous in origin.  It is the shadow of a discrete
fact: the informational record permits the insertion of an additional
irreducible refinement without contradiction.  Curl therefore measures
\emph{how many new distinctions} may be consistently added, not how space
physically twists.

In this sense, curl is the abstraction of freedom.  Where divergence counts
how much structure must be conserved, curl counts how much structure may be
created.  It measures the remaining capacity of a refinement cycle to accept
new distinguishable events.

The Galerkin cross product is the discrete prototype of this phenomenon.  It
does not compute a vector; it marks a direction in which refinement has not
yet been accounted for by any symmetric communicable form.  That direction
is the basis element that must be adjoined to make the refinement algebra
closed under composition.

Thus, communication produces a privileged symmetric subspace, while curl is
the algebraic witness that this subspace is incomplete.  Curl is not motion.
It is admissible novelty: the permission, granted by the axioms, to insert
one more countable distinction.

In the smooth limit, this permission appears as rotational structure in a
field.  In the discrete theory, it is nothing more---and nothing less---than the
fact that refinement is not exhausted by what can be communicated.
\end{phenomenon}

At this point, the structure is no longer exotic.  It is familiar enough to
be unsettling.  Nothing new has been assumed, no foreign machinery
introduced, and no hidden dynamics smuggled in.  The construction has relied
only on refinement, projection, and admissibility.

However, once things that cannot be projected are treated as real but unsayable, the
shape of the argument becomes difficult to unsee---another phenomenon that requires
explanation.  It is at this point, we can understand how limited measurements truly are because
now we are back where we started.  There is a single variable left unspecified for an event
until the event occurs.  At that point, the spline provides just enough free degrees of freedom
to make the problem well posed.

\NB{CAVEAT EMPTOR: Once things that cannot be projected are treated as real
but unsayable, the shape of the argument becomes difficult to unsee.  The
recursion can no longer be ignored, and must now be unwound. 
See Phenomenon~{ph:library-catalog}.}

\section{The Time Effect}
\label{sec:time}

Time does not enter this construction as a background parameter.  It is not a
coordinate laid upon events, nor a dimension through which objects move.
Time appears only when refinement becomes possible.

At any stage of the informational record, there exists a single free
parameter associated with the next admissible event.  Prior to occurrence,
this parameter is not speakable.  It cannot be projected, communicated, or
represented in any admissible basis.  It exists only as an open degree of
freedom in the spline completion problem.

The perceived flow of time is nothing more than the computation of the free
parameter of Propositon~\ref{prop:free-parameter}.

When the parameter is resolved, the spline closure problem becomes well
posed.  The minimal structure condition selects a unique admissible
completion, and the refinement record advances by one step.  What was
unsayable becomes fixed.  What was open becomes recorded.

This process repeats until after the computation of $\U_n$, $n \leq |{e\in\U_n}|$.
At that point, all events have been sorted. No further refinement is possible.

\begin{phenomenon}[The Time Effect~\cite{einstein1915,newton1687}]
\NB{While Newton and Einstein assume time as a primitive, both acknowledge
the difficulty of defining change without presupposing it.}

Time is not observed as a primitive background quantity but emerges as the
moment at which an informational spline becomes well posed.  Prior to any
event, the refinement record contains a single unsatisfied degree of freedom:
a free parameter that cannot be projected, communicated, or represented.

When this parameter is resolved, the admissible spline closes.  The
minimization of informational structure selects a unique completion of the
record, and a new event enters the causal history.  This act of closure is
experienced as the passage of time.

Thus, time is not motion and not duration.  It is the count of successful
resolutions of the free spline condition.  Each unit of time corresponds to
the elimination of one unspeakable degree of freedom and the stabilization of
one new admissible event.

The phenomenon of time is therefore the observable shadow of computation:
the discrete act of transforming an open refinement into a closed record.
What appears as temporal flow is nothing more than the repeated completion of
an otherwise underdetermined spline.
\end{phenomenon}

\section{Informational Viscosity~\cite{newton1687}}

\begin{phenomenon}[The Navier--Stokes effect~\cite{navier1822,stokes1845}]

\NB{This is an informational phenomenon.  No physical fluid or continuum is
assumed.  The classical Navier--Stokes equations are quoted only as the smooth
shadow of discrete refinement transport.  The phenomenon illustrates that the
appearance of viscous terms is nothing more than the accumulation of
informational strain under non-closing updates.}

Classical fluid dynamics records the transport of a state variable through
space and time.  The Navier--Stokes equation,
\[
\partial_t u + (u \cdot \nabla)u = -\nabla p + \nu\,\Delta u,
\]
is traditionally interpreted as the momentum balance of a viscous medium.

Informationally, this equation expresses something more fundamental:
\emph{closure requires correction}.  The convective term
\(
(u \cdot \nabla)u
\)
represents the pure transport of distinguishability under the refinement map.
If refinement closed globally, this transport would suffice.  Yet classical
convective transport fails to be integrable; small loops do not return the
same state.  The discrepancy accumulates as informational strain.

The viscous term
\(
\nu\,\Delta u
\)
is precisely the correction required to force closure.  It is the smooth
shadow of the strain operator $\Sigma$: the minimal adjustment needed to
reconcile locally transported information with a globally coherent record.
Viscosity is therefore an informational phenomenon.  It is the continuous
representation of the curvature induced by non-closure of refinement.

In this interpretation, Navier--Stokes is not a physical law but the canonical
example of how strain appears when local informational updates fail to agree.
Its form is dictated entirely by the requirement that refinement remain
coherent across overlapping regions.  The equation emerges as the unique
smooth expression of balancing informational strain.
\end{phenomenon}

\section{Non-linear Informational Strain}
\begin{phenomenon}[The Strong Interaction Effect]
\label{ph:strong-force}

\textbf{Statement.}
There exist refinement regimes in which informational strain is intrinsically
nonlinear.  In such regimes, strain does not disperse; it self--confines.

\textbf{Mechanism.}
In ordinary transport, the informational strain $\Sigma$ produced by a
refinement update disperses through the ledger and admits a linear smoothing
shadow.  However, for sufficiently dense configurations of causal threads,
the strain functional becomes nonlinear.

Let $q_i$ denote tightly coupled refinement threads.  Define the strain
density
\[
\Sigma = \Sigma(q_i, q_j).
\]
In the strong regime,
\[
\Sigma(q_i, q_j) \neq \Sigma(q_i) + \Sigma(q_j),
\]
and the superposition principle fails.

As separation increases, the cost of maintaining consistency grows rather than
decays.  The ledger assigns increasing informational cost to isolated
threads, producing a restoring force that prevents independent propagation.

\textbf{Interpretation.}
The strong force is not modeled as exchange of particles, but as a property of
nonlinear bookkeeping.  Attempts to separate correlated threads generate
additional strain rather than relief.  The ledger enforces confinement by
making isolation informationally inadmissible.

\textbf{Conclusion.}
Quark confinement is the smooth shadow of a ledger whose strain function is
nonlinear.  At short scales, symmetry permits limited motion; at large scales,
the informational cost diverges.  The strong interaction is therefore the
law of self--binding strain.
\end{phenomenon}


\section{The Residue of Inconsistency}

Let $e_i$ denote a distinguishable event and $\hat{R}(e_i)$ the restriction
operator determining admissible continuations.  Under the continuous update
map $\Psi$, successive refinements satisfy
\[
U_{i+1} = \Psi(e_{i+1} \cap \hat{R}(e_i))\, U_i .
\]

If a sequence of events returns to the same informational state after $k$
steps, global coherence requires that the net update be the identity in the
informational gauge:
\[
\Psi(e_{i+k} \cap \hat{R}(e_{i+k-1})) \cdots 
\Psi(e_{i+1} \cap \hat{R}(e_i)) = I.
\]

When this closure fails, the discrepancy is the \emph{informational strain}.
Define the strain operator
\[
\Sigma = 
\Psi(e_{i+k} \cap \hat{R}(e_{i+k-1})) \cdots 
\Psi(e_{i+1} \cap \hat{R}(e_i)) - I .
\]

The operator $\Sigma$ measures the failure of closure of informational
transport.  In the dense limit, its leading term becomes the curvature of the
informational gauge.  Thus, curvature is the smooth representation of 
discrete informational strain.

\begin{definition}[Informational Cross Product~\cite{jacobi1845}]\label{def:cross}
Let $e$ and $f$ be admissible refinements of an informational state $U$, and
let $\Psi$ be the continuous update operator
\[
U' = \Psi(e)\,U .
\]
The \emph{informational cross product} of $e$ and $f$ is the event--update
operator that measures the failure of the corresponding refinement actions to
commute.  It is defined by
\[
e \times f :=
\Psi(e)\,\Psi(f) - \Psi(f)\,\Psi(e) .
\]

\NB{This operator records the non--closure of refinement.  If $e$ and $f$
commute informationally, the cross product vanishes.  A nonzero result
represents the minimal corrective update that must be applied to preserve
coherence of the record.}

In the smooth shadow, $e \times f$ reduces to the classical curl of the
associated flow field, and the informational strain generated by a closed loop
of refinements is given by the accumulated cross product of the updates.
\end{definition}

\begin{proposition}[Informational Cross Product as Minimal Discretization]
\label{prop:informational-minimal-discretization}
\NB{This proposition uses the definitions introduced in
Definitions~\ref{def:real-cross-product},
\ref{def:galerkin-cross-product}, and
\ref{def:informational-cross-product}.  
The only assumptions are informational minimality and the Axiom of
Boltzmann, which forbids the introduction of unobserved structure.}

Let $\mathsf{X}$ be the generalized cross product of
Proposition~\ref{prop:recover-cross-product}, and let
$\mathsf{X}_G$ denote the Galerkin cross product obtained by weak--form
extremality in the sense of Chapter~3.  Let $\mathsf{X}_I$ denote the
Informational Cross Product of Definition~\ref{def:informational-cross-product}.

Then:
\begin{enumerate}
\item $\mathsf{X}_G$ is the unique smooth shadow admitted by spline--level
closure and informational reciprocity.
\item $\mathsf{X}_I$ is the unique information--minimal discretization of
$\mathsf{X}_G$ that introduces no additional admissible events under
refinement.
\item Consequently,
\[
\mathsf{X}_I \;=\; \operatorname{Disc}_{\epsilon}(\mathsf{X}_G),
\]
the $\epsilon$--refinement discretization of the Galerkin operator.
\end{enumerate}

\paragraph{Interpretation.}
No additional curvature, torsion, or unobserved structure may be introduced
without violating informational minimality.  Thus $\mathsf{X}_I$ is the
coarsest admissible refinement of the generalized antisymmetry.
\end{proposition}

\begin{proofsketch}{informational-minimal-discretization}
By construction, the Galerkin cross product $\mathsf{X}_G$ is obtained as the
weak--form limit of the refinement commutator in the dense sampling regime:
integration by parts and the Galerkin projection remove all components that
cannot be detected by the symmetric bilinear form $B(\cdot,\cdot)$, leaving a
unique smooth antisymmetric residue compatible with spline closure.

The discretization operator $\operatorname{Disc}_{\epsilon}$ is defined so
that, for any smooth operator $T$ on the trial space, $\operatorname{Disc}_\epsilon(T)$
is the unique discrete operator whose action agrees with $T$ on all refinement
patterns distinguishable at scale $\epsilon$, and differs from $T$ only by
terms that would require additional, unrecorded events to detect.  In
particular, if two discretizations $T_1$ and $T_2$ differ on any pattern
resolvable at scale $\epsilon$, then the difference encodes additional
structure that would need to be measured to be admissible.

Apply this to $T = \mathsf{X}_G$.  By definition of the Informational Cross
Product (Definition~\ref{def:informational-cross-product}), $\mathsf{X}_I$ is
precisely the event--update operator that records the non--commutativity of
refinement at the discrete level and vanishes whenever the updates commute.
Suppose there existed another discretization $\tilde{\mathsf{X}}$ of
$\mathsf{X}_G$ that differs from $\mathsf{X}_I$ on some distinguishable
refinement pattern.  Then $\tilde{\mathsf{X}}$ would encode additional twists
not required by the observed failure of commutation, thereby introducing
unobserved structure.  This contradicts informational minimality.

Hence $\mathsf{X}_I$ is the unique discretization compatible with both the
Galerkin shadow and the Axiom of Boltzmann.  By uniqueness of the discrete
operator agreed upon at all $\epsilon$--resolvable patterns, we have
\[
\mathsf{X}_I = \operatorname{Disc}_{\epsilon}(\mathsf{X}_G),
\]
as claimed.
\end{proofsketch}

\begin{phenomenon}[The Arago Effect]
\label{ph:arago-effect}

\textbf{Statement.}
A bright region appears in the geometric shadow of a circular obstacle because
the ledger must remain globally consistent along the entire boundary.  Local
histories are subordinated to global admissibility.

\textbf{Classical Context.}
Poisson famously argued that the wave theory of light was absurd because it
predicted a bright spot at the center of the shadow of a circular disk, a
region that ray optics insisted must be dark.  Arago's experimental
confirmation of the spot revealed that the absurdity lay not in the
prediction, but in the assumption that causal histories could be deleted
locally without reference to the global boundary.

\textbf{Informational Interpretation.}
The edge of the obstacle forms a closed causal boundary
\(
\partial \Omega.
\)
By the Law of Boundary Consistency (Law~3), the state of the field at any
interior point must be the unique refinement compatible with the entire
boundary ledger simultaneously.

Along the central axis behind the disk, every point is equidistant from
$\partial \Omega$.  Because the boundary refinements are symmetric, the
Axiom of Ockham (Axiom~3) forbids the introduction of unrecorded phase
asymmetries that would force destructive cancellation.  To assert darkness at
the center would require the ledger to encode hidden distinctions that do not
exist in the boundary record.

Therefore the only admissible history is the one in which refinements merge
coherently.  The bright spot is not the result of waves bending around an
object; it is the informational checksum of the boundary.  The ledger cannot
delete the signal at the center without introducing structure that was never
measured.  Global consistency overrides the intuition of local blocking.

\end{phenomenon}



\section{The Informational Strain Tensor}

\begin{definition}[Informational Strain Tensor~\cite{cauchy1828,saintvenant1860}]
Let $U$ be an informational state transported around a closed refinement
cycle.  The informational strain tensor is the unique multilinear operator
$\mathcal{S}$ satisfying
\[
U_{\mathrm{final}} - U_{\mathrm{initial}} = 
\mathcal{S}(U_{\mathrm{initial}}).
\]
\end{definition}

\NB{This definition expresses strain as the minimal multilinear correction 
required to reconcile initial and final informational states after a closed 
cycle of refinement.  In the smooth shadow, $\mathcal{S}$ reduces to the 
curvature tensor of the informational gauge.}

The strain tensor captures all second-order incompatibilities that arise from
trying to merge locally consistent refinements.  Where stress governs the
linear transport of distinguishability, strain measures the failure of that
transport to be integrable.  Strain is thus the obstruction to global 
coherence inherent in the refinement record itself.

\section{Unavoidable Strain and the Necessity of Curvature}

When local refinements agree on pairwise overlaps but fail on triple overlaps,
strain is unavoidable.  No ordering of updates or choice of gauge can remove
it.  This non-closure is the combinatorial analogue of the Bianchi identity:
a defect in the associativity of refinement that cannot be eliminated by
reparametrization.

Informational minimality ensures that this defect must appear.  If 
inconsistencies were ignored, they would create unrecorded structure, 
violating the axioms of event selection and informational closure.  Thus, the
existence of strain is a logical necessity, not a geometric postulate.

In the smooth shadow, unavoidable strain manifests as curvature.  In the
discrete domain, it is the minimal corrective refinement required to restore
global consistency.

\section{The Law of Curvature Balance}


\begin{law}[The Law of Curvature Balance]
\label{law:curvature-balance}
\NB{This law follows immediately from 
Proposition~\ref{prop:recover-cross-product} and 
Proposition~\ref{prop:informational-minimal-discretization}.  
No geometric postulates are made; curvature arises solely as the residue 
of informational non--closure.}

Let $\mathsf{X}$ be the generalized cross product of
Proposition~\ref{prop:recover-cross-product}, and let
$\mathsf{X}_I$ be its informational minimal discretization from
Proposition~\ref{prop:informational-minimal-discretization}.  
Let $\nabla$ denote the informational connection of Chapter~5, and let
$\mathcal{R}$ denote the curvature operator.

Then for all $u,v,w \in V$,
\[
\mathcal{R}(u,v)\,w
\;=\;
\bigl(\nabla_u\nabla_v
        - \nabla_v\nabla_u
        - \nabla_{u \mathsf{X}_I v}
\bigr) w.
\]

Moreover, the discrepancy
\[
\mathsf{S}(u,v) \;:=\; (u\,\mathsf{X}\,v) - (u\,\mathsf{X}_I\,v)
\]
is exactly the Informational Strain Tensor of
Definition~\ref{def:informational-strain}.  Thus
\[
\boxed{
\text{Curvature} 
\;=\; 
\text{Informational Strain}
\;=\;
\text{Minimal Non--Closure of the Generalized Cross Product}.
}
\]

\paragraph{Interpretation.}
Once the generalized antisymmetry reduces to the classical cross product in
three dimensions, and once the informational discretization is forced by
minimality, the defect of closure cannot be eliminated locally without
producing unobserved structure.  The axioms therefore require that this
residue be balanced globally, yielding curvature as a theorem of measurement.
\end{law}

By definition of the informational connection $\nabla$ (Chapter~5), parallel
transport of an informational state along refinement directions $u$ and $v$
is represented by iterated application of $\nabla_u$ and $\nabla_v$.  In the
smooth shadow, the curvature operator $\mathcal{R}(u,v)$ is the obstruction
to exchanging the order of these transports; classically,
\[
\mathcal{R}(u,v)w
=
\bigl(\nabla_u\nabla_v - \nabla_v\nabla_u\bigr)w
\]
whenever transport closes.

In the informational framework, refinements need not close.  The missing
update required to restore closure is recorded by the Informational Cross
Product: for refinement directions $u$ and $v$, the operator $u \mathsf{X}_I v$
is exactly the minimal corrective update that measures the failure of the
corresponding refinement actions to commute (Definition~\ref{def:informational-cross-product}).

Transporting $w$ around a closed refinement loop generated by $u$ and $v$
therefore produces three contributions:
\begin{enumerate}
\item the transport $\nabla_u\nabla_v w$,
\item the reversed transport $\nabla_v\nabla_u w$, and
\item the corrective transport along $u \mathsf{X}_I v$ required to maintain
      coherence.
\end{enumerate}
Global consistency demands that the net update around the loop be measured
entirely by the curvature of the informational gauge.  Any residual that
could be removed by adjusting the connection would represent unrecorded
structure and is forbidden by informational minimality.

Thus the true curvature operator $\mathcal{R}(u,v)$ must absorb both the
commutator of covariant derivatives and the corrective update along
$u \mathsf{X}_I v$:
\[
\mathcal{R}(u,v)w
=
\bigl(\nabla_u\nabla_v - \nabla_v\nabla_u - \nabla_{u \mathsf{X}_I v}\bigr)w.
\]
Rewriting the residual update in terms of the Informational Strain Tensor
$S$ (Definition~\ref{def:informational-strain}) shows that $S$ is exactly
the tensorial form of the non--closure of refinement, while $\mathcal{R}$ is
its smooth representation.  The divergence--free condition of the Law of
Curvature Balance, $\nabla \cdot S = 0$, then follows from the combinatorial
Bianchi--type identity for closed refinement cycles discussed in
Section~\ref{sec:unavoidable-strain}, which expresses that strain cannot
accumulate without bound on any admissible global history.

Hence curvature, informational strain, and minimal non--closure of the
generalized cross product are three shadows of the same obstruction to
refinement closure, completing the proof sketch.

\section{Flat Rotation Curves~\cite{rubin1970,rubin1980}}
\label{sec:rotation-curves}

The rotation profile of a galaxy provides an unusually clear window into the
informational structure of the causal record.  At large radii, the observer
is no longer tracking local forces or microscopic dynamics; the only
question is how much curvature can be distinguished as the history of a
rotating system is transported outward.  In the informational framework,
this is not a dynamical computation but a question of capacity.  The curved
portion of the record must be conveyed across increasingly sparse
refinement, and the rate at which new curvature can be distinguished is
strictly bounded by the Martin condition and the Kolmogorov limit of the
observer.

Shannon's theory provides the conceptual template: a channel with finite
capacity cannot reproduce arbitrarily rapid variation without error.  In the
same way, the causal network cannot propagate curvature corrections whose
informational rate exceeds the distinguishability bandwidth available at
large radius.  The classical Keplerian falloff requires an ever-increasing
curvature signal to be recorded as the orbital circumference grows, but the
observer cannot resolve this increase.  Beyond a certain point, additional
curvature is informationally invisible.

The result is not a failure of physics but the enforcement of informational
minimality.  When the curvature demand of the classical profile exceeds the
capacity of the refinement channel, the admissible history collapses to the
minimal-curvature solution compatible with the record.  The velocity curve
therefore flattens: not because mass is missing, but because the causal
network has exhausted its ability to distinguish any further variation in
the curvature ledger.


\begin{phenomenon}[The Flat Rotation Curve Effect~\cite{shannon1948}]
\NB{This is an informational consequence, not an astrophysical hypothesis.
No assumptions regarding dark matter, mass distributions, or Newtonian
potentials are invoked.  The flattening derived here is the smooth
shadow of a discrete consistency requirement: non--commuting refinements
produce a curvature residue that appears, in the continuum, as a viscous
correction to transport.}
\NB{The argument presented here is not a dynamical model of galaxies.
It is a bandwidth computation in the precise sense of Shannon's theory of
communication~\cite{shannon1948}.  The causal network has a finite capacity
to convey distinguishable refinement, and therefore cannot reproduce
curvature variations whose informational rate exceeds this capacity.  The
flattening of the rotation profile reflects this saturation of
distinguishability bandwidth, not the presence of unobserved mass or
additional physical fields.}


Every orbit reconstructed from finite measurements consists of two refinement
chains:
(i) the radial chain of recorded separations, and
(ii) the tangential chain of angular distinctions.
In an informationally flat geometry these chains commute---refining the radial
data then the angular record yields the same admissible completion as
refining them in the opposite order.

However, whenever local refinements disagree on their common boundary,
or when uncorrelant segments must be merged, the two refinement chains
fail to commute.  
By the Axiom of Ockham, no hidden structure may be inserted to enforce
commutativity, and by the Axiom of Boltzmann, the global record must
remain coherent.  
The irreducible mismatch is therefore a \emph{viscous residue}, the same
object defined in Section~\ref{sec:viscosity} as \emph{informational viscosity}.

In the smooth shadow, this residue manifests as a curvature-induced tangential
correction.  The observable effect is that the angular velocity $v_\theta(r)$
does \emph{not} decay as $r^{-1/2}$ even when the inferred radial refinements
would demand it.  Instead, informational viscosity contributes a
boundary-consistency correction that remains finite at large radii:
\begin{equation}
v_\theta(r)
\;=\;
v_{\mathrm{Newton}}(r)
\;+\;
\eta_{\mathrm{info}}
\left(
\frac{\partial}{\partial r}
\left(
\frac{1}{r}\,\frac{\partial r}{\partial \tau}
\right)
\right)
\;+\;
\mathcal{O}(\eta_{\mathrm{info}}^2),
\label{eq:rotation-viscosity}
\end{equation}
where $\eta_{\mathrm{info}}$ is the informational viscosity parameter introduced
in Equation~(6.x), and $\tau$ is the informational interval of
Section~\ref{sec:informational-interval}.  

At sufficiently large radii the Newtonian term becomes negligible while the
informational-viscosity term remains non-zero, leading to \emph{flattened
rotation curves}.
\end{phenomenon}


\label{sec:ang-momentum}
\begin{phenomenon}[The Angular Momentum Effect]

A bicycle wheel of mass $M$ and radius $R$ is mounted on low--friction
bearings.  The wheel is brought to a steady rotational speed and its angular
velocity is measured using a stroboscope or optical tachometer.

The angular momentum is then \emph{observed and computed} from measurable
quantities:
\[
L = I \,\omega ,
\]
where the moment of inertia of the wheel is
\[
I \approx M R^2 ,
\]
and the angular velocity is
\[
\omega = 2\pi f ,
\]
with $f$ the observed rotation frequency.

For example, a wheel with
\[
M = 2.0~\mathrm{kg}, \qquad R = 0.33~\mathrm{m}, \qquad f = 5~\mathrm{Hz}
\]
has
\[
\omega = 31.4~\mathrm{rad/s}, \qquad
I \approx 0.218~\mathrm{kg\,m^2},
\qquad
L \approx 6.85~\mathrm{kg\,m^2/s}.
\]

This value is not inferred from theory but reconstructed directly from
observable mass, geometry, and frequency.  The persistence of this quantity
under external perturbation constitutes the observational phenomenon of
angular momentum.

The observational computation above admits a strictly weaker informational
representation.  Although the applied influences are linear and act along
distinct spatial directions, the admissible record does not require a full
two--dimensional description of the induced motion.  The record may be
compressed by replacing independent linear displacements with a single angular
coordinate.

Rather than tracking the motion in a full planar basis, the admissible
description collapses to the pair
\[
(r,\theta),
\]
where $r$ encodes radial admissibility and $\theta$ encodes cyclic refinement.
The angular component carries half the effective dimensional burden of a
Cartesian basis, as the refinement is constrained to a closed orbit.

Informationally, this compression is not an approximation but a necessity:
the coherent record cannot sustain independent degrees of freedom once the
cyclic constraint becomes admissible.  The refinement therefore induces a
second--variational structure.  After the first (Jacobi) variation fixes the
admissible path, the remaining admissible deformations appear only in the
angular coordinate.

The persistence of angular momentum is, in this sense, not a force law but a
second--variational residue of admissible compression.
\end{phenomenon}


\section{Informational Strain Transport}
\label{sec:strain-transport}

\subsection{The Necessity of Strain Bookkeeping}

Chapters~5 and~6 established that the structure of the Causal Universe
Tensor $U$ is governed by a dynamic balance between \emph{informational
stress}---the metric gauge $g_{\mu\nu}$ recording how distinguishability is
propagated---and \emph{informational strain} $\Sigma$, the residue produced
whenever admissible refinements fail to close around a loop.  Stress is the
kinematic ledger; strain is the curvature-level correction demanded by the
Axiom of Ockham and the Axiom of Boltzmann.

The Law of Curvature Balance (Law~5) demonstrated that when two
refinement directions do not commute, the resulting discrepancy is not
optional bookkeeping: it is an irreducible residue of the informational
record.  No admissible extension may delete or overwrite this residue, and
no unobserved structure may be inserted to cancel it.  Thus, curvature is
not a field but a \emph{consequence}: a record of failed commutation that
must be reconciled by the global merger of histories.

This creates an immediate tension inside the causal network.  If $\Sigma$
cannot be locally eliminated without violating Ockham minimality, and if
the network must remain globally coherent under all admissible merges, then
the residue cannot stay where it is.  It must be \emph{transported}.  The
informational universe cannot allow curvature strain to accumulate
indefinitely at a refinement site, because doing so would force the network
to insert additional structure to preserve global consistency---an
inadmissible act.

The question, therefore, is unavoidable:

\begin{center}
\emph{How does the causal network transport uncorrected curvature residue
while preserving informational minimality?}
\end{center}

The answer follows from a key observation established earlier: different
refinement chains incur different informational costs.  Some chains require
many intermediate updates to preserve consistency; others require almost
none.  Among these possibilities, the axioms admit a special class of
histories: the \emph{minimal-coupling chains}.  These are refinement paths
that propagate informational curvature without forcing its resolution.  They
perform the least amount of bookkeeping necessary to carry $\Sigma$ forward
until a refinement is forced to absorb the residue.

Such chains saturate the maximal admissible propagation speed and interact
only when the informational record demands a second-order correction.  In
the smooth shadow, they behave like nearly interaction-free carriers of
curvature strain: the informational analogue of neutrinos.

This leads directly to the phenomenon below.  The Neutrino Effect is not a
physical hypothesis.  It is the smooth shadow of the unique minimal-cost
transport mechanism permitted by the axioms of measurement.


\begin{phenomenon}[The Neutrino Effect~\cite{fukuda2003,hirata1987}]
\NB{This informational phenomenon does not appeal to particle physics,
standard-model interactions, or any dynamical assumptions about matter.
It arises solely from the axioms of distinguishability, refinement
minimality, and curvature as the residue of non--commuting refinements.}
\NB{Astrophysical neutrinos from supernovae are empirically observed to
arrive before the concentrated burst of photons.  In the informational
framework, this is the expected shadow of curvature transport: the
curvature residue $R$ travels along admissible chains with a minimal set
of permitted interactions.  Because only a very small number of
refinement events are required to supply the second--order correction, the
messenger is effectively interaction--free.  Photons, by contrast, must
wait for the medium to refine sufficiently to release a coherent burst.
Thus, the informational ``neutrino'' arrives first, providing the
curvature fix that guarantees that the later photon record is globally
consistent for all observers.}
\NB{No claim is made regarding the taste, flavor, mouthfeel, bouquet, or
organoleptic profile of neutrinos.  Any resemblance to sensory
modalities is purely metaphorical and should not be construed as a
physical assertion.}


When two admissible refinement directions fail to commute, the Law of
Curvature Balance forces a discrete residue $R$.  By the Axiom of Ockham,
no unobserved structure may be introduced to remove this residue, and by
the Axiom of Boltzmann, the global causal record must remain coherent.
Thus, the residue must be transported until some refinement is forced to
resolve it.  This curvature--carrying transport behaves, in the smooth
shadow, like a nearly undetectable messenger field whose sole role is to
deliver the correction required for a consistent reconstruction of the
event.

In this sense, the informational neutrino carries not energy or matter but
the \emph{missing correlants} required to ensure that the photon record
will reconstruct the same admissible history in every reference frame.
Information cannot propagate faster than the maximal admissible
refinement speed, but the messenger of curvature strain saturates that
speed because it admits almost no intermediate interactions that would
delay its progression.  Upon arrival, it contributes the precise
second--order correction that resolves the non--commutative residue, so
that the photon burst---arriving later---is interpreted without ambiguity.

Thus, the Neutrino Effect is the informational shadow of curvature
transport: the discrete residue of non--closure moves first, ensuring that
the subsequent refinement (carried by photons) is interpreted consistently
in every admissible frame, thereby recovering the logic of Einstein's
original thought experiment.
\end{phenomenon}

\begin{example}[Implied Orthogonality and Space--Time]
\NB{CAVEAT EMPTOR}
The author presents no phenomenon suggesting any structure
\emph{orthogonal to space--time}.  Any such language in the surrounding
discussion is to be read as set--theoretic rather than geometric.

Rather, the author suggests there is an informational degree of freedom
between measurements.  See Phenomena~\ref{ph:here-and-now} and~\ref{ph:constant}.
\end{example}



\begin{coda}{Coda: The Informational Stress--Strain Relation}

\NB{Throughout this work, classical differential equations are treated not as
fundamental laws but as effects that can be observed.  The Navier--Stokes
equation is the smooth shadow of the balance between informational stress
(transport) and informational strain (non--closure)~cite{timoshenko1934}.  Nothing in this coda
assumes a physical medium; the equation is quoted only as the continuous
representation of the bookkeeping required for global coherence under
refinement.}
The path to Navier--Stokes begins with the simplest of all mechanical ideas:
statics.  In classical statics, a system is said to be in equilibrium when the
sum of forces vanishes.  Nothing moves, nothing deforms, and the internal
ledger of stresses balances exactly.  Every contribution is accounted for, and
the record closes without residue.  This is the mechanical expression of
coherence.

In the informational setting, the same idea appears at the level of
refinement.  A static configuration is one in which the admissible
distinguishability does not change.  The update operator is the identity, the
strain operator $\Sigma$ vanishes, and no correction is required to maintain
consistency.  Statics is therefore the trivial case of informational stress
and strain: transport is absent, and closure is automatic.

The transition from statics to dynamics occurs the moment transport is
introduced.  Once distinguishability begins to propagate, the stress ledger no
longer balances by default.  Refinements may fail to close, and the mismatch
accumulates as informational strain.  Classical mechanics responds to this
imbalance by introducing inertial terms, pressure forces, and viscous
corrections.  In the informational picture, these are not imposed laws but the
minimal bookkeeping required to restore coherence when transport is present.

Navier--Stokes arises precisely from this requirement.  It is the statement
that the stress generated by transport must be balanced by the strain required
to correct its non--closure.  The left--hand side of the equation records the
informational stress of convective propagation; the right--hand side records
the informational strain needed to enforce global compatibility.  In the
limit where refinements are dense and their residues are approximated by
differential operators, the balance of these quantities becomes the familiar
continuity equation of fluid dynamics.

Thus, Navier--Stokes is not a departure from statics but its extension.  It is
the natural generalization of equilibrium to situations in which information
is moving.  Statics states that the stress ledger must close when nothing
changes.  Navier--Stokes states that the ledger must still close when
everything does.

The informational interpretation of Navier--Stokes follows directly from the
definitions of stress and strain developed in this chapter.  The transport of
distinguishability under the update map $\Psi$ generates informational stress:
the left--hand side of the classical equation,
\[
\partial_t u + (u \cdot \nabla)u,
\]
represents the linear propagation of admissible refinements.  If this
transport were globally integrable, no additional correction would be needed.

However, convective transport is not integrable in general.  Closed loops of
refinement do not return to their initial state.  The mismatch accumulates as
informational strain.  In the smooth shadow, the required correction appears
as the right--hand side of the Navier--Stokes equation,
\[
-\frac{1}{\rho}\,\nabla p + \nu\,\Delta u,
\]
where the pressure term enforces compatibility with local volume constraints
and the viscous term $\nu\,\Delta u$ is the continuous representation of the
strain operator $\Sigma$ of Section~\ref{sec:strain-residue}.  Viscosity is
therefore an informational phenomenon: the amount of correction required to
neutralize non--closure and restore global consistency.

In this sense, Navier--Stokes is an informational stress--strain relation.
Transport generates the stress; non--closure generates the strain; and the
viscous term is the minimal second--order correction needed to reconcile them.
\section{Informational Angular Momentum}
Rotational structure emerges as the final classical observable invariant
before nonlocal refinement modes appear.  Unlike linear displacement, which
may be decomposed into independent observational updates, cyclic motion
imposes a global coherence constraint on the admissible record.  Once a
measurement history admits closed refinement paths, the record can no longer
be described by independent translations alone.  A persistent residual is
forced by the requirement of consistency under cyclic transport.  This
residual is not introduced as a physical postulate, but appears as an
observational necessity.

\section*{The Clay Navier--Stokes Problem in Informational Form}

\NB{The following description restates the classical Clay Institute problem in
the language of informational transport.  No claim of resolution is made.  The
problem is quoted for context only.}

Let $u(x,t)$ be the informational velocity field representing the smooth
shadow of refinement transport on $\mathbb{R}^3$.  The Clay problem concerns
whether solutions to the balance equation
\[
\partial_t u + (u \cdot \nabla)u =
-\nabla p + \nu\,\Delta u,
\qquad \nabla \cdot u = 0,
\]
exist for all time and remain smooth when the initial data are finite and
sufficiently regular.

In informational terms, the problem may be phrased as follows:

\begin{quote}
Does the balance between informational stress and informational strain admit a
globally coherent smooth shadow for all time, or can the strain operator
$\Sigma$ accumulate without bound, producing a breakdown of the continuous
representation even when the discrete refinement record remains well--defined?
\end{quote}

Equivalently: does the correction $\nu\,\Delta u$ always suffice to control
non--closure, or can convective transport accumulate strain faster than
viscosity can dissipate it?

\NB{A finite--time singularity in the classical equation corresponds, in the
informational picture, to the divergence of the smooth shadow of strain.  It
does not imply a contradiction in the underlying discrete refinement record,
but indicates that the continuum approximation has ceased to track it.}

The Clay problem therefore asks whether informational stress and informational
strain can remain in balance for all time under dense refinement, or whether
the continuous representation can fail even when the discrete theory remains
coherent.

\noindent\textit{Is the existence of quantum theory logically necessary?}
The author suggests that the differential equations may fail at small enough resolution.  See
Phenomenon~\ref{ph:dirac-operator} and Axiom~\ref{ax:planck}. Resonance is sometimes real, 
sometimes Gibb's phenomena.

\end{coda}

