\chapter{The Algebra of Events}
\label{chap:algebra}
\NB{The measurable objects of this chapter live in a finite--dimensional real
vector space $V$ and its tensor algebra $\mathcal{T}(V)$.  We assume no
metric, no inner product, and no rule for raising or lowering indices.
Consequently, there is no notion of contravariance or covariance in the
formal development, and Einstein summation does not apply.  The tensor
algebra here is purely algebraic: indices do not carry geometric meaning.

When a thought experiment quotes familiar expressions from continuum
physics (stress--energy, geodesic equations, curvature terms, and so on),
we reproduce their standard index notation verbatim so that the reader may
recognize the classical form.  These indices belong to the \emph{smooth
shadow} of the theory, not to the discrete algebra itself.  The combinatorial
foundation assumes only that $V$ exists; no metric structure is imposed.}


The first chapter established the informational mechanism of physics:
each measurement produces a finite, distinguishable event, and the
absence of additional events is itself a binding constraint.
Measurement is not a sampling of an underlying continuum; it is the
creation of distinguishability.  From a mathematical standpoint, the
universe is therefore a growing record of discrete selections, ordered
by refinement.

This chapter formalizes that structure.  We build the algebra of
measurement itself.  Rather than treating observations as values of
continuous functions, we adopt the combinatorial viewpoint forced by
the Axioms of Planck and Cantor: every admissible experimental record
is finite or countable, and every refinement is a restriction of
admissible outcomes.  The central object of this chapter---the
\emph{Causal Universe Tensor}---expresses the fact that history is
built multiplicatively: each new event contracts the set of admissible
continuations of the record.  The universe does not evolve additively
in time; it accumulates consistency through left products of restricted
increments.


This changes the role of time entirely.  In the discrete domain $E$,
time is ordinal: an index into the growing chain of distinguishable
selections.  In the continuous shadow $U$, time does not flow at all.
The continuous tensor $\mathbf{U}_k$ at step $k$ is not the result of
propagation, but the image of a restriction map:
\begin{equation}
\label{eq:Uk-update}
\mathbf{U}_{k+1} \;=\; \Psi\!\big(e_{k+1} \cap \hat{R}(e_k)\big)\,\mathbf{U}_k,
\end{equation}
where $\hat{R}$ is the discrete restriction induced by the most recent event
$e_k$, and $\Psi$ is its continuous representation.  Thus the
continuous universe is not postulated as a field living on a manifold:
it is the coherent bookkeeping of discrete consistency.

The ordered product makes this explicit.  If $\hat{R}(e_j)$ denotes
the admissible refinement of the $j$-th event, then the causal universe
as seen by a single inertial observer is
\begin{equation}
\mathbf{U}_k \;=\; \prod_{j=1}^{k-1} \Psi\!\big(e_{j+1} \cap \hat{R}(e_j)\big).
\end{equation}
No geometry, metric, or dynamical law is assumed.  Continuity,
smoothness, and variational structure will reappear later only as the
unique continuous shadow of this discrete product, forced by
informational minimality and global coherence.

In this way, Chapter~\ref{chap:algebra} performs the key transition:
from sets of distinguishable events to an algebra of restricted,
multiplicative updates.  The universe is ``embarrassingly parallel'':
each inertial frame maintains its own $\mathbf{U}_k$, derived solely
from the restriction of its local events.  Relativistic simultaneity
requires no further machinery.  Partitions of $E$ arise naturally from
informational independence, and the merge of light-cone–consistent
updates uniquely defines their reconciliation.

\NB{In the sense of parallel computing, the causal structure is
``embarrassingly parallel'' \cite{amdahl1967}: independent branches of
$E$ evolve without any need for global synchronization.  Only when
light cones overlap must their records be reconciled, and in that case
consistency is enforced by the causal order rather than by a shared
clock.}



The remainder of the chapter introduces the axioms, operators, and
tensor structures that make this viewpoint precise, culminating in the
formal definition of the causal universe tensor.

\begin{example}{Statistical Process Control~\cite{shewhart1931}}
\NB{Observational records have been used to understand and control complex
processes to remarkable success.  Statistical process control
demonstrates that measurement does not estimate a continuous parameter
directly; it eliminates process states that are incompatible with the
record.  The state of the system is therefore not an average, but the
set of configurations that have survived all admissible checks.}

Imagine a factory that manufactures a precision component.  The process
is controlled by a set of adjustable parameters: temperature, pressure,
feed rate, alignment, and so on.  At startup, all parameter settings
that satisfy the design tolerances are admissible; the process could be
in any one of many configurations.  A single measurement does not
determine the underlying state.  It merely rules out those
configurations that would have produced a conflicting outcome.

This is the essential structure of statistical process control.  Each
inspection, probe, gauge reading, or quality check eliminates a subset
of incompatible configurations.  After $k$ measurements, the surviving
parameter settings are precisely those that are consistent with all $k$
observations.

Let $e_k$ denote the $k$-th inspection result, and let $\hat{R}(e_k)$ be
the discrete restriction that removes every process state incompatible
with $e_k$.  If $\Psi$ embeds these restrictions into the continuous
tensor domain, the recorded state of the process after $k$ inspections
is
\begin{equation}
\mathbf{U}_k \;=\; \prod_{j=1}^{k-1} \Psi\!\big(e_{j+1} \cap \hat{R}(e_j)\big).
\end{equation}
The process does not ``evolve'' in time in the usual dynamical sense;
it accumulates admissibility.  Each new inspection refines the record
by discarding alternatives, giving the stepwise update
\begin{equation}
\mathbf{U}_{k+1} = \Psi\!\big(e_{k+1}\cap\hat{R}(e_{k})\big)\,\mathbf{U}_k.
\end{equation}

Two independent inspectors, perhaps located at different stations on
the production line, can refine their records without communication.
If their measurements are mutually consistent, the products merge
without conflict.  If not, no admissible configuration survives the
combined restrictions, and the process is flagged as out of control.
In this sense the system is ``embarrassingly parallel'': independent
measurements commute whenever they are spacelike in the informational
sense, and consistency is enforced only when histories are compared.

This ordinary industrial setting exhibits the same structure developed
in this chapter.  Measurement eliminates incompatible alternatives,
time indexes the number of admissible refinements, and the continuous
representation $\mathbf{U}_k$ is nothing more than the shadow of a
discrete product of selections.
\end{example}

We begin by enumerating the Axioms of Measurement, which formalize the
structure of admissible records and the refinement of observational
history.


\section{The Axioms of Mathematics}
\label{se:mathaxiom}

All mathematics in this work is carried out within the framework of
Zermelo–Fraenkel set theory with the Axiom of Choice (ZFC)~\cite{jech2003,kunen1980}.
Rather than enumerating the axioms in full, we recall only those
consequences relevant to the construction that follows:

\begin{itemize}
  \item \textbf{Extensionality} ensures that distinguishability has formal
  meaning: two sets differ if and only if their elements differ.
  \item \textbf{Replacement} and \textbf{Separation} guarantee that
  recursively generated collections such as the causal chain of events
  remain sets.
  \item \textbf{Choice} permits well–ordering, allowing every countable
  causal domain to admit an ordinal index.
\end{itemize}

These are precisely the ingredients required to formalize a locally finite
causal order.
All further constructions---relations, tensors, and operators---are definable
within standard ZFC mathematics; see Kunen~\cite{kunen1980} and Jech~\cite{jech2003}
for set-theoretic foundations, and Halmos~\cite{halmos1958,halmos1974naive} for the
induced tensor and operator structures on finite-dimensional vector spaces.

The starting point of this framework is methodological rather than
ontological.  We do not assume anything about the substance of physical
reality.  We assume only that the outcomes of measurement are finite or
countable collections of distinguishable results recorded in time.
This is standard across probability theory and information theory:
Shannon formalized information as distinguishable symbols drawn from a
finite or countable alphabet \cite{shannon1948}, and Kolmogorov showed
that empirical outcomes can be represented as elements of measurable
sets within standard set theory \cite{kolmogorov1933}.  In this view,
measurement produces data, and data are mathematical objects.
Everything that follows concerns the admissible transformations among
such records.

\begin{axiom}[The Axiom of Kolmogorov~\cite{kolmogorov1933}]
\label{ax:kolmogorov}
\emph{[Measurement as a Formal Record.]}

The record of measurement---defined as the finite or countable set of
observed, distinguishable events---is taken to be a mathematical object
representable within ZFC. No
ontological claim is made about physical reality. The axiom asserts only
that observable data can be formalized as sets and relations.

This standpoint is consistent with Kolmogorov's construction of probability
spaces, in which empirical outcomes are represented as measurable sets
\cite{kolmogorov1965}. Accordingly, a record of finite observations is a
mathematical object whose structure is defined entirely within ZFC. Throughout
this work, the word ``information'' refers exclusively to these representable
distinctions; nothing is asserted about any underlying physical substrate
that might produce them.
\end{axiom}



\begin{axiom}[The Axiom of Peano~\cite{fraenkel1922,martin1970,zermelo1908}]
\label{ax:peano}
\emph{[Counting as the Tool of Information]}
All reasoning in this work is confined to the framework of ZFC.
Every object---sets, relations, functions, and tensors---is
constructible within that system, and every statement is interpretable
as a theorem or definition of ZFC.  No additional logical principles
are assumed beyond those required for standard analysis and algebra.

Formally,
\[
\mathrm{Measurement} \;\subseteq\; \mathrm{Mathematics} \;\subseteq\; \mathrm{ZFC} \;subseteq\; \mathrm{Counting}.
\]
Thus, the language of mathematics is taken to be the entire ontology of
the theory: the physical statements that follow are expressions of
relationships among countable sets of distinguishable events, each
derivable within ordinary mathematical logic.
\end{axiom}

\begin{example}[The Speedometer~\cite{warner1902,yoshida1980}]
\label{te:speedometer}
\NB{The mechanical implementation of measuring devices often are protected
by explicit descriptions of how they work. The patents cited here explicitly
describe how they turn counting into data.}

Consider an ordinary automobile speedometer.  The dial appears to report a
continuous real number at each instant, but the device does not have access
to the real numbers.  A mechanical speedometer counts wheel rotations through
a gear train and maps those counts to pointer positions.  A digital
speedometer counts the same rotations and displays a numeral drawn from a
finite alphabet.

Each time the counter increments and the displayed symbol or pointer position
changes, a new distinguishable event is recorded.  Between two successive
display states there is no way, from the informational record alone, to assert
that any additional state occurred.  The apparent continuity of ``speed'' is a
visual interpolation of a finite counting process.

Thus the speedometer does not output a real number.  It outputs a countable
sequence of distinguishable states derived from integral counts of wheel
rotations.  The act of measuring speed reduces to counting transitions of a
finite-state device.  All physical inference based on such data can be
expressed within ordinary arithmetic and set theory.

This illustrates Axiom~\ref{ax:peano}: measurement generates only countable,
finitely coded distinctions, and every mathematical object used to interpret
those distinctions---numbers, functions, tensors---is a construct of ZFC.
No structure beyond counting is assumed at the fundamental informational
level.
\end{example}


\section{The Axioms of Information}

The previous section established that a physical record is a set of
distinguishable observations, representable within ZFC, and partially ordered
by causal precedence. Nothing further was assumed about geometry, dynamics, or
the continuum. In this section, we introduce two informational axioms that
restrict how such a record may be interpreted. These axioms express constraints
on admissible descriptions of the world, independent of any particular model
of physics.

Axiom~\ref{ax:ockham} formalizes the principle that a physical history may not
contain unobserved structure. Among all symbolic descriptions that reproduce
the recorded events, the admissible one is the shortest. This is the
information--theoretic form of Ockham's principle: no plurality of assumptions
without necessity.

Axiom~\ref{ax:causal} asserts that the record of events is not merely ordered but
forms a locally finite causal set. Local finiteness ensures that causal cardinality 
is discrete, while the partial order encodes temporal precedence. Continuum
spacetime, when it exists, is therefore understood as an approximation that
faithfully embeds this discrete informational structure.

Together, these axioms define the informational content of the physical world:
a causal set with no unrecorded structure and no additional assumptions beyond
the observational record itself.

\subsection{Information Minimality}

The observational record $E$ is defined only by the distinguishable events it
contains. Between two recorded events $e_i$ and $e_{i+1}$, no additional
structure is present in the data: no new marks in the notebook, no threshold
crossings, and no observable distinctions. Set theory alone does not forbid a
hypothetical refinement that inserts additional structure between $e_i$ and
$e_{i+1}$, but any such refinement asserts observations that did not occur.
To prevent unrecorded structure from being introduced by assumption, we impose
an informational constraint.

Among all symbolic descriptions that reproduce the recorded events, the
admissible one is the shortest. In modern information theory, this statement
is formalized by Kolmogorov complexity ~\cite{kolmogorov1965,li2008}:
a description is preferred if it
introduces no additional information beyond the events in $E$. This embodies
the classical principle that no plurality of assumptions should be posited
without necessity. It is not derived from the set-theoretic framework; it is
an axiom about how physical theories must interpret finite empirical records.

\begin{axiom}[The Axiom of Ockham~\cite{ockham1323})]
\label{ax:ockham}
\emph{[Information Minimality]}
Let $E=\{e_0\prec e_1\prec\cdots\prec e_n\}$ be the recorded events of an
experiment, understood as a finite or countable set of distinguishable
observations representable in ZFC. Among all symbolic descriptions that map
to $E$ and introduce no additional recorded events, the admissible completion
is the one of minimal Kolmogorov complexity.
~\cite{kolmogorov1965,li2008}.

Equivalently, if a hypothetical refinement of the history introduces a
distinguishable update that is not present in $E$, then that refinement is
inadmissible. Any shorter description consistent with $E$ is preferred.
\end{axiom}

We have seen this principle in action already.  Refer to Thought 
Experiment~\ref{te:invisible-curve} and the use of Simpson's rule to
compute the path of a spaceship with minimal measurement information.

\subsection{Causal Set Theory}
The previous axiom imposed an informational constraint on admissible
descriptions of the record of measurement. We now introduce a structural
constraint. The empirical record is a set of distinguishable events with a
causal precedence relation $\prec$, but this alone does not restrict the size
of causal intervals. In a general partially ordered set, the number of events
between $a$ and $b$ may be infinite. Physical measurements, however, produce
finite data. To represent this empirically grounded discreteness, we assume
that the causal order is locally finite: every causal interval contains only
finitely many recorded events.

This postulate places the present construction within the causal set program
of Sorkin and collaborators, where spacetime is modeled as a locally finite
partial order and continuum geometry, when it appears, is a derived
approximation. Order encodes temporal precedence, and local finiteness
encodes discrete causal volume. No metric, field, or manifold structure is
assumed at the fundamental level; these arise only if the causal set admits a
faithful embedding into a Lorentzian manifold.

\begin{axiom}[The Axiom of Causal Sets~\cite{bombelli1987}]
\label{ax:causal}
\emph{[Events are Discrete]}

The distinguishability relations among recorded events admit a representation
as a locally finite partially ordered set $(E,\prec)$, where
\begin{enumerate}
\item $e\prec f$ means that the record of $e$ is incorporated before the record of $f$,
\item $(E,\prec)$ is acyclic and transitive,
\item and for any two events $a\prec b$, the interval
$\{\,e\in E : a\prec e\prec b\,\}$ is finite.
\end{enumerate}
Local finiteness ensures that the recorded causal cardinality is discrete, and the
order relation encodes temporal precedence within the record.  Any Lorentzian
manifold, when it exists, is merely a physical model in which this discrete
causal structure may be faithfully approximated.
\end{axiom}


\begin{example}[The Laboratory Procedure~\cite{ockham1323,wheeler1983}]
\label{ex:psi-lab}
\NB{The following example collects ideas from several well–established
perspectives in measurement theory.  Bohr and Wheeler emphasize that a
physical experiment records only distinguishable outcomes; no other
structure is operationally meaningful~\cite{bohr1928,wheeler1983}.  In
information theory, such records are represented as finite or countable
strings of distinguishable symbols~\cite{cover2006,shannon1948}.  In
ergodic theory and causal set theory, successive measurements refine a
partition of the observational domain into finer distinguishable
elements~\cite{ornstein1991,rohlin1967,sorkin2005}.  Finally,
computational mechanics and operator–theoretic dynamics treat the
“evolution” of a system as the repeated update of its information
state~\cite{birkhoff1931,crutchfield1989,koopman1931}.  Taken together,
these perspectives justify modeling a laboratory procedure as a refinement
operator acting on a finite measurement record.  The experiment does not
solve differential equations; it follows the laboratory procedure $\Psi$.}

Consider a laboratory notebook in which each threshold crossing of a detector
is recorded as a mark in ink. The notebook contains a finite sequence of
distinguishable entries
\[
e_0 \prec e_1 \prec \cdots \prec e_n,
\]
each representing an irreversible update of the experimental record. The
notebook is not a model of reality; it is the empirical record. No
claim is made about any mechanism behind it.

Now suppose one attempts to describe what ``really'' happened between two
successive entries $e_i$ and $e_{i+1}$. If additional curvature, oscillation,
turning points, or discontinuities had occurred, then the detector would have
crossed a threshold and a new entry would appear. Because no such entry is
present, the observational record forbids any refinement that predicts one.

Thus the notebook determines a finite set $E=\{e_0,\dots,e_n\}$ of recorded
events. Every admissible history must be a completion that introduces no new
distinguishable events beyond $E$. Any hypothetical refinement with additional
structure is rejected as inadmissible, since it asserts observations that did
not occur.
\end{example}



\section{The Axioms of Physics}
\label{se:physicalaxioms}

A common criticism of mathematical physics is the extent to which mathematics can 
be tuned to fit observation~\cite{boltzmann1896,planck1914} and, conversely, 
manipulated to yield nonphysical results~\cite{berkeley1734,hossenfelder2018}.
The critique of Newton’s fluxions could only be answered by successful prediction. 
Today, calculus feels like a natural extension of the real world---so much so that 
Hilbert, in posing his famous list of open problems, explicitly formalized the lack 
of a rigorous foundation for physics as his Sixth Problem~\cite{hilbert1902problems,weyl1949}.

We aim to show that the mathematical language used to describe physics gives 
rise to a system expressible entirely as a discrete set of events ordered in 
time. Moreover, this ordered set possesses a mathematical structure that 
naturally yields the appearance of continuous physical laws and the conservation of quantities.
To understand how this works, we first clarify what we mean by measurement.

\subsection{Measurement and the Axiom of Cantor}
\label{sse:measurement}
Physical laws relate measurements. For example, Newton’s second law~\cite{newton1687}
\begin{equation}
\label{eq:newton2}
F=\frac{dp}{dt}
\end{equation}
states that force relates to the \emph{change} in momentum over time. To speak of change you must have at least
two momentum values, one that \emph{comes before} the other; otherwise there is nothing to distinguish.
In set-theoretic terms, by the Axiom of Extensionality (assumed in Axiom~\ref{ax:peano}), different states must differ in their
contents, so ``change'' presupposes the distinguishability of two states.

In this framing, measurement values are \emph{counts} (cardinalities) of elementary occurrences: the number of
hyperfine transitions during a gate, the tick marks traversed on a meter stick, the revolutions of a wheel.
The \emph{event} is the action that makes previously indistinguishable outcomes distinguishable; the
\emph{measurement} is the observed differentiation (the count) between two anchor events.  This is not the
absolute measure of the event, but just relative difference of the two.  We count the events as time passes (See Thought Experiment~\ref{te:speedometer}.

Since special relativity requires that time vary under the Lorentz transform~\cite{einstein1905, lorentz1904}, there can be no 
global scalar representation of temporal duration. Rather, special relativity permits us only to 
\emph{list} all events in the universe in their proper causal order. It is this ordered list that 
we elevate to the first physical principle:

\begin{axiom}[Axiom of Cantor~\cite{cantor1895,earman1974}]
\label{ax:cantor}
\emph{[Events are Ordered and Countable]}
The only invariant agreement in time guaranteed between two observers is
the order in which correlant events (see Definition~\ref{def:uncorrelant})
occur.  Duration is not a geometric interval; it is the count of
distinguishable events that can be recorded between two selections:
\begin{equation}
\label{eq:timevariance}
|\delta t| \;=\; \bigl|\text{events distinguished between}\bigr|.
\end{equation}
\end{axiom}


\begin{example}[Relativistic simultaneity~\cite{einstein1905}.]
Two laboratories, $A$ and $B$, perform independent procedures, each producing
a finite measurement record.  Because the experiments are independent, their
events commute: no record in $A$ constrains the order of any record in $B$.
Both notebooks are internally consistent, but their events are mutually
unordered.

Now two observers, $C$ and $D$, travel past the laboratories on different
trajectories, each at a velocity close to the speed of light.  Their
instruments register signals from $A$ and $B$ in different sequences.  Since
the events commute, both observers are free to assemble the two notebooks
into different global orders.  Observer $C$ concludes that certain events in
$A$ precede those in $B$, while observer $D$ concludes the opposite.  Each
construction is internally consistent, because commutativity permits the
reordering.

The discrepancy is not a contradiction, but the finite analogue of
relativistic simultaneity: different trajectories generate different
admissible orderings of commuting events.  The events themselves may be
reordered independently of each other, yet the invariants are preserved.
\end{example}


\subsection{Observations are Combinatorial}
\label{sse:finite}

A finite observer records events one at a time.  Each record refines the
set of admissible histories, and every refinement depends only on the
records accumulated so far.  Physical description is therefore necessarily
recursive: the $(k+1)$st step is constructed from the $k$ steps that
precede it.

The recursive description of physical reality is meaningful only within the
finite causal domain of an observer. Each step in such a description corre-
sponds to a distinct measurement or recorded event. Observation is therefore
bounded not by the universe itself, but by the observer’s own proper time and
capacity to distinguish events within it.

\begin{axiom}[The Axiom of Planck~\cite{planck1901}]
\label{ax:planck}
\emph{[Observations are Finite]}
For any observer, the set of observable events within their causal domain
is finite.  The chain of measurable distinctions terminates at the limit of the
observer’s proper time or causal reach.
\end{axiom}

\noindent
This axiom establishes the physical limit of any causal description:
the sequence of measurable events available to an observer always ends in a
finite record.  Beyond this frontier---beyond the end of the observer’s time---no
additional distinctions can be drawn.  The \emph{last event} of an observer
thus coincides with the top of their causal set: the boundary of all that can be
measured or known.

\subsection{Event Selection}
The preceding axioms restrict the informational content of the record and the
structure of causal precedence.  We now introduce an axiom governing how
events may be selected in a consistent physical history.  A partial history is
a finite sequence of recorded distinctions that respects the causal order.  In
a locally finite causal set, many partial histories may be extended, but not
all extensions are admissible: each new event must be consistent with the existing record and may not
contradict any previously recorded distinction.


Axiom~\ref{ax:boltzmann} asserts that whenever we impose countably many
local admissible requirements---each representing a physically permitted
constraint---there exists at least one consistent history that satisfies
all of them\footnote{In the continuum limit, when observables range over a complete
set of measurable values, the admissible history is unique up to sets of
measure zero: there is exactly one continuous completion consistent with
all recorded refinements.}.
  Mathematically, this parallels the role of Martin's Axiom
in set theory, where dense sets encode constraints and a filter selects
a coherent global object \cite{jech2003,kunen1980,martin1970,todorcevic2010}.
Physically, it echoes Boltzmann's principle that every admissible
microstate selection must preserve distinguishability \cite{boltzmann1896},
and follows the causal-set program in which a spacetime history is
constructed one event at a time under admissible refinement
\cite{bombelli1987,finkelstein1996}.  Hilbert's call to axiomatize the
foundations of physics \cite{hilbert1902} is realized here as a minimal
requirement: if each local constraint is permissible, then some coherent
global history must also be permissible.



\begin{axiom}[The Axiom of Boltzmann~\cite{boltzmann1877,martin1970}]
\label{ax:boltzmann}
\emph{[Events are Selected to be Coherent.]}
An experiment may impose many local causal requirements: detector
constraints, boundary conditions, conservation rules, and so on.
As long as each requirement can be satisfied on its own, the Axiom of
Boltzmann asserts that there always exists at least one, globally coherent
history satisfying \emph{all} of them simultaneously.  No matter how many
local constraints we specify, they can be assembled into one consistent
record.

Formally, let $(\mathsf{P},\leq)$ be the partially ordered set (Definition~\ref{def:poset}) of
finite, order-consistent partial histories in a locally finite causal
domain, ordered by extension.  For every countable family
$\{D_n\}_{n\in\mathbb{N}}$ of dense subsets of $\mathsf{P}$ (local causal
constraints), there exists a filter $G\subseteq\mathsf{P}$ such that
$G\cap D_n\neq\varnothing$ for all $n$.
\end{axiom}


\section{The Causal Universe Tensor}
The axioms above determine the structure of the physical record: events form a
locally finite causal set, extensions of partial histories preserve causal
consistency, and informational minimality forbids unrecorded structure.  What
remains is to represent this record in a mathematical form that allows the
accumulation of distinctions.  We now construct such a representation.

\subsection{Sets of Events}
\label{sse:eventsets}

Let the set of all events accessible to an observer be denoted $E$\footnote{
The symbol $E$ here denotes the \emph{set of distinguishable events}---it is
not the energy operator or expectation value familiar from mechanics.
Throughout this work, $E$ indexes discrete occurrences in the causal order,
while quantities such as energy, momentum, or stress appear only later as
\emph{derived measures} on this set.
}, ordered by causal precedence $(\prec)$.  
Because any physically realizable region is finite, this order forms a locally finite partially ordered set (poset)~\cite{finkelstein1988causal}.

\begin{definition}[Causal Precedence~\cite{bombelli1987}]
\label{def:causalprecedence}
Let $E$ be the set of distinguishable events accessible to an observer.
For $e_i,e_j \in E$, we say that $e_i$ \emph{causally precedes} $e_j$,
written $e_i \prec e_j$, if the record of $e_j$ cannot be formed without
already having distinguished $e_i$.  Equivalently, $e_j$ refines the
admissible outcomes of $e_i$.  The relation $\prec$ is a strict partial
order: it is irreflexive ($e \not\prec e$), antisymmetric, and transitive.

\NB{The term ``causal'' is used only in the sense of ordering:
$e_i \prec e_j$ asserts that $e_j$ depends on the distinctions recorded
in $e_i$.  No geometric notion of signal propagation or physical
influence is assumed.}
\end{definition}


Each admissible set of events may be represented as a locally finite
partially ordered structure~\cite{bombelli1987,sorkin1991},
whose links record only those relations that are causally admissible.
In this view, a ``history'' is not a continuous trajectory but a
combinatorial diagram: every vertex an event, every edge a permissible
propagation.
This discrete formulation generalizes the intuition behind
Feynman's space--time approach to quantum mechanics, in which the
amplitude of a process is obtained by summing over all consistent
histories~\cite{feynman1948,feynman1965}.
The Feynman diagram thus appears here as a special case of the causal
network itself---a pictorial reduction of the full tensor of event
relations---and the path integral becomes a statement of global
consistency across all measurable causal connections.

\begin{example}[Feynman Diagram as a Causal Network~\cite{feynman1965}]
\NB{This is a classical simplification of the highly specialized notation of
the Feynman diagram.  See Thought Experiment~\ref{te:feynman-full} for a
more rigorous treatment.}

In conventional quantum field theory, a Feynman diagram depicts a sum
over interaction histories connecting initial and final particle states.
Each vertex represents an elementary event---an interaction that renders
previously indistinguishable outcomes distinct---and each propagator
represents the possibility of causal influence between events.

In the present formulation, such a diagram is naturally interpreted as a
finite \emph{causal network}.  The set of vertices corresponds to the event
set $E$, and the directed edges encode the order relation $\prec$ defined
by Axiom~\ref{ax:cantor}.  To each event $e_k$ we associate a representation
$\mathbf{E}_k$ that records the admissible refinement induced by that
event, and the directed structure describes which refinements must
precede others.  The composition of these event tensors gives the Causal
Universe Tensor of the inertial frame:
\begin{equation}
\mathbf{U}_n = \prod_{k=1}^{n} \mathbf{E}_k.
\end{equation}

At this stage, $\mathbf{U}_n$ is a classical accumulator: it records the
count and structure of distinguishable events without assigning amplitudes
or phases.  This is deliberate.  The present framework concerns only the
logical bookkeeping of distinctions.  The full quantum structure---including
complex amplitudes, superposition, and interference---appears only after
the informational gauge is introduced.  In that setting, the classical
accumulator becomes the coarse projection of a richer amplitude algebra,
much as a Feynman diagram may be viewed as the combinatorial skeleton of
a path integral.  That generalization is deferred until
Chapter~\ref{chap:mass}, where the amplitude-bearing form of $\mathbf{U}$
is constructed.

Summing over all consistent diagrams is therefore equivalent to enumerating
all admissible orderings of distinguishable events.  The path integral
itself becomes a statement of \emph{global consistency} across the entire
causal network: every measurable amplitude corresponds to a possible
embedding of finite causal order into the continuous limit.  In this sense,
a Feynman diagram is not merely a pictorial tool, but a discrete
representation of the causal tensor algebra from which continuum physics
emerges.
\end{example}


This identification is pedagogically useful.  From this point onward, every
construction may be viewed as an algebraic generalization of the familiar
Feynman diagram:  the event tensors are its vertices, the causal relations
its edges, and the Universe Tensor the cumulative sum over all consistent
orderings.  The remainder of the monograph simply formalizes this graphical
intuition in set-theoretic and tensorial language, rather than using calculus.

At the heart of measurement is the concept of a partially ordered set.
\begin{definition}[Partially Ordered Set~\cite{davey2002}]\label{def:poset}
A poset is a pair $(E,\leq)$ where $\leq$ is a binary relation on $E$ satisfying:
\begin{enumerate}
  \item \textbf{Reflexivity:} $e \leq e$ for all $e \in E$
  \item \textbf{Antisymmetry:} if $e \leq f$ and $f \leq e$, then $e = f$
  \item \textbf{Transitivity:} if $e \leq f$ and $f \leq g$, then $e \leq g$
\end{enumerate}
\end{definition}

Such an ordering always admits at least one maximal element~\cite{bombelli1987}
\begin{definition}[Top of a Poset]
\label{def:top}
Let $(E,\leq)$ be a partially ordered set.  The \emph{top} of $E$, denoted
$\mathrm{Top}(E)$, is the set of maximal elements of $E$:
\begin{equation}
\label{eq:top}
\mathrm{Top}(E) = \{\, e \in E \mid \nexists f \in E \text{ with } e < f \,\}.
\end{equation}
That is, $\mathrm{Top}(E)$ contains those events in $E$ for which no strictly
greater event exists.
\end{definition}

The elements of \(\mathrm{Top}(E)\) represent the current causal frontier—the most recent events that have occurred but have no successors~\cite{sorkin2005}.  
Although \(\mathrm{Top}(E)\) may contain several incomparable (spacelike) elements, it is never empty and therefore provides a well-defined notion of a “last event’’ from the observer’s perspective.  
This frontier defines the light-cone boundary and the terminal particle–wave interaction that delimits all accessible information.


Every event $e \in E$ corresponds to an irreducible distinction in the
experimental record.  Under the measurable embedding
$\Psi : E \rightarrow \mathcal{T}$ introduced in Thought
Experiment~\ref{ex:psi-lab}, each logical event is mapped to an algebraic
object $\mathbf{E}_e$ in the tensor algebra.  These objects compose
whenever their corresponding events are compatible in the causal order,
so the accumulation of observed events yields a record that reflects the
ordered refinement of the causal set.

The goal of this section is to define a cumulative object $\mathbf{U}_n$
---the \emph{Causal Universe Tensor}---that embodies the total
informational content of all events observed up to step $n$ in the
current inertial reference frame.  This tensor is not a dynamical
evolution.  It is the bookkeeping device that records which refinements
have survived admissibility.

It is crucial to emphasize that no background time parameter is introduced.
There is no external clock and no continuous variable $t$ against which
events are measured.  Instead, Axiom~\ref{ax:cantor} guarantees that the
causal set admits a linear extension: the events can be listed in a
sequence that respects causal precedence.  In this framework, \emph{time}
is merely the ordinal index of an event in such a sequence.  It is not a
physical field or metric quantity, but a bookkeeping device that labels
the relative order of observations.

With this viewpoint, accumulating the event tensors in order is not
evaluating a function of time.  It is forming the ordered product of
distinctions that have occurred.  The resulting object, the Causal
Universe Tensor, represents the total recorded history up to any chosen
ordinal position in the list of events.


\subsection{Special Relativity}
\label{se:special-relativity}

Every physical description begins not with space or time, but with an \emph{event}---an 
interaction that makes previously indistinguishable outcomes distinct~\cite{boltzmann1872, planck1914}.  
The causal boundary of such an interaction is its \emph{light cone}: the set of all 
events that can influence or be influenced by it according to special relativity~\cite{einstein1905, minkowski1908}.
The intersection of two light cones, corresponding to the last particle--wave interaction 
accessible to an observer, defines the maximal region of causal closure~\cite{hawking1973, penrose1972}.  
Beyond this surface, no additional information can be exchanged; all distinguishable action has concluded.

It is from this closure that the ordering of events arises.  Each 
measurable interaction contributes one additional distinction to the universe, expanding its causal 
surface by a finite count~\cite{hawking1973, malament1977}.  The smooth fabric of spacetime is not 
primitive but emergent: it is the limiting behavior of discrete causal increments accumulated along 
the light cone~\cite{bombelli1987, sorkin1991}.  Within each cone, the universe can be represented 
by a finite tensor of interactions---local updates to a global state---that together approximate 
continuity only through cancellation across countable events~\cite{bombelli1987, sorkin2003}.

\begin{example}[Boosting Velocity~\cite{einstein1905}]
\label{ref:boosting-velocity}
\NB{The Lorentz equations are presented here only as an illustrative model
of the local causal structure.  They are not derived from the axioms in
this chapter, and no subsequent argument depends on them.}

Special relativity provides the canonical local model for this causal structure.  
Consider the Lorentz transformation for a boost of velocity $v$ in one spatial dimension,~\cite{rindler2006,taylor1992}
\begin{equation}
\label{eq:lorentz}
\begin{pmatrix}
t' \\ x'
\end{pmatrix}
=
\begin{pmatrix}
\gamma & -\gamma v/c^{2} \\
-\gamma v & \gamma
\end{pmatrix}
\begin{pmatrix}
t \\ x
\end{pmatrix},
\qquad \gamma = \frac{1}{\sqrt{1 - v^{2}/c^{2}}}.
\end{equation}
For infinitesimal separations satisfying \(x = ct\), the Lorentz transformation gives
\begin{equation}
t' = \gamma\, t (1 - v/c).
\end{equation}
If we take \(\Delta t = 1\) as the unit interval between distinguishable events,
then observers moving at relative velocity \(v\) will, in general, disagree on the
\emph{number} of such events that occur between two intersections of their respective
light cones~\cite{minkowski1908}.  The only invariant quantity is the causal ordering itself:
all observers concur on which event precedes which, even though they may count
a different number of intermediate ticks~\cite{malament1977}.
\end{example}

\begin{definition}[Rank time~\cite{bombelli1987,davey2002}]\label{def:rank-time}
Let $(E,\prec)$ be a locally finite \emph{partially ordered set of events}. A rank time is an order-embedding
\[
\tau : E \to \mathrm{Ord}
\]
satisfying $e \prec f \implies \tau(e) < \tau(f)$. Local finiteness implies that for any observer's causal domain $D \subseteq E$, $\tau(D)$ is order-isomorphic to an initial segment of $\mathbb{N}$. We therefore define the \emph{duration}, $|\delta t|$, between anchors $a \prec b$ by
\[
|\delta t|(a,b) \;=\; \#\{\, e \in E \mid a \prec e \prec b \,\}\in \mathbb{N}.
\]
Two rank functions $\tau,\tau'$ are \emph{equivalent} if there exists an order-isomorphism $\phi$ with $\tau'=\phi\circ\tau$; equivalent ranks yield identical durations.
\end{definition}


\begin{remark}[Operational content of time]
Time is an ordinal rank on $E$, not an independent scalar field. All subsequent uses of ``$t$'' refer to an order-equivalence class of rank functions as in Definition~\ref{def:rank-time}. The additivity $|\delta t|(a,b)=|\delta t|(a,c)+|\delta t|(c,b)$ follows from local finiteness.
\end{remark}

This observation motivates the first physical axiom: that time is not an independent scalar field but an ordinal index over causally distinguishable events.  Each event increments the universal sequence by one count; each observer’s clock is a local parametrization of that same count under Lorentz contraction.  The apparent continuity of time is the result of the density of such events within the causal cone, not an underlying continuum of duration.

\subsection{On the Structure of Measurement}

In this formulation, a measurement is not the evaluation of a continuous
quantity against an external time parameter.  No clock, ruler, or metric is
assumed.  Instead, the Axioms of Planck and Cantor assert that an observer's
record is a locally finite, causally ordered set of distinguishable events.
To extract a numerical value from such a record, one must identify which
events satisfy a specified property and count how many of them occur between
two anchors in the causal order.

This viewpoint treats measurement as a purely combinatorial act: the
\emph{value} of a measurement is the number of admissible distinctions
satisfying a predicate inside a finite causal interval.  The result is always
an integer, and continuity---when it appears---arises only as the smooth
limit of increasingly refined counts.  We formalize this as follows.


\begin{definition}[Measurement]
\label{def:measurement}
Let $(E,\prec)$ be a locally finite partially ordered set of events, and let
$P:E\to\{0,1\}$ be a predicate designating which events satisfy a specified
property.  For two anchor events $a,b\in E$ with $a\prec b$, the
\emph{measurement of $P$ between $a$ and $b$} is the finite integer
\[
M_P[a,b]
\;:=\;
\bigl|\{\,e\in E:\; a\prec e\prec b \text{ and } P(e)=1\,\}\bigr|
\;\in\;\mathbb{N}.
\]
That is, a measurement is a count of distinguished events satisfying $P$
within the causal interval $(a,b)$.
\end{definition}

A measurement in this setting is therefore nothing more than a count of
distinguished events between anchors.  Numerical values arise only when such
counts are compared against a conventional scale.  No continuous quantity is
assumed \emph{a priori}; continuity is inferred from the refinement of a
finite causal record.  In practice, every physical “number” depends on a
calibration that relates discrete counts to a chosen system of units.


\begin{example}[Planck's Constant as a Dimensional Anchor {\cite{planck1901}}]
\NB{Planck's constant is ``constant'' only after a choice of units and a
calibration procedure.  In practice, the quoted numerical value of $h$
is obtained by fitting experimental data to a model, often by minimizing
an $L^2$ measurement error across a calibration experiment.  The
physical principle is invariant, but the reported number reflects the
best fit of a finite data set in a chosen system of units.}

Imagine a hypothetical measuring apparatus that records distinctions not by counting particles or intervals, but by tallying \emph{acts of discernment}—each act adding one quantum of distinguishability to the record. Suppose further that the calibration of such a device required only a single fixed scale to relate discrete counts to continuous units of measure. In physics, Planck’s constant $h$ serves precisely this purpose: it is not a force or an energy, but a bookkeeping factor that ensures continuity between discrete and continuous domains.

In the present framework, the analogous constant plays no physical role—it merely fixes the \emph{dimensional scale} by which finite distinctions are rendered comparable. The constant’s existence affirms that measurement can be both discrete and metrically consistent without invoking any specific quantum postulate. As with $h$, the constant here is not discovered but \emph{defined}: a normalization that preserves coherence between counting and continuity.
\end{example}


The analysis concerns only the \emph{structure of measurement itself}:
the mathematical relations among counts of distinguishable events that
underlie all physical observations.  In this framing, physics is viewed
as a grammar of distinctions.  The familiar constants and fields---mass,
charge, curvature, temperature---arise as \emph{derived measures} within a
finite causal order, not as independent entities.

\begin{example}[Measurement as a BNF Grammar~\cite{backus1959,naur1963}]
\label{ex:bnf-measurement}
Because measurement produces distinguishable outcomes, each observation
selects a symbol from a finite or countable alphabet
\[
\Sigma = \{\sigma_1, \sigma_2, \ldots \}.
\]
A record of $n$ measurements is therefore a word $w \in \Sigma^n$.  When
an instrument is refined—by increasing precision or reducing noise—any
coarse symbol $\sigma_k$ may be replaced by a finite set of more precise
symbols,
\[
\sigma_k \;\Rightarrow\; \sigma_{k,1} \;\big|\; \sigma_{k,2} \;\big|\;
\cdots \;\big|\; \sigma_{k,r},
\]
just as in a Backus--Naur Form (BNF) production rule
\cite{backus1959,naur1963}.  Not all replacements are admissible: they
must remain compatible with every other measurement that overlaps in
time or causal order.  Two refined histories that disagree on an
overlapping interval cannot both represent valid records.

Thus admissible measurement histories form a formal language generated by
the allowed refinement rules.  The ``law'' governing measurement is the
constraint that only globally consistent extensions of a record may be
generated.  This is not an analogy: it is the standard formal structure
of symbol sequences in coding and information theory \cite{sipser1997}.
\end{example}


No new particles, forces, or cosmological effects are introduced.
The present theory interrogates only the rules by which such effects are
numerically expressed.
It is not a revision of physics but a clarification of its syntax: a study
of the measures of phenomena rather than the phenomena themselves.
We begin by introducing the necessary set-theoretic language and
associating it with a discrete notion of ``time.''

\begin{definition}[Distinguishability Chain~\cite{kolmogorov1933}]
Let $\Omega$ be a nonempty set.
A distinguishability chain on $\Omega$ is a sequence
$\mathcal{P}=\{P_n\}_{n\in\mathbb{Z}}$ of partitions $P_n\in\Part(\Omega)$ such that
$P_{n+1}$ \emph{refines} $P_n$ for all $n$ (every block of $P_{n+1}$ is contained in a block of $P_n$).
Write $\Blocks{P}$ for the set of blocks of a partition $P$
Each refinement step produces zero or more event.
\end{definition}

\begin{definition}[Event~\cite{kolmogorov1933,sorkin2005}]\label{def:event}
Fix a distinguishability chain $\mathcal{P}=\{P_n\}$.
An event at index $n$ is a minimal refinement step:
a pair
\begin{equation}
\label{eq:eventdef}
e=(B,\{B_i\}_{i\in I},n)
\end{equation}
such that:
\begin{enumerate}
  \item $B\in\Blocks{P_n}$;
  \item $\{B_i\}_{i\in I}\subseteq \Blocks{P_{n+1}}$ is the family of all blocks of $P_{n+1}$ contained in $B$,
        with $|I|\ge2$ (a nontrivial split);
  \item (\emph{minimality}) there is no proper subblock $C\subsetneq B$ with $C\in\Blocks{P_n}$ for which
        the family $\Blocks{P_{n+1}}\cap\mathcal{P}(C)$ is nontrivial.
\end{enumerate}
Let $E$ denote the set of all such events.
We define a strict order on events by
$e\prec f \iff n_e<n_f$, where $n_e$ denotes the index of $e$
\end{definition}

\begin{definition}[Proper Time~\cite{misner1973}]
Let $E$ be the set of events generated by a distinguishability chain $P=\{P_n\}$. 
For any two events $a,b\in E$ with $a\prec b$, the \emph{proper time} between them is
\[
\tau(a,b)
=
\max\Bigl\{
\,|C|:\; C=\{c_0,\dots,c_k\}\subseteq E,\;
a=c_0\prec c_1\prec\cdots\prec c_k=b
\Bigr\}.
\]
That is, $\tau(a,b)$ is the cardinality of a maximal chain of strictly refinable
events between $a$ and $b$. Local finiteness of the distinguishability chain
guarantees $\tau(a,b)\in\mathbb{N}$.
\end{definition}

\begin{remark}
\label{rem:proper-time}
Proper time is not a geometric length. It is the number of admissible,
irreversible refinements separating two recorded events. Additional refinement
(higher resolution) may increase $\tau(a,b)$; coarse--graining cannot. Thus,
proper time is an \emph{invariant} of the partially ordered event record, not a metric
assumption.
\end{remark}

\begin{remark}
A chain need not include all events, and incomparable events do not contribute
to one another's proper time.  Only if every pair of events were comparable
would $\tau$ reduce to a total order.  In general, $E$ is only partially
ordered.  \NB{In physical terms, this corresponds to relativistic
simultaneity: incomparable events occupy disjoint causal domains and cannot
be ordered by any observer.}
\end{remark}


\begin{remark}[Smooth limit~\cite{riemann1854}]
If refinements become dense and the discrete extremal converges to a $C^2$
spline, then
\[
\lim_{\text{refinement}\to\infty} \tau(a,b)
=
\int_a^b \sqrt{-\,ds^2},
\]
the Lorentzian proper time. The integral form is not assumed; it is the smooth
shadow of the combinatorial count.
\end{remark}

The notion of \emph{uncorrelant events} formalizes the idea that two recorded
distinctions may be independent of one another.  In causal set theory,
incomparability under the causal order corresponds to physical independence
of events \cite{bombelli1987}.  The same conceptual separation appears in
quantum theory, where observables acting on independent subsystems commute
and their measurement outcomes do not influence each other
\cite{dirac1958,peres1995}.  Classical discussions of separated systems, from
Einstein--Podolsky--Rosen and Schr\"odinger to Wheeler's formulation of
complementarity \cite{einstein1935,schrodinger1935,wheeler1983}, frame the
same idea operationally: when no physical procedure can distinguish the
relative order of two events, their ordering has no empirical content.  The
definitions below captures this in the minimal set-theoretic language of the
causal poset.


\begin{definition}[Uncorrelant~\cite{bombelli1987,sorkin1991}]
\label{def:uncorrelant}
Let $(E,\prec)$ be a locally finite partially ordered set of events. Two
events $e,f\in E$ are said to be \emph{uncorrelant} if they are incomparable
under the causal order; that is,
\[
\neg(e\prec f)\quad\text{and}\quad \neg(f\prec e).
\]
The uncorrelant relation partitions $E$ into equivalence classes of events
whose relative order carries no operational consequence for any admissible
measurement or refinement.  In particular, no experimentally distinguishable
difference follows from interchanging the positions of uncorrelant events
in any linear extension of $(E,\prec)$.
\end{definition}

\begin{remark}
If $e$ and $f$ are uncorrelant, permuting them in any chain, merge, or
refinement does not change any observable invariant of the Causal Universe 
Tensor. No observer can construct a sequence of measurements that forces an 
ordering between $e$ and $f$ without introducing new events.
\end{remark}

\begin{remark}
\label{rem:refinement}
Correlant events may, but do not necessarily, admit a strict causal
precedence and therefore contribute to proper time along a chain;
uncorrelants do not.  In particular, a chain that includes $e$ but not
$f$ may be maximally refined without reference to $f$.  Thus,
uncorrelants represent \emph{informational independence}, not
simultaneity.
\end{remark}


\begin{remark}
In spacetime language, uncorrelants are precisely those event pairs that 
are spacelike--separated: reordering them changes no measurable scalar.
Here, this is not assumed from geometry; it is a consequence of 
incomparability in the event order.
\end{remark}

\begin{definition}[Causal Network]
\label{def:causal-network}
Let $E$ be a finite set of admissible events and let $\triangleright$ denote
the \emph{immediate causal cover}: $e \triangleright f$ if and only if $e < f$
and there exists no $g \in E$ such that $e < g < f$.  The \emph{causal network}
is the directed graph $(E, \triangleright)$ whose vertices are the events in
$E$ and whose directed edges record the immediate causal relations.
\end{definition}

This network is the combinatorial diagram of the event record: each vertex is
a distinguishable event, and each directed edge $e \triangleright f$ certifies
that $f$ cannot be observed without first observing $e$.  Its transitive
closure recovers the full causal order $<$ of Definition~\ref{def:causal-order}.


\begin{definition}[Causal Order~\cite{bombelli1987}]
\label{def:causal-order}
Let $P=\{P_n\}_{n\in\mathbb{Z}}$ be a distinguishability chain of partitions, and let an
event be $e=(B,\{B_i\}_{i\in I},n)$ as in Definition~\ref{def:event}, where $B\in\mathrm{Bl}(P_n)$ splits
nontrivially into child blocks $\{B_i\}\subset\mathrm{Bl}(P_{n+1})$.

For $m>n$ and $C\in\mathrm{Bl}(P_m)$, let $\pi_{m\to n}(C)\in\mathrm{Bl}(P_n)$ denote the unique
ancestor block in $P_n$ containing $C$ (well-defined because $P_{n+1}$ refines $P_n$).
Define the \emph{immediate causal cover} relation $e\triangleright f$ between events
$e=(B,\{B_i\},n)$ and $f=(C,\{C_j\},m)$ by
\[
n<m
\quad\text{and}\quad
\pi_{m\to n+1}(C)\subseteq B_i\ \text{for some child}\ B_i\ \text{created by } e.
\]
The \emph{causal order} $\prec$ on the event set $E$ is the transitive closure of
$\triangleright$:
\[
e\prec f \iff \text{there exist events } e=e_0,e_1,\dots,e_k=f \text{ with } e_i\triangleright e_{i+1}\ \text{for all }i.
\]
Then $(E,\prec)$ is a locally finite partially ordered set (reflexivity suppressed for strictness),
where incomparability is allowed: it may happen that neither $e\prec f$ nor $f\prec e$.
\end{definition}

As an illustration, recall the twin paradox of the previous chapter\footnote{See Coda: The Twin Paradox, Chapter 1.}.
In the informational gauge, proper time is not a geometric interval but the
work of reconciling distinguishable events.  The traveling twin accrues a
denser log of refinements---engine burns, course corrections, telemetry---while
the stay-at-home twin records a coarser sequence.  When their notebooks are
merged into a single coherent history, the richer record requires strictly
greater informational effort to reconcile.  Equivalently, the proper time of
the unaccelerated twin is necessarily longer, because her history contains
fewer distinctions and therefore a larger merge is required to absorb those
recorded by her sibling.  In the smooth limit this appears as a shorter
proper time along the curved worldline, but the effect is not mysterious:
it is the discrete fact that one history contains more recorded distinctions
than the other.  Geometry only codifies what measurement already certified.


\begin{remark}[Index is an order--embedding, not an equivalence]
If $e\prec f$, then $n_e<n_f$. Thus the refinement index provides a rank
function (Definition~\ref{def:rank-time}) that is \emph{monotone} with respect to $\prec$. The converse
need not hold: $n_e<n_f$ does not imply $e\prec f$. Hence the causal order
is generally \emph{partial}, not total.
\end{remark}

\begin{remark}[Uncorrelants and permutation invariance]
Events $e,f$ with neither $e\prec f$ nor $f\prec e$ are \emph{uncorrelant} (incomparable).
Permuting uncorrelant events in any linear extension of $(E,\prec)$ leaves all scalar
invariants of the Causal Universe Tensor unchanged; causal histories are unique only
up to permutation of uncorrelants.
\end{remark}

\subsection{Accumulation of Measurement}

Operationally, every observation can be decomposed into three layers:
\begin{enumerate}
  \item the \textbf{logical} layer---which events are distinguishable;
  \item the \textbf{mathematical} layer---how those distinctions are counted;
  \item the \textbf{physical} layer---how the resulting counts are named and
        parameterized as energy, momentum, or time.
\end{enumerate}
By isolating the first two layers, we obtain a calculus of variations that is universal
to any admissible physics: a closed system of relations that expresses how
order itself becomes measurable.


The framework that follows formalizes this intuition.  Within ZFC,
we construct an ordered set of events whose distinguishability relations
generate the causal ordering of special relativity.  Measurements are
counts of these relations, and the Causal Universe Tensor---the cumulative
left product of \emph{event tensors} over all causal increments---supplies
the discrete substrate from which the smooth laws of physics arise in the
limit of refinement.

The preceding axioms establish a measurement record as a locally finite,
partially ordered set of distinctions $(E,\prec)$.  This structure is
purely combinatorial.  To connect the logical record to physical
measurement, we require a representation that can carry numerical values
and allow recorded distinctions to combine.  A vector space $V$ provides a
domain for measurable quantities, but to represent successive distinctions
we also need a rule for composition.  The tensor algebra $\mathcal{T}(V)$
is the freest algebra generated by $V$: it contains $V$, supports
noncommutative products, and imposes no additional relations beyond those
required by linearity.  By associating each logical event $e_k$ with a
tensor $\mathbf{E}_k$ in $\mathcal{T}(V)$ we obtain an algebraic record of
distinctions that can be composed and accumulated.  This representation
introduces no structure beyond what is logically required to encode
measurable updates.


\begin{definition}[Event Tensor~\cite{golub2013}]
\label{def:eventtensor}
Let $V$ be a finite-dimensional real vector space of measurable quantities.
An event tensor $\mathbf{E}_k \in \mathcal{T}(V)$ encodes the
distinguishable contribution of the $k$th event $e_k \in E$ to the
cumulative record.  It is related to the logical event by a measurable
embedding
\begin{equation}
\Psi : E \to \mathcal{T}(V), \qquad \mathbf{E}_k = \Psi(e_k).
\end{equation}
No algebraic relations are assumed beyond those required by linearity:
$\mathbf{E}_k$ is simply the algebraic image of the $k$th logical
distinction.
\end{definition}

An individual event tensor records a single admissible refinement of the
measurement record.  To represent the cumulative effect of many events, we
must specify how these algebraic objects combine.  Because the causal set is
ordered only up to informational precedence, the combination rule must
respect a chosen linear extension of the partial order and must make no
assumptions of commutativity.  This leads naturally to a left--multiplicative
update: each new event contracts the admissible record of all that precede
it, and the cumulative history is represented by the product of these
restricted increments along any finite prefix of the causal chain.

The combination rule corresponds directly to the set--theoretic refinement
of admissible outcomes.  At each step, the new logical event is not taken in
isolation, but restricted against all prior observations:
\[
e_{k+1}' := e_{k+1} \cap \bigcap_{j=1}^{k} \hat{R}(e_j),
\]
where $\hat{R}$ is the operator that removes outcomes incompatible with the
existing record.  In this framework, the ``laws of physics'' appear nowhere
else: they are encoded entirely in the restriction operator.  What survives
admissibility is physical; what is removed was never a possible history.

In the
algebraic domain this restriction is represented by
\[
\mathbf{U}_{k+1}
:= \Psi(e_{k+1}')\,\mathbf{U}_k
= \Psi\!\bigl(e_{k+1} \cap \hat{R}(e_k)\bigr)\,\mathbf{U}_k,
\]
where $\Psi$ embeds the surviving distinctions into the tensor algebra.
Each new event therefore contracts the admissible history by left
multiplication.  The cumulative record is the product of these restricted
increments along any finite prefix of the causal chain.

Formally, the measurable embedding $\Psi$ sends the set--theoretic
restriction to a multiplicative update in the tensor algebra.  Instead of
embedding the raw event $e_{k+1}$, we embed only the portion that survives
all prior admissibility constraints:
\[
\mathbf{E}_{k+1}
=
\Psi\!\Bigl(
e_{k+1} \cap \bigcap_{j=1}^{k} \hat{R}(e_j)
\Bigr).
\]
Writing $\mathbf{R}(e) := \Psi(\hat{R}(e))$, the cumulative record evolves by
left multiplication:
\[
\mathbf{U}_{k+1}
=
\mathbf{R}(e_{k+1})\,\mathbf{U}_k
=
\Psi\!\bigl(e_{k+1} \cap \hat{R}(e_k)\bigr)\,\mathbf{U}_k,
\qquad 0 \le k < n.
\]
Thus the tensor update is the algebraic realization of the same logical
operation performed in $E$: a new event is applied only after its outcomes
have been restricted by all earlier observations.  The universe accumulates
consistency through products of restricted increments, not by additive
evolution.

\begin{definition}[Partition of the Event Set]
\label{def:partition}
Let $(E,\prec)$ be a locally finite partially ordered set of distinguishable
events.  A \emph{partition} of $E$ is a collection of disjoint subsets
$\{E_\alpha\}_{\alpha\in A}$ such that
\[
E = \bigcup_{\alpha\in A} E_\alpha,
\qquad
E_\alpha \cap E_\beta = \varnothing
\quad\text{for}\;\alpha\neq\beta.
\]
Each $E_\alpha$ is an informationally independent component: no event in
$E_\alpha$ refines or is refined by an event in $E_\beta$.  Correlant
events therefore lie within the same partition element, while uncorrelants
lie in distinct elements of the partition.
\end{definition}

\begin{definition}[Restriction Operator]
\label{def:restriction}
Let $(E,\prec)$ be a partially ordered set of events, and let
$e \in E$ be a newly recorded event.  The \emph{restriction operator}
\[
\hat{R}(e) : E \to E
\]
acts on the event record by removing any outcomes that are incompatible
with $e$.  For $f \in E$,
\[
\hat{R}(e)(f) =
\begin{cases}
f, & \text{if $f$ is admissible given $e$,} \\
\varnothing, & \text{otherwise.}
\end{cases}
\]
Equivalently, if $E_\alpha$ is the partition element containing $e$,
then
\[
\hat{R}(e)
\;:\; E_\alpha \mapsto E_\alpha',
\qquad
E_\alpha' = \{\,f \in E_\alpha \mid f \text{ is compatible with } e\,\}.
\]
Thus $\hat{R}(e)$ contracts the event domain by discarding outcomes that
contradict the new distinction.
\end{definition}

We now present the \emph{Causal Universe Tensor}.

\begin{proposition}[Causal Universe Tensor]
\label{prop:universe-tensor}
Let $(E,\prec)$ be a locally finite partially ordered set of events, and let
$\Psi : E \to \mathcal{T}(V)$ be the measurable embedding.  For each event
$e\in E$, define its admissible factor by
\[
\mathbf{F}(e) \;:=\; \Psi\!\big(\hat{R}(e)\big).
\]
Fix a finite linear extension $e_1 \prec \cdots \prec e_n$ of $(E,\prec)$ and
set $\mathbf{U}_0 := \mathbf{I}$ (the multiplicative identity in
$\mathcal{T}(V)$).  Define the left recursion
\begin{equation}
\label{eq:left-update}
\mathbf{U}_{k+1}
:= \mathbf{E}_{k+1} \,\mathbf{U}_k
= \Psi\!\big(e_{k+1} \cap \hat{R}(e_k)\big)\,\mathbf{U}_k,
\qquad 0 \le k < n,
\end{equation}
Then:
\begin{enumerate}
\item \emph{(Naturality of restriction)} The update \eqref{eq:left-update}
is precisely the expansion of the discrete restriction through the
representation: $\,\mathbf{F}(e)=\Psi(\hat{R}(e))\,$ so that
\[
\mathbf{U}_{k+1}
\;=\;
\Psi\!\big(\hat{R}(e_{k+1})\big)\,\mathbf{U}_k.
\]
Equivalently, $R\circ\Psi=\Psi\circ\hat{R}$ on ${\rm im}\,\Psi$.

\item \emph{(Causal uniqueness)} The recursion \eqref{eq:left-update} is
uniquely determined by the chosen linear extension.  Any two linear
extensions differ only by permutations of informationally independent
events (partition elements of $E$), so once the order is fixed the product
is mechanically well-defined.

\item \emph{(Independence under commuting factors)} If a subset
$S\subset\{1,\dots,n\}$ indexes events whose admissible factors pairwise
commute, $\mathbf{F}(e_i)\mathbf{F}(e_j)=\mathbf{F}(e_j)\mathbf{F}(e_i)$ for
$i,j\in S$, then any permutation of $\{\mathbf{F}(e_i)\}_{i\in S}$ leaves
$\mathbf{U}_n$ invariant under all cyclic scalar functionals (e.g., traces
of contractions).

\item \emph{(Fully commutative case)} If all admissible factors commute, then
\[
\mathbf{U}_n \;=\; \prod_{k=1}^{n} \mathbf{F}(e_k)
\]
is independent of the linear extension; the product reduces to the
order-insensitive accumulation of factors.
\end{enumerate}
\end{proposition}

\begin{proofsketch}
(1) By definition $\mathbf{F}(e)=\Psi(\hat{R}(e))$, so the left update is the
representation of the discrete restriction; this is $R\circ\Psi=\Psi\circ\hat{R}$
on ${\rm im}\,\Psi$. (2) Associativity of multiplication in $\mathcal{T}(V)$
gives well-definedness for a fixed order; linear extensions differ only by
swapping independent events. (3) and (4) follow from standard properties of
products with commuting factors and invariance of cyclic scalar functionals.
\end{proofsketch}



\begin{remark}[Ordinal determinacy]
The sequence $(\U_k)$ is not merely algebraically well-defined but \emph{physically ordered}:  
$k$ indexes ordinal rank, not arbitrary enumeration.  
Hence any reordering outside uncorrelant classes violates Axiom~\ref{ax:cantor}.
\end{remark}



With the ordinal structure of events established, we now formalize how these measurements combine algebraically within a finite vector space.


\subsection{Formal Structure of Event and Universe Tensors}
\label{se:formaluniverse}

We now specify the algebraic structure of the quantities introduced above.
Let $\V$ denote a finite--dimensional real vector space representing
the independent channels of measurable quantities (e.g.\ energy, momentum,
charge).  Define the tensor algebra~\cite{halmos1958,lang2002}
\begin{equation}
\label{eq:tensoralg}
\Talg = \bigoplus_{r=0}^\infty \V^{\otimes r},
\end{equation}
whose elements are finite sums of $r$--fold tensor products over $\mathbb{R}$.
Each \emph{event tensor} $E_k$ is a member of $\Talg$
encoding the distinguishable contribution of the $k$--th event to the global
state.  We write
\begin{equation}
\label{eq:eventalgebra}
\E_k \in \Talg, \qquad
\U_n = \prod_{k=1}^{n} \E_k \in \Talg).
\end{equation}
Addition is understood componentwise in the direct sum and preserves the
ordering of indices guaranteed by the Axiom of~Order~\cite{bombelli1987,halmos1958}.  In this setting the
``universe tensor'' $\U_n$ is the cumulative history of all event tensors up to
ordinal~$n$.

\begin{definition}[Tensor Algebra~\cite{golub2013}]\label{def:tensoralgebra}
The tensor algebra on a vector space $\V$ is
\[
\Talg=\bigoplus_{r=0}^{\infty}\V^{\otimes r}
\]
with componentwise addition and associative tensor product
\end{definition}


\begin{remark}
\label{rem:posetfrontier}
Each logical event $e_k$ in the partially ordered set $(E,\prec)$
induces a tensor $\E_k = \Psi(e_k)$ in $\Talg$.
The mapping $\Psi$ translates causal structure into algebraic contribution,
ensuring that causal precedence corresponds to index ordering in $\U_n$.
\end{remark}

Because $\Talg$ is a free associative algebra, all
operations on $\U_n$ are well defined using the standard linear maps,
contractions, and bilinear forms of~$\V$.  The subsequent analysis
of variation and measurement therefore proceeds entirely within conventional
linear--operator theory.

From the definition of the Universe Tensor
\begin{equation}
U_n = \prod_{k=1}^{n} E_k,
\end{equation}
we may regard an \emph{uncorrelant} as any subset of events whose local order can be permuted without altering the global scalar invariants of \(U_n\). 
Formally, a subset \(S \subseteq \{E_1, \ldots, E_n\}\) is uncorrelant if, for every permutation \(\pi\) of \(S\),
\begin{equation}
\prod_{E_i \in S} E_i = \prod_{E_i \in S} E_{\pi(i)}.
\end{equation}
In this case, all contractions or scalar traces derived from \(U_n\) remain unchanged by reordering the elements of \(S\), even though the operator sequence itself may differ.

\begin{definition}[Commutator and Commutator Ideal~\cite{dummit2004}]
Let $\mathcal{A}$ be an algebra over a field $\mathbb{F}$ with bilinear
multiplication $(x,y)\mapsto xy$.  For $x,y\in\mathcal{A}$, the
\emph{commutator} of $x$ and $y$ is the element
\[
[x,y] \;:=\; xy - yx \;\in\; \mathcal{A}.
\]
The set of all finite $\mathbb{F}$-linear combinations of commutators,
\[
[\mathcal{A},\mathcal{A}]
\;:=\;
\left\{\,\sum_{i=1}^{m}\alpha_i [x_i,y_i]
:\alpha_i\in\mathbb{F},\;x_i,y_i\in\mathcal{A}\,\right\},
\]
is called the \emph{commutator ideal}.  It is the smallest two-sided ideal
of $\mathcal{A}$ that contains every element $xy-yx$; equivalently, it is
the smallest linear subspace of $\mathcal{A}$ closed under left and right
multiplication by arbitrary elements of $\mathcal{A}$.
\end{definition}



\begin{remark}[Algebraic Characterization of Informational Independence]
\label{rem:uncorrelant-algebraic}
Let $\Psi : E \to \mathcal{T}(V)$ be the event embedding and
$\mathbf{E}_e := \Psi(e)$.  If $S \subseteq E$ lies in distinct elements of
the partition of $E$ (Definition~\ref{def:partition}), then the admissible
increments $\{\mathbf{E}_e\}_{e \in S}$ pairwise commute.  Consequently,
any reordering of these factors within a linear extension of $(E,\prec)$
produces the same value of $\mathbf{U}_n$ under all cyclic scalar
functionals (e.g., traces of contractions).  In this algebraic sense,
informational independence corresponds exactly to order-insensitive
contribution to the invariants derived from $\mathbf{U}$.
\end{remark}

\begin{example}[Non-commutative Event Pair~\cite{hawking1973}]
\NB{Non-commutative event tensors often signal a \emph{dependency}:
one update must precede the other for the restricted outcome set to
remain consistent.  Reversing such events changes the operator state,
even though measurable scalar invariants remain the same.}

Let $V=\mathbb{R}^2$ and let event tensors act as $2\times 2$ matrices
under the usual (non-commutative) multiplication.  Define
\[
E_A=\begin{pmatrix}1 & 1\\[4pt] 0 & 1\end{pmatrix},
\qquad
E_B=\begin{pmatrix}1 & 0\\[4pt] 1 & 1\end{pmatrix}.
\]
A direct computation gives
\[
E_AE_B=\begin{pmatrix}2 & 1\\[4pt] 1 & 1\end{pmatrix}
\;\neq\;
\begin{pmatrix}1 & 1\\[4pt] 1 & 2\end{pmatrix}=E_BE_A,
\quad\text{so } [E_A,E_B]\neq 0.
\]

Thus, applying the updates in different orders leads to different operator
states.  However, cyclic scalar invariants agree:
\[
\mathrm{tr}(E_AE_B)=\mathrm{tr}(E_BE_A)=3,
\qquad
\det(E_AE_B)=\det(E_A)\det(E_B)=1.
\]
In this sense, noncommutativity affects the internal operator record but
not the measurable quantities obtained by cyclic scalar functionals.
\end{example}


\begin{example}[Independent Event Chains~\cite{langevin1911}]
\NB{This is analogous to the inertial segment of the twin paradox.  During
coasting, neither twin exchanges signals with the other, so no event on one
worldline refines or restricts events on the other.  The two chains are
informationally independent until a causal interaction occurs.}

Consider two finite event chains
\[
A_1 \prec A_2,
\qquad
B_1 \prec B_2,
\]
with no causal relation between any $A_i$ and any $B_j$.  Let their event
tensors act on $V=\mathbb{R}^2$ as
\[
E_{A1}=\begin{pmatrix}1&0\\0&0\end{pmatrix},
\quad
E_{A2}=\begin{pmatrix}0&1\\0&0\end{pmatrix},
\qquad
E_{B1}=\begin{pmatrix}0&0\\1&0\end{pmatrix},
\quad
E_{B2}=\begin{pmatrix}0&0\\0&1\end{pmatrix}.
\]

Because the $A$-events refine only the $A$-chain and the $B$-events refine
only the $B$-chain, their admissible factors commute:
\[
E_{A2}E_{B2} = E_{B2}E_{A2}.
\]
Thus, any linear extension of the partial order may place the $A$- and $B$-
events in either interleaving without changing cyclic scalar invariants.  For
example, applying the four events in the order
\[
A_1,\, A_2,\, B_1,\, B_2
\quad\text{or}\quad
A_1,\, B_1,\, A_2,\, B_2
\]
gives operator states that differ, but
\[
\mathrm{tr}(E_{A2}E_{B2}) = \mathrm{tr}(E_{B2}E_{A2}) = 1,
\qquad
\det(E_{A2}E_{B2}) = \det(E_{B2}E_{A2}) = 0.
\]

This illustrates the algebraic meaning of independence: when two event chains
are partitioned into disjoint informational domains, their admissible
increments commute.  Order affects the internal operator record but leaves
measurable cyclic scalars unchanged, exactly as in the coasting phase of the
twin paradox.
\end{example}


\section{Information Minimality and Kolmogorov Closure}

The previous definitions describe events as finite distinctions and their
ordering as a partial refinement of information. What remains is the rule
that determines which extensions of a recorded event set are admissible.
Not every history consistent with the order is physically meaningful: a
completion that inserts unobserved structure would imply additional
measurements that never occurred. Information minimality formalizes this
constraint through algorithmic information theory in the sense of
Kolmogorov, Solomonoff, and Chaitin \cite{chaitin1975,kolmogorov1965,solomonoff1964a,
solomonoff1964b}.

We treat histories as finite symbolic strings and measure their descriptive
content by Kolmogorov complexity. A physically admissible history is one
that cannot be compressed by adding unrecorded structure.

\begin{definition}[Kolmogorov Complexity {\cite{kolmogorov1965,chaitin1975}}]
Fix a universal Turing machine $U$~\cite{turing1936}. For any finite string $w\in\Sigma^{*}$,
the Kolmogorov complexity $K(w)$ is the length of the shortest input to $U$
that outputs $w$ and halts. The functional $K:\Sigma^{*}\rightarrow\mathbb{N}$
is defined up to an additive constant independent of $w$.
\end{definition}

\begin{definition}[Admissible Extension {\cite{li1997}}]
Let $E=\{e_0\prec e_1\prec\cdots\prec e_n\}$ be the recorded events of an
experiment. A finite string $w\in\Sigma^{*}$ is an \emph{extension} of $E$
if its image under the event map contains $E$ in the same causal order.
An extension $w$ is \emph{admissible} if it introduces no additional events
beyond $E$; that is, every distinguishable update encoded by $w$ has a
corresponding element of $E$. Any extension predicting unobserved structure
is rejected as inadmissible.
\end{definition}

\begin{example}[Pathological Extension Without Event Selection~\cite{lewis1976}]
\NB{These sorts of pathologies can appear to look like paradoxes arising from
\emph{time travel}, \emph{remote viewing}, or other specious phenomena.}

Let $E = \{e_1, e_2, e_3, \dots\}$ be a locally finite causal chain where each
event $e_i$ has a unique successor $e_{i+1}$.  Define the corresponding universe
tensor
\begin{equation}
\U_n = \sum_{k=1}^{n} \E_k, \qquad \E_k=\mathbf\Psi_k(e_k).
\end{equation}
Now suppose we attempt to ``extend'' this history by splitting a single event
$e_j$ into uncountably many indistinguishable refinements:
\begin{equation}
e_j \longrightarrow \{e_{j,\alpha}\}_{\alpha \in [0,1]},
\end{equation}
each representing a formally distinct but observationally identical outcome.
Algebraically, this replacement yields
\begin{equation}
\E_j \longrightarrow \int_{0}^{1} \E_{j,\alpha}\, d\alpha,
\end{equation}
so that the next update becomes
\begin{equation}
\U_{n+1} = \U_n + \int_{0}^{1} \E_{j,\alpha}\, d\alpha.
\end{equation}

This ``extension'' violates the finiteness and distinguishability conditions
necessary for causal coherence:
\begin{enumerate}
\item The set $\{e_{j,\alpha}\}$ is uncountable, destroying local finiteness;
\item The new events are indistinguishable, so Extensionality no longer
      guarantees unique contributions;
\item The total tensor amplitude $U_{n+1}$ can diverge or cancel arbitrarily,
      depending on how the continuum of duplicates is treated.
\end{enumerate}

Operationally, this is a Banach--Tarski-like overcounting: the causal structure
has been ``refined'' in a way that preserves measure only formally while the
order relation collapses.  The observer would now predict contradictory
outcomes for the same antecedent state---an \emph{overcomplete history}.

To prevent this, the \emph{Axiom of Event Selection} restricts the permissible
extension to a countable, consistent refinement:
\begin{equation}
e_j \longrightarrow e_{j,1}, e_{j,2}, \dots, e_{j,k},
\end{equation}
and requires the selection of exactly one representative outcome from each
locally admissible family.  This keeps $E$ locally finite and maintains a
single-valued universe tensor,
\begin{equation}
\U_{n+1} = \U_n + \E_{j,k^\ast}.
\end{equation}
The axiom thus enforces the same regularity that Martin's Axiom guarantees in
set theory: every countable family of local choices admits a globally consistent
selection that preserves the partial order.
\end{example}


\begin{definition}[Information Minimality {\cite{kolmogorov1965,li1997}}]
Among all admissible extensions of $E$, the physically admissible history is
the one of minimal Kolmogorov complexity:
\[
w_{min}=\arg\min\{K(w): w\ \text{is an admissible extension of }E\}.
\]
\end{definition}

Information minimality expresses the logical content of measurement: if
additional curvature, oscillation, turning points, or discontinuities had
occurred between $e_i$ and $e_{i+1}$, those features would have generated
new events. Since no such events are present in $E$, any extension that
predicts them is inadmissible, and a shorter description exists.

\begin{remark}
This principle is purely set--theoretic. No geometry, metric, or
differential structure is assumed. Kolmogorov minimality selects the
shortest admissible description of the recorded distinctions and forbids
unobserved structure.
\end{remark}

\begin{remark}
As the resolution of measurement increases, the admissible extension forms
a Cauchy sequence~\cite{cauchy1821} in the space of symbolic descriptions. In the dense limit,
its smooth shadow is the unique spline that introduces no new structure
between recorded events. Thus the variational calculus is not imposed; it
is the continuum limit of Kolmogorov minimality.
\end{remark}

\subsection{Inadmissibility of Unobserved Structure}

Let $E=\{e_0\prec e_1\prec\cdots\prec e_n\}$ be the finite set of recorded
events produced by a measurement process. By Definition~\ref(def:measurement),
each event corresponds to a distinguishable update of state: a change that
crossed a detection threshold and became causally recorded.

Between two successive events $e_i$ and $e_{i+1}$, no additional events
were recorded. This absence is a data constraint: any refinement of the
history that introduces detectable structure---curvature, oscillation,
turning points, discontinuities, or other distinguishable phenomena---would
generate additional events. Since these events do not appear in $E$, any
history that predicts them is logically inconsistent with the observational
record.

\begin{definition}[Unobserved Structure]
Let $w$ be an admissible extension of $E$ (Definition~2.3.3). A symbolic
segment of $w$ between $e_i$ and $e_{i+1}$ contains \emph{unobserved
structure} if it encodes a distinguishable update that is not present in $E$.
\end{definition}

\section{Correlation and Dependency}

In conventional quantum mechanics the word ``entanglement’’ refers to a
non-classical dependency among amplitudes: indistinguishable histories are
combined before probabilities are assigned.  The present framework adopts a
similar intuition, but in a purely informational and algebraic form, with no
amplitudes and no functional dependencies.

Two events are \emph{uncorrelant} when no \emph{correlant} exists between them.
In this case, their transposition commutes with every admissible invariant
of the Universe Tensor, and the events may be represented independently.
Uncorrelant events are informationally separable: no refinement of the
record forces them to be treated jointly.

Two events are \emph{correlant} when they do not commute: exchanging them
changes at least one admissible invariant.  In this case a correlant
exists.  A correlant is an informational relation---the minimal structure
required when two events cannot be represented independently of one
another.  Importantly, a correlant does not specify direction or causation:
nothing is said about which event precedes, influences, or determines the
other.  It expresses only that the transposition fails to commute.

Uncorrelant events can become correlated when their light cones merge.
Before the merger, each event admits a representation that commutes with
the other; no correlant exists, and their histories may be transposed
without altering any admissible invariant.  After the merger, additional
distinctions become available, and the transposition may fail to commute.
A correlant then forms, not because one event generates the other, but
because the enlarged record no longer permits them to be represented
independently.

Dependency relations are stronger still.  A dependency asserts that one
event is determined by another, as in the functional relationships of the
classical calculus.  Such relations describe macro--events in conventional
dynamics, where causes generate effects.  The present work is not concerned
with dependency.  Correlation is the weaker structure: non-commutativity
under admissible permutation, with no claim of generation or determination.

Thus, ``entanglement'' in the conventional quantum sense has two
informational analogues in this framework.  When amplitudes combine as
indistinguishable histories, the result is a superposition.  When events
cannot be transposed without altering admissible invariants, the result is
a correlant.  Both are consequences of the same principle: distinctions
cannot be manufactured retroactively.  What differs is the level at which
indistinguishability occurs---the discrete record of events or the smooth
representation of extremals.


\begin{example}[Spooky Action at a Distance~\cite{bell1964,einstein1935,sorkin2005}]
\label{ex:spooky}
Consider an uncorrelant $S = \{ \E_i, \E_j \}$ of two
spatially separated measurement events.  
By definition, the order of $\E_i$ and $\E_j$ may be permuted
without changing any invariant scalar of the universe tensor:
\begin{equation}
\label{eq:spooky}
\E_i \E_j = \E_j \E_i.
\end{equation}
When an observer records $\E_i$, the global ordering is fixed, and the
universe tensor is updated accordingly.  
Because $\E_j$ belongs to the same uncorrelant set, its contribution
is now determined consistently with $\E_i$, even if $E_j$
occurs at a spacelike separation.  
This manifests as the phenomenon of ``spooky action at a distance''---the
appearance of instantaneous correlation due to reassociation within the
uncorrelant subset.
\end{example}

\begin{example}[Hawking Radiation~\cite{hawking1975,unruh1976}]
\label{ex:hawking}
Let $\E_\text{in}$ and $\E_\text{out}$ denote the pair of
particle-creation events near a black hole horizon.  
These events form an uncorrelant set:
\begin{equation}
\label{eq:hawking}
S = \{ \E_\text{in}, \E_\text{out} \}.
\end{equation}
As long as both remain unmeasured, their contributions may permute freely within
the universe tensor, preserving scalar invariants.  
However, once $\E_\text{out}$ is measured by an observer at infinity,
the ordering is fixed, and $\E_\text{in}$ is forced to a complementary
state inside the horizon.  
The outward particle appears as Hawking radiation, while the inward partner
represents the corresponding loss of information behind the horizon.  
Thus Hawking radiation is naturally expressed as an uncorrelant whose collapse
into correlation occurs asymmetrically across a causal boundary.
\end{example}



\begin{coda}{Achilles and the Tortoise}
\NB{For a rich treatment of this paradox, see Hofstadter~\cite{hofstadter1979}.}
Zeno’s paradox of Achilles and the tortoise~\cite{plato1996} is one of the oldest arguments
against the possibility of motion. Achilles, swift of foot, gives a tortoise
a small head start. Because the tortoise begins ahead, Achilles must first
reach the tortoise’s initial position. By that time, the tortoise has advanced
a little farther; Achilles must then reach that new position, and by the time
he arrives, the tortoise has advanced again, and so on without end. Zeno’s
conclusion is that Achilles can never overtake the tortoise, for he must
complete an infinite sequence of tasks to do so.

Formally, one can express the argument in familiar modern notation. Suppose
the tortoise begins one unit ahead. Achilles covers half the remaining
distance on his first stride, then half of what remains on the next stride,
then half again, producing the well-known geometric series
\[
1 = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + \cdots .
\]
More generally, one may express the same identity as
\[
1 = \sum_{n=1}^{\infty} \frac{1}{2^{\,n}}.
\]
Zeno’s reasoning is now captured in a single line: if Achilles must perform
an infinite number of sub-journeys to reach the tortoise, and if completing
infinitely many tasks requires infinite time, then Achilles never arrives.

The mathematics appears to sharpen the paradox. The right-hand side contains
infinitely many terms, and yet their sum is finite. An infinite decomposition
and a finite limit uneasily coexist. From a purely symbolic viewpoint, Zeno
is correct: the path to the finish line can be written as a countable infinity
of smaller and smaller segments. Nothing in the algebra forbids infinitely
many subdivisions of the interval.

The difficulty lies not in the mathematics, but in the hidden assumption that
every subdivision corresponds to a physically meaningful event. Zeno imagines
that the runner physically performs each of these infinitesimal subpaths, as
though each term in the series corresponds to an actual step. In reality, the
decomposition exists only on paper. It is an artifact of representation, not
an element of the physical world.

In the information gauge, motion is not defined by a continuous geometric
parameter, but by the accumulation of admissible distinctions---measurable,
irreversible updates of state. A notebook of observations does not record
symbolic halvings of distance; it records physical events that are detectable
by an instrument. Proper time is not the integral of infinitesimal steps, but
the count of such admissible distinctions.

Viewed in this light, the identity
\[
1 = \sum_{n=1}^{\infty} \frac{1}{2^{\,n}}
\]
does not imply that Achilles performs infinitely many physical actions. It
states only that a continuous model permits infinitely many subdivisions,
should one choose to write them down. The infinite chain is a mathematical
convenience, not a physical ledger.

The resolution is found in precision. Achilles does not detect every possible
subinterval of his path; no instrument possesses infinite resolving power. His
step length, his stride cadence, and the sensor that records his position
determine a finite resolution. If the act of stepping advances him by
$10^{-2}$ units, there are at most $100$ admissible distinctions in a one-unit
race. Even if the instrumentation resolves position to $10^{-6}$ units, the
notebook contains no more than one million recorded distinctions. Once this
finite notebook is reconciled, Achilles is at the finish line. The race
consumes a finite count of admissible distinctions because the physical
process does not instantiate an actual infinity of subevents.

Zeno’s paradox relies on treating every symbolic refinement of the interval
as physically real. The information gauge rejects that assumption. A
measurement records only what can be stably distinguished. Achilles’s
``infinite'' steps are not steps at all; they are possible refinements of a
mathematical model. Precision is the gatekeeper. The paradox dissolves when
we recall that Achilles’s motion is measured, not imagined, and that every
measurement has finite resolution. Refinement does not create motion; it
reveals it.

\end{coda}

