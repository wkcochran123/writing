\chapter{The Calculus of Measurement}
\section{Introduction}
\label{se:measurement_intro}

Every physical description begins not with space or time, but with an \emph{event}---an 
interaction that makes previously indistinguishable outcomes distinct~\cite{boltzmann1872, planck1914}.  
The causal boundary of such an interaction is its \emph{light cone}: the set of all 
events that can influence or be influenced by it according to special relativity~\cite{einstein1905, minkowski1908}.
The intersection of two light cones, corresponding to the last particle--wave interaction 
accessible to an observer, defines the maximal region of causal closure~\cite{hawking1973, penrose1972}.  
Beyond this surface, no additional information can be exchanged; all distinguishable action has concluded.


It is from this closure that the ordering of events arises~\cite{hawking1973, malament1977}.  Each 
measurable interaction contributes one additional distinction to the universe, expanding its causal 
surface by a finite count~\cite{hawking1973, malament1977}.  The smooth fabric of spacetime is not 
primitive but emergent: it is the limiting behavior of discrete causal increments accumulated along 
the light cone~\cite{bombelli1987, sorkin1991}.  Within each cone, the universe can be represented 
by a finite tensor of interactions---local updates to a global state---that together approximate 
continuity only through cancellation across countable events~\cite{bombelli1987, sorkin2003}.

Special relativity provides the canonical local model for this causal structure~\cite{einstein1905}.  
Consider the Lorentz transformation for a boost of velocity $v$ in one spatial dimension,~\cite{einstein1905,rindler2006,taylor1992}
\begin{equation}
\label{eq:lorentz}
\begin{pmatrix}
t' \\ x'
\end{pmatrix}
=
\begin{pmatrix}
\gamma & -\gamma v/c^{2} \\
-\gamma v & \gamma
\end{pmatrix}
\begin{pmatrix}
t \\ x
\end{pmatrix},
\qquad \gamma = \frac{1}{\sqrt{1 - v^{2}/c^{2}}}.
\end{equation}
For infinitesimal separations satisfying \(x = ct\), the Lorentz transformation gives
\begin{equation}
t' = \gamma\, t (1 - v/c).
\end{equation}
If we take \(\Delta t = 1\) as the unit interval between distinguishable events,
then observers moving at relative velocity \(v\) will, in general, disagree on the
\emph{number} of such events that occur between two intersections of their respective
light cones~\cite{minkowski1908}.  The only invariant quantity is the causal ordering itself:
all observers concur on which event precedes which, even though they may count
a different number of intermediate ticks~\cite{malament1977}.

\newglossaryentry{ranktime}{
  name={rank time},
  description={Order-embedding $\tau:E\to \text{Ord}$ assigning an ordinal rank to each event in a locally finite poset},
  symbol={\tau},
  sort=ranktime
}

\begin{definition}[Rank time~\cite{bombelli1987,davey2002}]\label{def:rank-time}
Let $(E,\preceq)$ be a locally finite \emph{partially ordered set of events}. A \gls{ranktime} is an order-embedding
\[
\tau : E \to \mathrm{Ord}
\]
satisfying $e \prec f \implies \tau(e) < \tau(f)$. Local finiteness implies that for any observer's causal domain $D \subseteq E$, $\tau(D)$ is order-isomorphic to an initial segment of $\mathbb{N}$. We therefore define the \emph{duration}, $|\delta t|$, between anchors $a \prec b$ by
\[
|\delta t|(a,b) \;=\; \#\{\, e \in E \mid a \prec e \prec b \,\}\in \mathbb{N}.
\]
Two rank functions $\tau,\tau'$ are \emph{equivalent} if there exists an order-isomorphism $\phi$ with $\tau'=\phi\circ\tau$; equivalent ranks yield identical durations.
\end{definition}


\begin{remark}[Operational content of time]
Time is an ordinal rank on $E$, not an independent scalar field. All subsequent uses of ``$t$'' refer to an order-equivalence class of rank functions as in Definition~\ref{def:rank-time}. The additivity $|\delta t|(a,b)=|\delta t|(a,c)+|\delta t|(c,b)$ follows from local finiteness.
\end{remark}

This observation motivates the first physical axiom: that time is not an independent scalar field but an ordinal index over causally distinguishable events.  Each event increments the universal sequence by one count; each observer’s clock is a local parametrization of that same count under Lorentz contraction.  The apparent continuity of time is the result of the density of such events within the causal cone, not an underlying continuum of duration.

\subsection{On the Structure of Measurement}

This work does not propose new physical phenomena or reinterpret existing
experimental data.  Rather, it reformulates how measurable quantities are
represented and reduces the number of degrees of freedom needed to describe
the universe to a single parameter that can be curve–fit.
\begin{example}[Planck's Constant as a Dimensional Anchor {\cite{planck1901}}]
Imagine a hypothetical measuring apparatus that records distinctions not by counting particles or intervals, but by tallying \emph{acts of discernment}—each act adding one quantum of distinguishability to the record. Suppose further that the calibration of such a device required only a single fixed scale to relate discrete counts to continuous units of measure. In physics, Planck’s constant $h$ serves precisely this purpose: it is not a force or an energy, but a bookkeeping factor that ensures continuity between discrete and continuous domains.

In the present framework, the analogous constant plays no physical role—it merely fixes the \emph{dimensional scale} by which finite distinctions are rendered comparable. The constant’s existence affirms that measurement can be both discrete and metrically consistent without invoking any specific quantum postulate. As with $h$, the constant here is not discovered but \emph{defined}: a normalization that preserves coherence between counting and continuity.
\end{example}


The analysis concerns only the \emph{structure of measurement itself}:
the mathematical relations among counts of distinguishable events that
underlie all physical observations.  In this framing, physics is viewed
as a grammar of distinctions.  The familiar constants and fields---mass,
charge, curvature, temperature---arise as \emph{derived measures} within a
finite causal order, not as independent entities.

\begin{example}[Measurement as a BNF Grammar~\cite{backus1959,naur1963}]
\label{ex:bnf-measurement}
Because measurement produces distinguishable outcomes, each observation
selects a symbol from a finite or countable alphabet
\[
\Sigma = \{\sigma_1, \sigma_2, \ldots \}.
\]
A record of $n$ measurements is therefore a word $w \in \Sigma^n$.  When
an instrument is refined—by increasing precision or reducing noise—any
coarse symbol $\sigma_k$ may be replaced by a finite set of more precise
symbols,
\[
\sigma_k \;\Rightarrow\; \sigma_{k,1} \;\big|\; \sigma_{k,2} \;\big|\;
\cdots \;\big|\; \sigma_{k,r},
\]
just as in a Backus--Naur Form (BNF) production rule
\cite{backus1959,naur1963}.  Not all replacements are admissible: they
must remain compatible with every other measurement that overlaps in
time or causal order.  Two refined histories that disagree on an
overlapping interval cannot both represent valid records.

Thus admissible measurement histories form a formal language generated by
the allowed refinement rules.  The ``law'' governing measurement is the
constraint that only globally consistent extensions of a record may be
generated.  This is not an analogy: it is the standard formal structure
of symbol sequences in coding and information theory \cite{sipser1997}.
\end{example}


No new particles, forces, or cosmological effects are introduced; only the
rules by which such effects are numerically expressed are examined.
Hence the present theory is not a revision of physics but a clarification
of its syntax: it studies the measures of phenomena, not the phenomena
themselves.

\newglossaryentry{distinguishabilitychain}{
  name={distinguishability chain},
  description={A sequence $\mathcal{P} = \{P_n\}$ of finite partitions of an observational domain,
  where each $P_{n+1}$ strictly refines $P_n$},
  sort=distinguishabilitychain
}

\begin{definition}[Distinguishability Chain~\cite{kolmogorov1933}]
Let $\Omega$ be a nonempty set.
A \gls{distinguishabilitychain} on $\Omega$ is a sequence
$\mathcal{P}=\{P_n\}_{n\in\mathbb{Z}}$ of partitions $P_n\in\Part(\Omega)$ such that
$P_{n+1}$ \emph{refines} $P_n$ for all $n$ (every block of $P_{n+1}$ is contained in a block of $P_n$).
Write $\Blocks{P}$ for the set of blocks of a partition $P$
Each refinement step produces zero or more \glspl{event}.
\end{definition}

\newglossaryentry{event}{
  name={event},
  description={A minimal refinement step in a distinguishability chain $\mathcal{P}=\{P_n\}$, represented by a pair $(B,\{B_i\}_{i\in I},n)$ where a block $B\in\Blocks{P_n}$ splits into a family of subblocks $\{B_i\}\subseteq\Blocks{P_{n+1}}$ with $|I|\ge2$},
  sort=event
}

\begin{definition}[Event~\cite{kolmogorov1933,sorkin2005}]\label{def:event}
Fix a \gls{distinguishabilitychain} $\mathcal{P}=\{P_n\}$.
An \gls{event} at index $n$ is a minimal refinement step:
a pair
\begin{equation}
\label{eq:eventdef}
e=(B,\{B_i\}_{i\in I},n)
\end{equation}
such that:
\begin{enumerate}
  \item $B\in\Blocks{P_n}$;
  \item $\{B_i\}_{i\in I}\subseteq \Blocks{P_{n+1}}$ is the family of all blocks of $P_{n+1}$ contained in $B$,
        with $|I|\ge2$ (a nontrivial split);
  \item (\emph{minimality}) there is no proper subblock $C\subsetneq B$ with $C\in\Blocks{P_n}$ for which
        the family $\Blocks{P_{n+1}}\cap\mathcal{P}(C)$ is nontrivial.
\end{enumerate}
Let $E$ denote the set of all such events.
We define a strict order on events by
$e\prec f \iff n_e<n_f$, where $n_e$ denotes the index of $e$
\end{definition}

\begin{definition}[Proper Time~\cite{misner1973}]
Let $E$ be the set of events generated by a distinguishability chain $P=\{P_n\}$. 
For any two events $a,b\in E$ with $a\prec b$, the \emph{proper time} between them is
\[
\tau(a,b)
=
\max\Bigl\{
\,|C|:\; C=\{c_0,\dots,c_k\}\subseteq E,\;
a=c_0\prec c_1\prec\cdots\prec c_k=b
\Bigr\}.
\]
That is, $\tau(a,b)$ is the cardinality of a maximal chain of strictly refinable
events between $a$ and $b$. Local finiteness of the distinguishability chain
guarantees $\tau(a,b)\in\mathbb{N}$.
\end{definition}

\begin{remark}
\label{rem:proper-time}
Proper time is not a geometric length. It is the number of admissible,
irreversible refinements separating two recorded events. Additional refinement
(higher resolution) may increase $\tau(a,b)$; coarse--graining cannot. Thus,
proper time is an invariant of the partially ordered event record, not a metric
assumption.
\end{remark}

\begin{remark}
A chain need not include all events, and incomparable events do not contribute
to one another's proper time. Only if every pair of events were comparable would
$\tau$ reduce to a total order. In general, $E$ is only partially ordered.
\end{remark}

\begin{remark}[Smooth limit~\cite{riemann1854}]
If refinements become dense and the discrete extremal converges to a $C^2$
spline, then
\[
\lim_{\text{refinement}\to\infty} \tau(a,b)
=
\int_a^b \sqrt{-\,ds^2},
\]
the Lorentzian proper time. The integral form is not assumed; it is the smooth
shadow of the combinatorial count.
\end{remark}

The notion of \emph{uncorrelant events} formalizes the idea that two recorded
distinctions may be independent of one another.  In causal set theory,
incomparability under the causal order corresponds to physical independence
of events \cite{bombelli1987}.  The same conceptual separation appears in
quantum theory, where observables acting on independent subsystems commute
and their measurement outcomes do not influence each other
\cite{dirac1958,peres1995}.  Classical discussions of separated systems, from
Einstein--Podolsky--Rosen and Schr\"odinger to Wheeler's formulation of
complementarity \cite{einstein1935,schrodinger1935,wheeler1983}, frame the
same idea operationally: when no physical procedure can distinguish the
relative order of two events, their ordering has no empirical content.  The
definition below captures this in the minimal set-theoretic language of the
causal poset.


\begin{definition}[Uncorrelant~\cite{bombelli1987,sorkin1991}]
\label{def:uncorrelant}
Let $(E,\prec)$ be a locally finite partially ordered set of events. Two
events $e,f\in E$ are said to be \emph{uncorrelant} if they are incomparable
under the causal order; that is,
\[
\neg(e\prec f)\quad\text{and}\quad \neg(f\prec e).
\]
The uncorrelant relation partitions $E$ into equivalence classes of events
whose relative order carries no operational consequence for any admissible
measurement or refinement.  In particular, no experimentally distinguishable
difference follows from interchanging the positions of uncorrelant events
in any linear extension of $(E,\prec)$.
\end{definition}

\begin{remark}
\label{rem:refinement}
If $e$ and $f$ are uncorrelant, permuting them in any chain, merge, or
refinement does not change any observable invariant of the Causal Universe 
Tensor. No observer can construct a sequence of measurements that forces an 
ordering between $e$ and $f$ without introducing new events.
\end{remark}

\begin{remark}
Correlatant events admit a strict causal relation and therefore contribute
to proper time; uncorrelants do not. In particular, a chain that includes 
$e$ but not $f$ may be maximally refined without reference to $f$.
Thus, uncorrelants represent informational independence, not simultaneity.
\end{remark}

\begin{remark}
In spacetime language, uncorrelants are precisely those event pairs that 
are spacelike--separated: reordering them changes no measurable scalar.
Here this is not assumed from geometry; it is a consequence of 
incomparability in the event order.
\end{remark}

\begin{definition}[Causal Order~\cite{bombelli1987}]
Let $P=\{P_n\}_{n\in\mathbb{Z}}$ be a distinguishability chain of partitions, and let an
event be $e=(B,\{B_i\}_{i\in I},n)$ as in Definition~3, where $B\in\mathrm{Bl}(P_n)$ splits
nontrivially into child blocks $\{B_i\}\subset\mathrm{Bl}(P_{n+1})$.

For $m>n$ and $C\in\mathrm{Bl}(P_m)$, let $\pi_{m\to n}(C)\in\mathrm{Bl}(P_n)$ denote the unique
ancestor block in $P_n$ containing $C$ (well-defined because $P_{n+1}$ refines $P_n$).
Define the \emph{immediate causal cover} relation $e\triangleright f$ between events
$e=(B,\{B_i\},n)$ and $f=(C,\{C_j\},m)$ by
\[
n<m
\quad\text{and}\quad
\pi_{m\to n+1}(C)\subseteq B_i\ \text{for some child}\ B_i\ \text{created by } e.
\]
The \emph{causal order} $\prec$ on the event set $E$ is the transitive closure of
$\triangleright$:
\[
e\prec f \iff \text{there exist events } e=e_0,e_1,\dots,e_k=f \text{ with } e_i\triangleright e_{i+1}\ \text{for all }i.
\]
Then $(E,\prec)$ is a locally finite partially ordered set (reflexivity suppressed for strictness),
where incomparability is allowed: it may happen that neither $e\prec f$ nor $f\prec e$.
\end{definition}

\begin{remark}[Index is an order--embedding, not an equivalence]
If $e\prec f$, then $n_e<n_f$. Thus the refinement index provides a rank
function (Definition~1) that is \emph{monotone} with respect to $\prec$. The converse
need not hold: $n_e<n_f$ does not imply $e\prec f$. Hence the causal order
is generally \emph{partial}, not total.
\end{remark}

\begin{remark}[Uncorrelants and permutation invariance]
Events $e,f$ with neither $e\prec f$ nor $f\prec e$ are \emph{uncorrelant} (incomparable).
Permuting uncorrelant events in any linear extension of $(E,\prec)$ leaves all scalar
invariants of the Causal Universe Tensor unchanged; causal histories are unique only
up to permutation of uncorrelants.
\end{remark}

\newglossaryentry{poset}{
  name={partially ordered set},
  description={A pair $(E,\leq)$ where $\leq$ is a binary relation on $E$ that is reflexive, antisymmetric, and transitive},
  sort=poset
}

\begin{definition}[Partially Ordered Set~\cite{davey2002}]\label{def:poset}
A \gls{poset} is a pair $(E,\leq)$ where $\leq$ is a binary relation on $E$ satisfying:
\begin{enumerate}
  \item \textbf{Reflexivity:} $e \leq e$ for all $e \in E$
  \item \textbf{Antisymmetry:} if $e \leq f$ and $f \leq e$, then $e = f$
  \item \textbf{Transitivity:} if $e \leq f$ and $f \leq g$, then $e \leq g$
\end{enumerate}
\end{definition}




Operationally, every observation can be decomposed into three layers:
\begin{enumerate}
  \item the \textbf{logical} layer---which events are distinguishable;
  \item the \textbf{mathematical} layer---how those distinctions are counted;
  \item the \textbf{physical} layer---how the resulting counts are named and
        parameterized as energy, momentum, or time.
\end{enumerate}
By isolating the first two layers, we obtain a calculus that is universal
to any admissible physics: a closed system of relations that expresses how
order itself becomes measurable.


The framework that follows formalizes this intuition.  The axioms of 
Zermelo--Fraenkel set theory with the Axiom of Choice, we construct an 
ordered set of events whose distinguishability relations reproduce the 
causal order implied by special relativity.  Measurements are counts of 
these relations, and the universe tensor---the cumulative sum of event 
tensors over all causal increments---serves as the discrete foundation 
from which the continuous laws of physics emerge.

\paragraph{Historical context.}
A measurement is defined operationally as the count of distinguishable
events between two anchors---the minimal act of drawing a distinction
in a finite causal order.  This definition echoes Boltzmann's use of
distinguishable microstates as the foundation of entropy
\cite{boltzmann1872}, Planck's quantization of action
\cite{planck1901}, and Wheeler's dictum that "it from bit"
\cite{wheeler1990}, but is here formalized as an axiom of order rather
than an empirical postulate.

\section{The Axioms of Mathematics}
\label{se:mathaxiom}

All mathematics in this work is carried out within the framework of
Zermelo–Fraenkel set theory with the Axiom of Choice (ZFC)~\cite{jech2003,kunen1980}.
Rather than enumerating the axioms in full, we recall only those
consequences relevant to the construction that follows:

\begin{itemize}
  \item \textbf{Extensionality} ensures that distinguishability has formal
  meaning: two sets differ if and only if their elements differ.
  \item \textbf{Replacement} and \textbf{Separation} guarantee that
  recursively generated collections such as the causal chain of events
  remain sets.
  \item \textbf{Choice} permits well–ordering, allowing every countable
  causal domain to admit an ordinal index.
\end{itemize}

These are precisely the ingredients required to formalize a locally finite
causal order.
All further constructions---relations, tensors, and operators---are definable
within standard ZFC mathematics; see Kunen~\cite{kunen1980} and Jech~\cite{jech2003}
for set-theoretic foundations, and Halmos~\cite{halmos1958,halmos1974naive} for the
induced tensor and operator structures on finite-dimensional vector spaces.

The starting point of this framework is methodological rather than
ontological.  We do not assume anything about the substance of physical
reality.  We assume only that the outcomes of measurement are finite or
countable collections of distinguishable results recorded in time.
This is standard across probability theory and information theory:
Shannon formalized information as distinguishable symbols drawn from a
finite or countable alphabet \cite{shannon1948}, and Kolmogorov showed
that empirical outcomes can be represented as elements of measurable
sets within standard set theory \cite{kolmogorov1933}.  In this view,
measurement produces data, and data are mathematical objects.
Everything that follows concerns the admissible transformations among
such records.

\begin{axiom}[The Axiom of Kolmogorov: Measurement as a Formal Record~\cite{kolmogorov1933}]
\label{ax:kolmogorov}
The record of measurement---defined as the finite or countable set of
observed, distinguishable events---is taken to be a mathematical object
representable within Zermelo--Fraenkel set theory with Choice (ZFC). No
ontological claim is made about physical reality. The axiom asserts only
that observable data can be formalized as sets and relations.

This standpoint is consistent with Kolmogorov's construction of probability
spaces, in which empirical outcomes are represented as measurable sets
\cite{kolmogorov1965}. Accordingly, a record of finite observations is a
mathematical object whose structure is defined entirely within ZFC. Throughout
this work, the word ``information'' refers exclusively to these representable
distinctions; nothing is asserted about any underlying physical substrate
that might produce them.
\end{axiom}



\begin{axiom}[The Axiom of Peano: Counting as the Tool of Information~\cite{fraenkel1922,kunen1980,zermelo1908}]
\label{ax:peano}
All reasoning in this work is confined to the framework of
Zermelo--Fraenkel set theory with the Axiom of Choice (ZFC).
Every object---sets, relations, functions, and tensors---is
constructible within that system, and every statement is interpretable
as a theorem or definition of ZFC.  No additional logical principles
are assumed beyond those required for standard analysis and algebra.

Formally,
\[
\mathrm{Measurement} \;\subseteq\; \mathrm{Mathematics} \;\subseteq\; \mathrm{ZFC}.
\]
Thus, the language of mathematics is taken to be the entire ontology of
the theory: the physical statements that follow are expressions of
relationships among countable sets of distinguishable events, each
derivable within ordinary mathematical logic.
\end{axiom}

\begin{example}[The Speedometer~\cite{warner1902,yoshida1980}]
\NB{The mechanical implementation of measuring devices often are protected
by explicit descriptions of how they work. The patents cited here explicitly
describe how they turn counting into data.}

Consider an ordinary automobile speedometer.  The dial appears to report a
continuous real number at each instant, but the device does not have access
to the real numbers.  A mechanical speedometer counts wheel rotations through
a gear train and maps those counts to pointer positions.  A digital
speedometer counts the same rotations and displays a numeral drawn from a
finite alphabet.

Each time the counter increments and the displayed symbol or pointer position
changes, a new distinguishable event is recorded.  Between two successive
display states there is no way, from the informational record alone, to assert
that any additional state occurred.  The apparent continuity of ``speed'' is a
visual interpolation of a finite counting process.

Thus the speedometer does not output a real number.  It outputs a countable
sequence of distinguishable states derived from integral counts of wheel
rotations.  The act of measuring speed reduces to counting transitions of a
finite-state device.  All physical inference based on such data can be
expressed within ordinary arithmetic and set theory.

This illustrates Axiom~\ref{ax:peano}: measurement generates only countable,
finitely coded distinctions, and every mathematical object used to interpret
those distinctions---numbers, functions, tensors---is a construct of ZFC.
No structure beyond counting is assumed at the fundamental informational
level.
\end{example}


\section{The Axioms of Information}

The previous chapter established that a physical record is a set of
distinguishable observations, representable within ZFC, and partially ordered
by causal precedence. Nothing further was assumed about geometry, dynamics, or
the continuum. In this section, we introduce two informational axioms that
restrict how such a record may be interpreted. These axioms express constraints
on admissible descriptions of the world, independent of any particular model
of physics.

The first axiom formalizes the principle that a physical history may not
contain unobserved structure. Among all symbolic descriptions that reproduce
the recorded events, the admissible one is the shortest. This is the
information--theoretic form of Occam's principle: no plurality of assumptions
without necessity.

The second axiom asserts that the record of events is not merely ordered but
forms a locally finite causal set. Local finiteness ensures that causal volume
is discrete, while the partial order encodes temporal precedence. Continuum
spacetime, when it exists, is therefore understood as an approximation that
faithfully embeds this discrete informational structure.

Together, these axioms define the informational content of the physical world:
a causal set with no unrecorded structure and no additional assumptions beyond
the observational record itself.

\subsection{Information Minimality}

The observational record $E$ is defined only by the distinguishable events it
contains. Between two recorded events $e_i$ and $e_{i+1}$, no additional
structure is present in the data: no new marks in the notebook, no threshold
crossings, and no observable distinctions. Set theory alone does not forbid a
hypothetical refinement that inserts additional structure between $e_i$ and
$e_{i+1}$, but any such refinement asserts observations that did not occur.
To prevent unrecorded structure from being introduced by assumption, we impose
an informational constraint.

Among all symbolic descriptions that reproduce the recorded events, the
admissible one is the shortest. In modern information theory, this statement
is formalized by Kolmogorov complexity: a description is preferred if it
introduces no additional information beyond the events in $E$. This embodies
the classical principle that no plurality of assumptions should be posited
without necessity. It is not derived from the set-theoretic framework; it is
an axiom about how physical theories must interpret finite empirical records.


\begin{axiom}[The Axiom of Ockham: Informational Minimality~\cite{ockham1323})]
\label{ax:ockham}
Let $E=\{e_0\prec e_1\prec\cdots\prec e_n\}$ be the recorded events of an
experiment, understood as a finite or countable set of distinguishable
observations representable in ZFC. Among all symbolic descriptions that map
to $E$ and introduce no additional recorded events, the admissible completion
is the one of minimal Kolmogorov complexity.

Equivalently, if a hypothetical refinement of the history introduces a
distinguishable update that is not present in $E$, then that refinement is
inadmissible. Any shorter description consistent with $E$ is preferred.
\end{axiom}

We have seen this principle in action already.  Refer to Thought 
Experiment~\ref{te:invisible-curve} and the use of Simpson's rule to
compute the path of a spaceship with minimal measurement information.

\subsection{Causal Set Theory}
The previous axiom imposed an informational constraint on admissible
descriptions of the record of measurement. We now introduce a structural
constraint. The empirical record is a set of distinguishable events with a
causal precedence relation $\prec$, but this alone does not restrict the size
of causal intervals. In a general partially ordered set, the number of events
between $a$ and $b$ may be infinite. Physical measurements, however, produce
finite data. To represent this empirically grounded discreteness, we assume
that the causal order is locally finite: every causal interval contains only
finitely many recorded events.

This postulate places the present construction within the causal set program
of Sorkin and collaborators, where spacetime is modeled as a locally finite
partial order and continuum geometry, when it appears, is a derived
approximation. Order encodes temporal precedence, and local finiteness
encodes discrete causal volume. No metric, field, or manifold structure is
assumed at the fundamental level; these arise only if the causal set admits a
faithful embedding into a Lorentzian manifold.


\begin{axiom}[The Axiom of Causal Set Theory]
label{ax:causal}
The fundamental structure underlying spacetime is a causal set: a locally
finite partially ordered set $(E,\prec)$, where
\begin{enumerate}
\item $e\prec f$ means $e$ causally precedes $f$,
\item $(E,\prec)$ is acyclic and transitive,
\item and for any two events $a\prec b$, the interval
$\{\,e\in E : a\prec e\prec b\,\}$ is finite.
\end{enumerate}
Local finiteness ensures that causal volume is discrete, and the order
relation encodes temporal precedence. A Lorentzian manifold, when it exists,
is merely a continuum approximation in which the causal set can be faithfully
embedded.
\end{axiom}

\begin{example}[The Laboratory Procedure~\cite{ockham1323,wheeler1983}]
\label{ex:psi-lab}
The following example collects ideas from several well–established
perspectives in measurement theory.  Bohr and Wheeler emphasize that a
physical experiment records only distinguishable outcomes; no other
structure is operationally meaningful~\cite{bohr1928,wheeler1983}.  In
information theory, such records are represented as finite or countable
strings of distinguishable symbols~\cite{shannon1948,cover2006}.  In
ergodic theory and causal set theory, successive measurements refine a
partition of the observational domain into finer distinguishable
elements~\cite{rohlin1967,ornstein1991,sorkin2005}.  Finally,
computational mechanics and operator–theoretic dynamics treat the
“evolution” of a system as the repeated update of its information
state~\cite{crutchfield1989,koopman1931,birkhoff1931}.  Taken together,
these perspectives justify modeling a laboratory procedure as a refinement
operator acting on a finite measurement record.  The experiment does not
solve differential equations; it applies $\Psi$.

Consider a laboratory notebook in which each threshold crossing of a detector
is recorded as a mark in ink. The notebook contains a finite sequence of
distinguishable entries
\[
e_0 \prec e_1 \prec \cdots \prec e_n,
\]
each representing an irreversible update of the experimental record. The
notebook is not a model of reality; it \emph{is} the empirical record. No
claim is made about any mechanism behind it.

Now suppose one attempts to describe what ``really'' happened between two
successive entries $e_i$ and $e_{i+1}$. If additional curvature, oscillation,
turning points, or discontinuities had occurred, then the detector would have
crossed a threshold and a new entry would appear. Because no such entry is
present, the observational record forbids any refinement that predicts one.

Thus the notebook determines a finite set $E=\{e_0,\dots,e_n\}$ of recorded
events. Every admissible history must be a completion that introduces no new
distinguishable events beyond $E$. Any hypothetical refinement with additional
structure is rejected as inadmissible, since it asserts observations that did
not occur.
\end{example}



\section{The Axioms of Physics}
\label{se:physicalaxioms}

A common criticism of mathematical physics is the extent to which mathematics can 
be tuned to fit observation~\cite{boltzmann1896,planck1914} and, conversely, 
manipulated to yield nonphysical results~\cite{berkeley1734,hossenfelder2018}.
The critique of Newton’s fluxions could only be answered by successful prediction. 
Today, calculus feels like a natural extension of the real world---so much so that 
Hilbert, in posing his famous list of open problems, explicitly formalized the lack 
of a rigorous foundation for physics as his Sixth Problem~\cite{hilbert1902problems,weyl1949}.

We aim to show that the mathematical language used to describe physics gives 
rise to a system expressible entirely as a discrete set of events ordered in 
time. Moreover, this ordered set possesses a mathematical structure that 
naturally yields the appearance of continuous physical laws and the conservation of quantities.
To understand how this works, we first clarify what we mean by measurement.

\subsection{Measurement and the Axiom of Cantor}
\label{sse:measurement}
Physical laws relate measurements. For example, Newton’s second law~\cite{newton1687}
\begin{equation}
\label{eq:newton2}
F=\frac{dp}{dt}
\end{equation}
states that force relates to the \emph{change} in momentum over time. To speak of change you must have at least
two momentum values, one that \emph{comes before} the other; otherwise there is nothing to distinguish.
In set-theoretic terms, by the Axiom of Extensionality (assumed in Axiom~\ref{ax:peano}), different states must differ in their
contents, so ``change'' presupposes the distinguishability of two states.

In this framing, measurement values are \emph{counts} (cardinalities) of elementary occurrences: the number of
hyperfine transitions during a gate, the tick marks traversed on a meter stick, the revolutions of a wheel.
The \emph{event} is the action that makes previously indistinguishable outcomes distinguishable; the
\emph{measurement} is the observed differentiation (the count) between two anchor events.  This is not the
absolute measure of the event, but just relative difference of the two.  We count the events as time passes.

Since special relativity requires that time vary under the Lorentz transform~\cite{einstein1905, lorentz1904}, there can be no 
global scalar representation of temporal duration. Rather, special relativity permits us only to 
\emph{list} all events in the universe in their proper causal order. It is this ordered list that 
we elevate to the first physical principle:

\begin{axiom}[The Axiom of Cantor: Events are Ordered Countably~\cite{cantor1895, earman1974}]
\label{ax:cantor}
The only invariant agreement in time guaranteed between two observers is the order in which the 
events occur. The duration between two events is defined as the number of measurements that can 
be recorded between them:
\begin{equation}
\label{eq:timevarianve}
|\delta t| \;=\; \bigl|\text{events distinguished between}\bigr|.
\end{equation}
\end{axiom}

\subsection{Observations are Combinatorial}
\label{sse:finite}

The recursive description of physical reality is meaningful only within the
finite causal domain of an observer. Each step in such a description corre-
sponds to a distinct measurement or recorded event. Observation is therefore
bounded not by the universe itself, but by the observer’s own proper time and
capacity to distinguish events within it.

\begin{axiom}[The Axiom of Planck: Observations are Finite~\cite{planck1901}]
\label{ax:planck}
For any observer, the set of observable events within their causal domain
is finite.  The chain of measurable distinctions terminates at the limit of the
observer’s proper time or causal reach.
\end{axiom}

\noindent
This axiom establishes the physical limit of any causal description:
the sequence of measurable events available to an observer always ends in a
finite record.  Beyond this frontier---beyond the end of the observer’s time---no
additional distinctions can be drawn.  The \emph{last event} of an observer
thus coincides with the top of their causal set: the boundary of all that can be
measured or known.

\subsection{Event Selection}
The preceding axioms restrict the informational content of the record and the
structure of causal precedence.  We now introduce an axiom governing how
events may be selected in a consistent physical history.  A partial history is
a finite sequence of recorded distinctions that respects the causal order.  In
a locally finite causal set, many partial histories may be extended, but not
all extensions are admissible: each new event must preserve causal
consistency and remain compatible with every previously recorded distinction.

The Axiom of Boltzmann asserts that whenever we impose countably many
local causal requirements---each representing a physically admissible
constraint---there exists a single consistent history that satisfies all of
them.  Mathematically, this parallels the role of Martin's Axiom in set
theory, where dense sets encode constraints and a filter selects a coherent
global object \cite{martin1970,kunen1980,jech2003,todorcevic2010}.
Physically, it echoes Boltzmann's principle that every admissible microstate
selection must preserve distinguishability \cite{boltzmann1896}, and follows
the causal-set program in which a spacetime history is constructed one event
at a time under causal consistency \cite{bombelli1987,finkelstein1996}.
Hilbert's call to axiomatize the foundations of physics \cite{hilbert1902}
is realized here as a minimal requirement: if each local constraint is
physically permissible, then the combined history must also be permissible.



\begin{axiom}[The Axiom of Boltzmann: Events are Selected to be Coherent]\label{ax:boltzmann}
Let $(\mathsf{P},\le)$ be the poset of finite, order-consistent partial 
histories in a locally finite causal domain, ordered by extension. For
every countable family $\{D_n\}_{n\in\mathbb{N}}$ of dense subsets of
$\mathbf{P}$ (local causal constraints), \emph{there exists} a filter 
$G\subseteq \mathsf{P}$ with $G\cap D_n\neq\varnothing$ for all $n$.
\end{axiom}


\section{The Causal Universe Tensor}
The axioms above determine the structure of the physical record: events form a
locally finite causal set, extensions of partial histories preserve causal
consistency, and informational minimality forbids unrecorded structure.  What
remains is to represent this record in a mathematical form that allows the
accumulation of distinctions.  We now construct such a representation.

\subsection{Sets of Events}
\label{sse:eventsets}

Let the set of all events accessible to an observer be denoted \(E\)\footnote{
The symbol $E$ here denotes the \emph{set of distinguishable events}---it is
not the energy operator or expectation value familiar from mechanics.
Throughout this work, $E$ indexes discrete occurrences in the causal order,
while quantities such as energy, momentum, or stress appear only later as
\emph{derived measures} on this set.
}
, ordered by causal precedence \(\leq\).  
Because any physically realizable region is finite, this order forms a locally finite partially ordered set (poset)~\cite{finkelstein1988causal}.

Each admissible set of events may be represented as a locally finite
partially ordered structure~\cite{bombelli1987,sorkin1991},
whose links record only those relations that are causally admissible.
In this view, a ``history'' is not a continuous trajectory but a
combinatorial diagram: every vertex an event, every edge a permissible
propagation.
This discrete formulation generalizes the intuition behind
Feynman's space--time approach to quantum mechanics, in which the
amplitude of a process is obtained by summing over all consistent
histories~\cite{feynman1948,feynman1965}.
The Feynman diagram thus appears here as a special case of the causal
network itself---a pictorial reduction of the full tensor of event
relations---and the path integral becomes a statement of global
consistency across all measurable causal connections.

\begin{example}[Feynman Diagram as a Causal Network~\cite{feynman1965}]
\NB{This is a \emph{classical} simplification of the highly complex notation
of the Feynman Diagram. See Thought Experiment~\ref{te:feynman-full} for a more
rigorous treatment.}

In conventional quantum field theory, a Feynman diagram depicts a sum over
interaction histories connecting initial and final particle states.  Each
vertex represents an elementary event---an interaction that renders previously
indistinguishable outcomes distinct---and each propagator represents the
possibility of causal influence between events.

In the present formulation, such a diagram is naturally interpreted as a finite
\emph{causal network}.  The set of vertices corresponds to the event set
$E$, and the directed edges encode the causal relation $\leq$ defined by
Axiom~\ref{ax:cantor}.  The tensor assigned to each vertex,
$E_k \in T(V)$, records the measurable contribution of that interaction to
the global state, while the propagators describe admissible compositions of
these event tensors within the Universe Tensor
\[
U_n = \sum_{k=1}^n E_k.
\]

At this stage, $U_n$ is a classical accumulator: it records the count and
structure of distinguishable events without assigning amplitudes or
phases.  This is deliberate.  The present framework concerns only the
logical bookkeeping of distinctions.  The full quantum structure---including 
complex amplitudes, superposition, and interference---appears
only after the informational gauge is introduced.  In that setting, the
classical accumulator becomes the coarse projection of a richer amplitude
algebra, much as a Feynman diagram may be viewed as the combinatorial
skeleton of a path integral.  That generalization is deferred until
Chapter~ref{chap:mass}, where the amplitude-bearing form of $U$ is constructed.


Summing over all consistent diagrams is therefore equivalent to enumerating
all admissible orderings of distinguishable events.  The path integral itself
becomes a statement of \emph{global consistency} across the entire causal
network: every measurable amplitude corresponds to one possible embedding of
finite causal order into the continuous limit.  In this sense, a Feynman
diagram is not merely a pictorial tool but a discrete representation of the
causal tensor algebra from which continuum physics emerges.
\end{example}

This identification is pedagogically useful.  From this point onward, every
construction may be viewed as an algebraic generalization of the familiar
Feynman diagram:  the event tensors are its vertices, the causal relations
its edges, and the Universe Tensor the cumulative sum over all consistent
orderings.  The remainder of the monograph simply formalizes this graphical
intuition in set-theoretic and tensorial language, rather than using calculus.

Such an ordering always admits at least one maximal element~\cite{bombelli1987}:
\begin{equation}
\label{eq:top}
\mathrm{Top}(E) = \{\, e \in E \mid \nexists f \in E \text{ with } e < f \,\}.
\end{equation}
The elements of \(\mathrm{Top}(E)\) represent the current causal frontier—the most recent events that have occurred but have no successors~\cite{sorkin2005}.  
Although \(\mathrm{Top}(E)\) may contain several incomparable (spacelike) elements, it is never empty and therefore provides a well-defined notion of a “last event’’ from the observer’s perspective.  
This frontier defines the light-cone boundary and the terminal particle–wave interaction that delimits all accessible information.


Every event $e\in E$ corresponds to an irreducible distinction in the
experimental record.  Under the measurable embedding
$\Psi:E\rightarrow\mathcal{T}(V)$ of Definition~\ref{def:eventtensor}, each
logical event is mapped to an algebraic object $E_e$ in the tensor algebra.
These objects can be composed and accumulated, producing a record that
reflects the ordered refinement of the causal set.  The goal of this section
is to define a cumulative object $U$---the \emph{Causal Universe Tensor}---that
embodies the total informational content of all events observed so far.

It is crucial to emphasize that no background time parameter is introduced.
There is no external clock and no continuous variable $t$ against which
events are measured.  Instead, Axiom~\ref{ax:cantor} guarantees that the causal
set admits a linear extension: the events can be listed in a sequence that
respects causal precedence.  In this framework, \emph{time} is merely the
ordinal index of an event in such a sequence.  It is not a physical field or
metric quantity, but a bookkeeping device that labels the relative order of
observations.

With this viewpoint, accumulating the event tensors in order is not
evaluating a function of time.  It is forming the algebraic sum of the
distinctions that have already occurred.  The resulting object, the Causal
Universe Tensor, represents the total recorded history up to any chosen
ordinal position in the list of events.


\newglossaryentry{time}{
  name={time},
  description={An ordinal index into the ordered list of events guaranteed by the Axiom of Order},
  sort=time
}

\begin{definition}[Time (non-standard)]\label{def:time}
\gls{time} is not a variable, scalar, or independent measurement. Rather, it is an index into the
sorted list of events guaranteed by the Axiom of Order. Its role is purely ordinal: to
enumerate the relative position of events within the universal sequence
\end{definition}

\newglossaryentry{eventtensor}{
  name={event tensor},
  description={An element $\E_k \in \Talg$ encoding the measurable contribution of an event $e_k \in \Eset$ to the global state via an embedding $\Psi:\Eset\to\Talg$},
  symbol={$\E_k$},
  sort=eventtensor
}

The preceding axioms establish a measurement record as a locally finite,
partially ordered set of distinctions $(E,\prec)$. This structure is purely
combinatorial. To connect the logical record to physical measurement, we
require a representation that can carry numerical values and allow recorded
distinctions to combine. A vector space $V$ provides a domain for measurable
quantities, but to represent successive distinctions we also need a rule for
composition. The tensor algebra $\mathcal{T}(V)$ is the freest algebra
generated by $V$: it contains $V$, supports noncommutative products, and
imposes no additional relations beyond those required by linearity. By
associating each logical event $e_k$ with a tensor $E_k$ in $\mathcal{T}(V)$
we obtain an algebraic record of distinctions that can be summed and composed.
This representation introduces no structure beyond what is logically required
to encode measurable updates.


\begin{definition}[Event Tensor~\cite{golub2013}]\label{def:eventtensor}
Let $\V$ be a finite-dimensional real vector space of measurable quantities.
An \gls{eventtensor} $\E_k \in \Talg$ encodes the distinguishable contribution
of the $k$th event $e_k \in \Eset$ to the global state.
It is related to the logical event by a measurable embedding
\[
\Psi:\Eset\to\Talg,\quad\E_k=\Psi(e_k)
\]
\end{definition}


\newglossaryentry{orderedfold}{
  name={ordered fold},
  description={An associative left fold over a totally ordered sequence of event tensors, preserving the order of composition in a non-commutative algebraic structure},
  sort=orderedfold
}

\begin{definition}[Ordered fold (non-standard)]\label{def:ordered-fold}
Let $(E,\preceq)$ be totally ordered as $\langle e_1,\dots,e_n\rangle$ on a finite prefix, and let $(\mathcal{A},\oplus)$ be a (not-necessarily commutative) associative algebraic structure with identity $0$. Given event tensors $E_k\in\mathcal{A}$, define the ordered fold by
\[
\mathrm{Fold}_\oplus(E_1,\dots,E_n)\;:=\;(((0\oplus E_1)\oplus E_2)\cdots)\oplus E_n.
\]
\end{definition}

\newglossaryentry{uncorrelantequivalence}{
  name={uncorrelant equivalence},
  description={An equivalence relation between event tensors or ordered lists that differ only by permutations within commutative subsets preserving all cyclic scalar invariants such as traces of contractions},
  sort=uncorrelantequivalence
}

\begin{definition}[Uncorrelant Equivalence]\label{def:uncorrelantequivalence}
Write $E_i \sim E_j$ if they lie in a subset on which $\oplus$ is commutative and which preserves all
cyclic scalar invariants (for example, traces of contractions).
Two ordered lists are \emph{\gls{uncorrelantequivalence}} if they differ only by permutations
inside such subsets.
We write $\equiv$ for equality modulo uncorrelant equivalence
\end{definition}



\begin{definition}[Selection Operator]
\label{def:selection-operator}
Let $E$ be a set of recorded events. A \emph{selection operator} is a map
\[
\mathcal{S} : \mathcal{P}(E) \to \mathcal{P}(E)
\]
such that $\mathcal{S}(A)$ returns the subset of events in $A$ that remain
distinguishable under admissible refinement.  In particular, $\mathcal{S}$
removes all identifications that cannot be supported by record.  If
$\mathcal{S}(A) = A$, the set $A$ is said to be \emph{admissible}; if
$\mathcal{S}(A) \subsetneq A$, the removed elements were
indistinguishable from others within $A$.

The selection operator induces a partial order on $E$ by the rule
\[
e \prec f \quad \text{iff} \quad e \in \mathcal{S}(\{e,f\}).
\]
In words, $e$ precedes $f$ when $e$ is a distinguishable refinement of the
pair $\{e,f\}$.  No causal generation is implied: the operator records only
the order in which distinctions appear in the admissible record.

A collection of events is a \emph{selection chain} if repeated application of
$\mathcal{S}$ eventually yields a singleton.  The Universe Tensor is built
from the family of all such chains: each acts as a discrete analog of an
integral curve in conventional calculus.
\end{definition}



\begin{proposition}[Causal Universe Tensor]\label{prop:universe-tensor}
Let $E_1\prec\cdots\prec E_n$ be the event tensors in order, with $\oplus$ the addition in $T(V)$ (componentwise in the direct sum) and composition handled only by subsequent linear functionals. Define $U_0:=0$ and
\[
U_{k+1}\;:=\;U_k \oplus E_{k+1},\qquad 0\le k<n.
\]
Then:
\begin{enumerate}
\item
(\emph{Causal uniqueness})  
Let the index $k$ correspond to the ordinal rank of each event
(Definition~\ref{def:rank-time}), whose existence is guaranteed by ZFC + Axiom of Cantor (Axiom~\ref{ax:cantor}).
Then the recursion
\begin{equation}
U_{k+1}=U_k\oplus E_{k+1}
\end{equation}
is unique because this ordinal order $\preceq$ is fixed by the causal structure and cannot be permuted outside uncorrelant-equivalence classes (Definition~\ref{def:uncorrelant}).
Associativity of $\oplus$ ensures mechanical well-definedness once that order is fixed.
\item If a subset $S\subset\{1,\dots,n\}$ is uncorrelated in the sense of Definition~\ref{def:uncorrelant}, then reordering $\{E_i\}_{i\in S}$ leaves all cyclic scalar invariants of $U_n$ unchanged; i.e.\ $U_n \equiv U_n'$ for any such reordering.
\item In the fully commutative case, $U_n=\sum_{k=1}^n E_k$ as a componentwise sum in $T(V)$.
\end{enumerate}
\end{proposition}

\begin{proofsketch}{universe-tensor}
(1) Associativity gives well-definedness of the left fold. (2) By construction, permutations inside uncorrelated subsets preserve $\oplus$ and cyclic scalar functionals (e.g.\ traces of contractions), hence invariants coincide. (3) If $\oplus$ is commutative, the fold equals the ordinary finite sum.
\end{proofsketch}

\begin{remark}[Ordinal determinacy]
The sequence $(\U_k)$ is not merely algebraically well-defined but \emph{physically ordered}:  
$k$ indexes ordinal rank, not arbitrary enumeration.  
Hence any reordering outside uncorrelant classes violates Axiom~\ref{ax:cantor}.
\end{remark}



With the ordinal structure of events established, we now formalize how these measurements combine algebraically within a finite vector space.


\subsection{Formal Structure of Event and Universe Tensors}
\label{se:formaluniverse}

We now specify the algebraic structure of the quantities introduced above.
Let $\V$ denote a finite--dimensional real vector space representing
the independent channels of measurable quantities (e.g.\ energy, momentum,
charge).  Define the tensor algebra~\cite{halmos1958,lang2002}
\begin{equation}
\label{eq:tensoralg}
\Talg = \bigoplus_{r=0}^\infty \V^{\otimes r},
\end{equation}
whose elements are finite sums of $r$--fold tensor products over $\mathbb{R}$.
Each \emph{event tensor} $E_k$ is a member of $\Talg$
encoding the distinguishable contribution of the $k$--th event to the global
state.  We write
\begin{equation}
\label{eq:eventalgebra}
\E_k \in \Talg, \qquad
\U_n = \sum_{k=1}^{n} \E_k \in \Talg).
\end{equation}
Addition is understood componentwise in the direct sum and preserves the
ordering of indices guaranteed by the Axiom of~Order~\cite{bombelli1987,halmos1958}.  In this setting the
``universe tensor'' $\U_n$ is the cumulative history of all event tensors up to
ordinal~$n$.

\newglossaryentry{tensoralgebra}{
  name={tensor algebra},
  description={The direct sum $\Talg=\bigoplus_{r=0}^{\infty}\V^{\otimes r}$ with componentwise addition and associative tensor product on a vector space $\V$},
  sort=tensoralgebra
}

\begin{definition}[Tensor Algebra~\cite{golub2013}]\label{def:tensoralgebra}
The \gls{tensoralgebra} on a vector space $\V$ is
\[
\Talg=\bigoplus_{r=0}^{\infty}\V^{\otimes r}
\]
with componentwise addition and associative tensor product
\end{definition}


\begin{remark}
\label{rem:posetfrontier}
Each logical event $e_k$ in the partially ordered set $(\Eset,\prec)$
induces a tensor $\E_k = \Psi(e_k)$ in $\Talg$.
The mapping $\Psi$ translates causal structure into algebraic contribution,
ensuring that causal precedence corresponds to index ordering in $\U_n$.
\end{remark}

Because $\Talg$ is a free associative algebra, all
operations on $\U_n$ are well defined using the standard linear maps,
contractions, and bilinear forms of~$\V$.  The subsequent analysis
of variation and measurement therefore proceeds entirely within conventional
linear--operator theory.

From the definition of the Universe Tensor
\begin{equation}
U_n = \sum_{k=1}^{n} E_k,
\end{equation}
we may regard an \emph{uncorrelant} as any subset of events whose local order can be permuted without altering the global scalar invariants of \(U_n\). 
Formally, a subset \(S \subseteq \{E_1, \ldots, E_n\}\) is uncorrelated if, for every permutation \(\pi\) of \(S\),
\begin{equation}
\sum_{E_i \in S} E_i = \sum_{E_i \in S} E_{\pi(i)}.
\end{equation}
In this case, all contractions or scalar traces derived from \(U_n\) remain unchanged by reordering the elements of \(S\), even though the operator sequence itself may differ.

\newglossaryentry{uncorrelant}{
  name={uncorrelant},
  description={A subset of event tensors whose reordering leaves all scalar invariants of the universe tensor unchanged},
  sort=uncorrelant
}

\begin{remark}[Algebraic Characterization of Uncorrelants]
\label{rem:uncorrelant-algebraic}
Let $\Psi:E\rightarrow\mathcal{T}(V)$ be the event embedding of
Definition~\ref{def:eventtensor}, and let $E_e=\Psi(e)$.  If
$S\subseteq E$ is a set of uncorrelant events (Definition~\ref{def:uncorrelant}),
then reordering the tensors $\{E_e\}_{e\in S}$ in any linear extension of
$(E,\prec)$ leaves all scalar invariants of the Universe Tensor unchanged.
By Proposition~\ref{prop:extension-invariance}, the difference between any
two ordered folds over $S$ lies in the commutator ideal
$[\mathcal{T}(V),\mathcal{T}(V)]$, and therefore vanishes under any
observable that annihilates commutators.  Thus the set-theoretic notion of
uncomparability corresponds exactly to the algebraic notion of order-insensitive
contribution to scalars derived from $U$.
\end{remark}


\begin{definition}[Commutator]
Let $\mathcal{A}$ be an algebra over a field $\mathbb{F}$, constructed as a
set equipped with a bilinear product $(x,y)\mapsto xy$. For $x,y\in\mathcal{A}$
the \emph{commutator} of $x$ and $y$ is the element
\[
[x,y] \;:=\; xy - yx \;\in\; \mathcal{A}.
\]
The set of all finite $\mathbb{F}$-linear combinations of commutators,
\[
[\mathcal{A},\mathcal{A}]
\;:=\;
\left\{\;\sum_{i=1}^{m} \alpha_i\,[x_i,y_i]
\;:\;\alpha_i\in\mathbb{F},\; x_i,y_i\in\mathcal{A}\;\right\},
\]
is called the \emph{commutator ideal}. It is the smallest linear subspace of
$\mathcal{A}$ that contains every element of the form $xy-yx$ and is closed
under multiplication by arbitrary elements of $\mathcal{A}$.
\end{definition}


\begin{proposition}[Extension Invariance up to Commutators]
\label{prop:extension-invariance}
Let $(E,\prec)$ be a locally finite causal set and
$\Psi:E\to\mathcal{T}(V)$ assign event tensors $E_e=\Psi(e)$.
For any finite down-set $D\subseteq E$ and any linear extension
$L=(e_1,\dots,e_m)$ of $(D,\prec)$, define the ordered fold
\[
U_L(D)\;:=\;(((\mathbf{1}\,\oplus E_{e_1})\oplus E_{e_2})\cdots)\oplus E_{e_m}
\;\in\;\mathcal{T}(V),
\]
where $\oplus$ is the (generally noncommutative) fold operation of
Definition~10.

Let $[\mathcal{T}(V),\mathcal{T}(V)]$ denote the commutator ideal generated by
elements of the form $XY-YX$. Then for any two linear extensions $L,L'$ of $D$,
\[
U_L(D)\;\equiv\;U_{L'}(D)\quad\text{mod }[\mathcal{T}(V),\mathcal{T}(V)].
\]
Equivalently, the difference $U_L(D)-U_{L'}(D)$ is a finite sum of commutators.
\end{proposition}

\begin{proofsketch}{extension-invariance}
Any two linear extensions of a finite poset are related by a sequence of
adjacent swaps of incomparable elements. Each adjacent swap replaces a factor
$\cdots\oplus E_a\oplus E_b\cdots$ by $\cdots\oplus E_b\oplus E_a\cdots$.
Expanding both orders shows their difference lies in the ideal generated by
$E_aE_b-E_bE_a$ (and higher nested commutators if $\oplus$ is not simple
multiplication). Iterating over the swap sequence expresses
$U_L(D)-U_{L'}(D)$ as a sum of commutators. A full proof is provided in
Appendix~A.
\end{proofsketch}

\begin{corollary}[Scalar Observables are Extension-Invariant]
Let $\phi:\mathcal{T}(V)\to\mathbb{F}$ be any linear functional that vanishes
on commutators (e.g., a trace-like or abelianized evaluation). Then for every
finite down-set $D$ and linear extensions $L,L'$,
\[
\phi\!\left(U_L(D)\right)\;=\;\phi\!\left(U_{L'}(D)\right).
\]
Thus physical scalars are insensitive to permutations of uncorrelant events
even though the Universe Tensor itself is order-sensitive.
\end{corollary}

\begin{remark}[Consistency with Thought Experiment 2.4.1]
The noncommutative example with events $A,B$ shows $E_AE_B\neq E_BE_A$; the
fold $U_L$ depends on order. The proposition does not deny this. It states
that such differences are \emph{pure commutators}, so any observable that
kills commutators (the quantities we actually report) is invariant under
relinearization.
\end{remark}

\begin{remark}[Where Minimality Acts]
Informational minimality (Axiom of Occam) should be applied either to
(i) observables $\phi(U_L)$ for functionals $\phi$ that annihilate commutators,
or (ii) the abelianization $\mathcal{T}(V)/[\mathcal{T}(V),\mathcal{T}(V)]$.
This keeps Occam’s selection compatible with the noncommutative fold.
\end{remark}


\begin{example}[Non-commutative event pair~\cite{hawking1973}]
\NB{Non-commutative events are often in a \emph{dependency} relationship, one event must \emph{precede} the other for consistent measurement to occur.}

Let $V=\mathbb{R}^2$ and take event tensors as $2\times2$ matrices acting on $V$ with the usual (non-commutative) product. Define
\[
E_A=\begin{pmatrix}1&1\\0&1\end{pmatrix},\qquad
E_B=\begin{pmatrix}1&0\\1&1\end{pmatrix}.
\]
Then
\[
E_AE_B=\begin{pmatrix}2&1\\1&1\end{pmatrix}\neq
\begin{pmatrix}1&1\\1&2\end{pmatrix}=E_BE_A,
\quad\text{so }[E_A,E_B]\neq 0.
\]
    Thus, the universe update $U_2=E_AE_B$ differs from $U_2'=E_BE_A$ whenever the event pair is in a uncorrelant class that permits permutation.
However, cyclic scalar invariants agree: $\mathrm{tr}(E_AE_B)=\mathrm{tr}(E_BE_A)=3$, and $\det(E_AE_B)=\det(E_A)\det(E_B)=1$.
Hence order affects the \emph{operator} state but leaves cyclic scalars (our measurable invariants) unchanged.
This illustrates how Event Selection can forbid reordering of correlated events while Martin-like consistency still preserves global scalar bookkeeping.
\end{example}
\begin{example}[Independent Event Chains~\cite{langevin1911}]
\NB{This result is analogous to the central segment of the twin paradox, when
neither twin is being accelerated. During that interval the Earth and rocket
worldlines are independent event chains. No signal has been exchanged, so no
event on one chain is comparable to any event on the other. Clock comparison
only becomes meaningful when a causal interaction occurs.}

Consider two independent event chains \(A_1 \prec A_2\) and \(B_1 \prec B_2\), represented by \(2\times2\) event tensors
\begin{equation}
E_{A1} =
\begin{pmatrix}
1 & 0\\
0 & 0
\end{pmatrix},
\quad
E_{A2} =
\begin{pmatrix}
0 & 1\\
0 & 0
\end{pmatrix},
\quad
E_{B1} =
\begin{pmatrix}
0 & 0\\
1 & 0
\end{pmatrix},
\quad
E_{B2} =
\begin{pmatrix}
0 & 0\\
0 & 1
\end{pmatrix}.
\end{equation}
The cumulative tensor through all four events is
\begin{equation}
U_4 = E_{A1} + E_{A2} + E_{B1} + E_{B2}
      = 
      \begin{pmatrix}
      1 & 1\\
      1 & 1
      \end{pmatrix}.
\end{equation}
Because \(E_{A2}\) and \(E_{B2}\) commute under addition, the subset
\(S=\{E_{A2},E_{B2}\}\) is uncorrelated: its permutation leaves all scalar invariants of \(U_4\) unchanged.
This simple algebraic example demonstrates how correlation corresponds to commutative structure within a finite causal chain.

The cumulative universe tensor through all four events is then
\begin{equation}
\label{eq:permex2}
\U_4 = \E_{A_1}+\E_{A_2}+\E_{B_1}+\E_{B_2}
      = \begin{pmatrix}1 & 1\\ 1 & 1\end{pmatrix}.
\end{equation}
If the uncorrelant pair $\{A_2,B_2\}$ is permuted, the componentwise sum is
unchanged, $\E_{A_2}+\E_{B_2}=\E_{B_2}+\E_{A_2}$, illustrating that
uncorrelant classes correspond to commutative subsets within the
otherwise ordered sequence.  This simple construction realizes the algebraic
content of Proposition~\ref{prop:universe-tensor} in explicit matrix form.
\end{example}

\section{Information Minimality and Kolmogorov Closure}

The previous definitions describe events as finite distinctions and their
ordering as a partial refinement of information. What remains is the rule
that determines which extensions of a recorded event set are admissible.
Not every history consistent with the order is physically meaningful: a
completion that inserts unobserved structure would imply additional
measurements that never occurred. Information minimality formalizes this
constraint through algorithmic information theory in the sense of
Kolmogorov, Solomonoff, and Chaitin \cite{kolmogorov1965,solomonoff1964a,
solomonoff1964b,chaitin1975}.

We treat histories as finite symbolic strings and measure their descriptive
content by Kolmogorov complexity. A physically admissible history is one
that cannot be compressed by adding unrecorded structure.

\begin{definition}[Kolmogorov Complexity {\cite{kolmogorov1965,chaitin1975}}]
Fix a universal Turing machine $U$. For any finite string $w\in\Sigma^{*}$,
the Kolmogorov complexity $K(w)$ is the length of the shortest input to $U$
that outputs $w$ and halts. The functional $K:\Sigma^{*}\rightarrow\mathbb{N}$
is defined up to an additive constant independent of $w$.
\end{definition}

\begin{definition}[Admissible Extension {\cite{li1997}}]
Let $E=\{e_0\prec e_1\prec\cdots\prec e_n\}$ be the recorded events of an
experiment. A finite string $w\in\Sigma^{*}$ is an \emph{extension} of $E$
if its image under the event map contains $E$ in the same causal order.
An extension $w$ is \emph{admissible} if it introduces no additional events
beyond $E$; that is, every distinguishable update encoded by $w$ has a
corresponding element of $E$. Any extension predicting unobserved structure
is rejected as inadmissible.
\end{definition}

\begin{definition}[Information Minimality {\cite{kolmogorov1965,li1997}}]
Among all admissible extensions of $E$, the physically admissible history is
the one of minimal Kolmogorov complexity:
\[
w_{min}=\arg\min\{K(w): w\ \text{is an admissible extension of }E\}.
\]
\end{definition}

Information minimality expresses the logical content of measurement: if
additional curvature, oscillation, turning points, or discontinuities had
occurred between $e_i$ and $e_{i+1}$, those features would have generated
new events. Since no such events are present in $E$, any extension that
predicts them is inadmissible, and a shorter description exists.

\begin{remark}
This principle is purely set--theoretic. No geometry, metric, or
differential structure is assumed. Kolmogorov minimality selects the
shortest admissible description of the recorded distinctions and forbids
unobserved structure.
\end{remark}

\begin{remark}
As the resolution of measurement increases, the admissible extension forms
a Cauchy sequence in the space of symbolic descriptions. In the dense limit,
its smooth shadow is the unique spline that introduces no new structure
between recorded events. Thus the variational calculus is not imposed; it
is the continuum limit of Kolmogorov minimality.
\end{remark}

\subsection{Inadmissibility of Unobserved Structure}

Let $E=\{e_0\prec e_1\prec\cdots\prec e_n\}$ be the finite set of recorded
events produced by a measurement process. By Definition~15 (Measurement),
each event corresponds to a distinguishable update of state: a change that
crossed a detection threshold and became causally recorded.

Between two successive events $e_i$ and $e_{i+1}$, no additional events
were recorded. This absence is a data constraint: any refinement of the
history that introduces detectable structure---curvature, oscillation,
turning points, discontinuities, or other distinguishable phenomena---would
generate additional events. Since these events do not appear in $E$, any
history that predicts them is logically inconsistent with the observational
record.

\begin{definition}[Unobserved Structure]
Let $w$ be an admissible extension of $E$ (Definition~2.3.3). A symbolic
segment of $w$ between $e_i$ and $e_{i+1}$ contains \emph{unobserved
structure} if it encodes a distinguishable update that is not present in $E$.
\end{definition}



\section{Correlation and Dependency}

In conventional quantum mechanics the word ``entanglement’’ refers to a
non-classical dependency among amplitudes: indistinguishable histories are
combined before probabilities are assigned.  The present framework adopts a
similar intuition, but in a purely informational and algebraic form, with no
amplitudes and no functional dependencies.

Two events are \emph{uncorrelant} when no \emph{correlant} exists between them.
In this case, their transposition commutes with every admissible invariant
of the Universe Tensor, and the events may be represented independently.
Uncorrelant events are informationally separable: no refinement of the
record forces them to be treated jointly.

Two events are \emph{correlant} when they do not commute: exchanging them
changes at least one admissible invariant.  In this case a correlant
exists.  A correlant is an informational relation---the minimal structure
required when two events cannot be represented independently of one
another.  Importantly, a correlant does not specify direction or causation:
nothing is said about which event precedes, influences, or determines the
other.  It expresses only that the transposition fails to commute.

Uncorrelant events can become correlated when their light cones merge.
Before the merger, each event admits a representation that commutes with
the other; no correlant exists, and their histories may be transposed
without altering any admissible invariant.  After the merger, additional
distinctions become available, and the transposition may fail to commute.
A correlant then forms, not because one event generates the other, but
because the enlarged record no longer permits them to be represented
independently.

Dependency relations are stronger still.  A dependency asserts that one
event is determined by another, as in the functional relationships of the
classical calculus.  Such relations describe macro--events in conventional
dynamics, where causes generate effects.  The present work is not concerned
with dependency.  Correlation is the weaker structure: non-commutativity
under admissible permutation, with no claim of generation or determination.

Thus, ``entanglement'' in the conventional quantum sense has two
informational analogues in this framework.  When amplitudes combine as
indistinguishable histories, the result is a superposition.  When events
cannot be transposed without altering admissible invariants, the result is
a correlant.  Both are consequences of the same principle: distinctions
cannot be manufactured retroactively.  What differs is the level at which
indistinguishability occurs---the discrete record of events or the smooth
representation of extremals.


\begin{example}[Spooky Action at a Distance~\cite{bell1964,einstein1935,sorkin2005}]
\label{ex:spooky}
Consider an uncorrelant $S = \{ \E_i, \E_j \}$ of two
spatially separated measurement events.  
By definition, the order of $\E_i$ and $\E_j$ may be permuted
without changing any invariant scalar of the universe tensor:
\begin{equation}
\label{eq:spooky}
\E_i + \E_j = \E_j + \E_i.
\end{equation}
When an observer records $\E_i$, the global ordering is fixed, and the
universe tensor is updated accordingly.  
Because $\E_j$ belongs to the same uncorrelant set, its contribution
is now determined consistently with $\E_i$, even if $E_j$
occurs at a spacelike separation.  
This manifests as the phenomenon of ``spooky action at a distance''---the
appearance of instantaneous correlation due to reassociation within the
uncorrelant subset.
\end{example}

\begin{example}[Hawking Radiation~\cite{hawking1975,unruh1976}]
\label{ex:hawking}
Let $\E_\text{in}$ and $\E_\text{out}$ denote the pair of
particle-creation events near a black hole horizon.  
These events form an uncorrelant set:
\begin{equation}
\label{eq:hawking}
S = \{ \E_\text{in}, \E_\text{out} \}.
\end{equation}
As long as both remain unmeasured, their contributions may permute freely within
the universe tensor, preserving scalar invariants.  
However, once $\E_\text{out}$ is measured by an observer at infinity,
the ordering is fixed, and $\E_\text{in}$ is forced to a complementary
state inside the horizon.  
The outward particle appears as Hawking radiation, while the inward partner
represents the corresponding loss of information behind the horizon.  
Thus Hawking radiation is naturally expressed as an uncorrelant whose collapse
into correlation occurs asymmetrically across a causal boundary.
\end{example}



Intuitively, $P_n$ encodes which outcomes of $\Omega$ are indistinguishable at index $n$.
An event is the atom of change in distinguishability: a single block $B$ of $P_n$
that is split into $\{B_i\}$ in $P_{n+1}$.

\newglossaryentry{predicate}{
  name={predicate},
  description={A map $P:E\to\{0,1\}$ assigning a truth value to each event, used to indicate which events satisfy a specified property},
  sort=predicate
}

\begin{definition}[Predicate on Events~\cite{tarski1933,quine1953}]\label{def:predicate}
A \gls{predicate} is any map $P:E\to\{0,1\}$. It selects which events are ``counted''
\end{definition}


\begin{definition}[Measurement]
\label{def:measurement}
Let $E$ be the event set with order $\prec$, and let $P:E\to\{0,1\}$ be a predicate.
Given two \emph{anchor events} $a,b\in E$ with $a\prec b$, the \emph{measurement of $P$ between $a$ and $b$} is
\begin{equation}
M_P[a,b]\;:=\;\#\{\, e\in E \mid a \prec e \prec b \text{ and } P(e)=1 \,\}\in\mathbb{N}.
\end{equation}
\end{definition}

Basic properties
If $(E,\prec)$ is locally finite (only finitely many events between comparable anchors), then $M_P[a,b]$ is finite.
Measurements are \emph{additive}: for $a\prec c\prec b$,
\begin{equation}
M_P[a,b] \;=\; M_P[a,c] + M_P[c,b].
\end{equation}
They are also \emph{order-invariant}: any strictly order-preserving reindexing of $E$ leaves $M_P[a,b]$ unchanged.

\subsection{Construction of the Universe Tensor and the Axiom of Event Selection}

The algebraic structure introduced so far defines a finite causal order of distinguishable events, each contributing an elementary tensor $\E_k$ to the cumulative universe tensor
\begin{equation}
\U_n = \sum_{k=1}^n \E_k .
\end{equation}
This sequence describes the universe as a recursively constructed record of distinctions: every new event refines the existing causal order by one measurable increment.  
Yet the same mathematical machinery that enables such constructions can also generate pathological extensions—formal solutions with no physical meaning.  
To maintain causal coherence, the theory must therefore include a regularity condition that limits which extensions are admissible.

\begin{example}[Pathological Extension Without Event Selection~\cite{lewis1976}]
\NB{These sorts of pathologies can appear to look like paradoxes arising from
\emph{time travel}, \emph{remote viewing}, or other specious phenomena.}

Let $E = \{e_1, e_2, e_3, \dots\}$ be a locally finite causal chain where each
event $e_i$ has a unique successor $e_{i+1}$.  Define the corresponding universe
tensor
\begin{equation}
\U_n = \sum_{k=1}^{n} \E_k, \qquad \E_k=\mathbf\Psi_k(e_k).
\end{equation}
Now suppose we attempt to ``extend'' this history by splitting a single event
$e_j$ into uncountably many indistinguishable refinements:
\begin{equation}
e_j \longrightarrow \{e_{j,\alpha}\}_{\alpha \in [0,1]},
\end{equation}
each representing a formally distinct but observationally identical outcome.
Algebraically, this replacement yields
\begin{equation}
\E_j \longrightarrow \int_{0}^{1} \E_{j,\alpha}\, d\alpha,
\end{equation}
so that the next update becomes
\begin{equation}
\U_{n+1} = \U_n + \int_{0}^{1} \E_{j,\alpha}\, d\alpha.
\end{equation}

This ``extension'' violates the finiteness and distinguishability conditions
necessary for causal coherence:
\begin{enumerate}
\item The set $\{e_{j,\alpha}\}$ is uncountable, destroying local finiteness;
\item The new events are indistinguishable, so Extensionality no longer
      guarantees unique contributions;
\item The total tensor amplitude $U_{n+1}$ can diverge or cancel arbitrarily,
      depending on how the continuum of duplicates is treated.
\end{enumerate}

Operationally, this is a Banach--Tarski-like overcounting: the causal structure
has been ``refined'' in a way that preserves measure only formally while the
order relation collapses.  The observer would now predict contradictory
outcomes for the same antecedent state---an \emph{overcomplete history}.

To prevent this, the \emph{Axiom of Event Selection} restricts the permissible
extension to a countable, consistent refinement:
\begin{equation}
e_j \longrightarrow e_{j,1}, e_{j,2}, \dots, e_{j,k},
\end{equation}
and requires the selection of exactly one representative outcome from each
locally admissible family.  This keeps $E$ locally finite and maintains a
single-valued universe tensor,
\begin{equation}
\U_{n+1} = \U_n + \E_{j,k^\ast}.
\end{equation}
The axiom thus enforces the same regularity that Martin's Axiom guarantees in
set theory: every countable family of local choices admits a globally consistent
selection that preserves the partial order.
\end{example}


\paragraph{Overgeneration and the Need for Selection.}
Pure mathematics allows objects that exceed any finite observer’s capacity to distinguish: sets without measurable support, or decompositions that preserve volume while destroying order (as in the Banach–Tarski paradox).  
In physical terms, such pathologies correspond to hypothetical universes that overcount possibilities—histories in which indistinguishable outcomes are spuriously distinguished by the formalism itself.  
To restrict attention to realizable histories, we introduce an axiom that selects only those extensions of the causal order that remain both countable and consistent with local finiteness.


\begin{proposition}[Minimal informational closure]\label{prop:minimal-closure}
Let $G\subseteq\mathsf{P}$ be a global filter guaranteed by
Axiom~\ref{ax:boltzmann}.  
Then there exists an equivalence class $\mathcal{U}_G$ of field configurations consistent with $G$.  
Among these, the canonical representative selected by the Selection Operator (Definition~\ref{def:selection-operator}) minimizes the informational curvature functional
\[
R[U]\;=\;\int (\Delta_h^{(2)} U)^2\,dx.
\]
The Euler–Lagrange condition
\[
\frac{\delta R}{\delta U}=0
\quad\Longleftrightarrow\quad
U^{(4)}=0
\]
defines the unique minimal-information extension of $G$.
\end{proposition}

\begin{proof}
Axiom~\ref{ax:boltzmann} ensures non-empty existence of $G$.  
Each admissible $U$ consistent with $G$ corresponds to a permissible refinement satisfying local constraints.
The Selection Operator chooses the least-biased representative—the one minimizing $R[U]$, the “informational bending energy.”  
By standard variational calculus, minimization of this quadratic functional yields the cubic-spline condition $U^{(4)}=0$.  
Thus, the non-constructive existence of $G$ implies the existence of a minimal-curvature representative $U_G$ within its equivalence class.  
This is the informational analog of Occam’s principle: simplicity as closure.
\end{proof}


\begin{remark}[Logical guarantee, not a mechanism]\label{rem:nonconstructive}
Axiom~\ref{ax:boltzmann} is non-constructive. It asserts the \emph{existence} of at least one globally consistent extension meeting all countably many local constraints but does not prescribe any observable or deterministic procedure that finds it. This mirrors the role of the Rasiowa--Sikorski lemma in forcing and is structurally analogous (though weaker in scope) to Martin's Axiom on ccc posets. The axiom thereby rules out pathological overgeneration (e.g.\ uncountable splits into indistinguishable refinements) by restricting attention to countable, order-coherent extensions.
\end{remark}

\begin{example}[Algorithmic analogies are illustrative only]\label{ex:dantzig}
Classical algorithms such as Dantzig's simplex method \emph{select} admissible vertices in a feasible polytope under global constraints, providing existence-by-structure but not physics. We invoke such algorithms only as intuition pumps: they exemplify selection under constraints, not a dynamical law implemented by nature.
\end{example}

\begin{remark}
Downstream results should cite Axiom~\ref{ax:boltzmann} only for \emph{existence}. Any phrase suggesting that the axiom ``chooses,'' ``constructs,'' or ``computes'' a history should be replaced with ``there exists a history meeting the constraints.''
\end{remark}


\paragraph{Interpretation.}
Axiom~\ref{ax:boltzmann} serves as the ``spline condition'' for causal structure: it ensures that the discrete increments of measurement join smoothly into a coherent global record.  
Just as a cubic spline is the minimal analytic closure that interpolates local data without oscillation, Event Selection is the minimal logical closure that interpolates local causal choices without contradiction.  
The result is a universe tensor $\U_n$ that can evolve indefinitely while preserving the consistency of order:
\[
\U_{n+1} = \U_n + \E_{n+1}, 
\qquad 
\text{with all admissible } \E_{n+1} \text{ selected by causal consistency.}
\]
Under this rule, the smoothness of physical law is not imposed but emerges as the global continuity of distinguishability itself.


\begin{corollary}[Martin consistency from Event Selection (domain version)]
Let $P$ be the poset of all finite, order–consistent partial histories in a fixed observer’s causal domain, ordered by extension ($p \le q$ iff $q$ extends $p$ without introducing new indistinguishabilities). Then:
\begin{enumerate}
\item $P$ satisfies the countable chain condition (ccc).
\item For every \emph{countable} family $\{D_n : n \in \mathbb{N}\}$ of dense subsets of $P$, there exists a filter $G \subseteq P$ such that $G \cap D_n \neq \varnothing$ for all $n$.
\end{enumerate}
Consequently, every countable system of local causal choices admits a globally consistent extension meeting all local constraints. In \S2.3.4--\S2.3.5 we interpret this as the finite causal analogue of Martin's property in this domain.
\end{corollary}

\begin{proof}
\textbf{(1) $P$ is ccc.}
By construction, each condition $p \in P$ encodes only finitely many events and order-relations drawn from a \emph{countable} label set available to the observer (Axiom~\ref{ax:planck}). Two conditions are incompatible iff they disagree on at least one finite relation (e.g.\ they force contradictory orderings on some finite subconfiguration). But there are only countably many distinct finite patterns over a countable alphabet; hence any antichain injects into a countable set of such patterns and must itself be countable. Therefore $P$ has no uncountable antichain, i.e.\ $P$ is ccc.

\smallskip
\textbf{(2) Existence of a filter meeting a countable dense family~\cite{rasiowa1963,kunen1980}.}
Let $\langle D_n : n \in \mathbb{N} \rangle$ be dense subsets of $P$. We build an increasing sequence $(p_n)_{n \in \mathbb{N}}$ in $P$ by recursion so that $p_{n+1} \in D_n$ for all $n$.

Start with any $p_0 \in P$ (e.g.\ the empty partial history). Given $p_n$, use the density of $D_n$ to choose $p_{n+1} \in D_n$ with $p_{n+1} \le p_n$. (Here $\le$ is the extension order, so $p_{n+1}$ extends $p_n$ and is therefore compatible with all earlier requirements.) This recursion is legitimate by the Axiom of Choice (assumed via Axiom~\ref{ax:peano}).

Define
\begin{equation}
G \;:=\; \{\, q \in P \mid \exists n\;\; p_n \le q \,\}.
\end{equation}
Then $G$ is upward closed by definition; and it is directed since $(p_n)$ is an increasing chain: for any $q_1,q_2 \in G$ choose $n_1,n_2$ with $p_{n_i} \le q_i$ and let $m=\max\{n_1,n_2\}$; then $p_m \le q_1,q_2$, so any $q \ge p_m$ lies in $G$ and is a common extension. Thus $G$ is a filter on $P$.

Finally, for each $n$ we have $p_{n+1} \in D_n$ and $p_{n+1} \in G$, so $G \cap D_n \neq \varnothing$. Hence $G$ meets every dense set in the given countable family.

\smallskip
\textbf{Remark (transfinite families).}
The above construction yields the classical Rasiowa--Sikorski lemma for countably many dense sets (provable in ZFC). In our setting, Axiom~\ref{ax:boltzmann} supplies the physical regularity that, together with local finiteness (ccc), supports the same book-keeping recursion along any well-orderable family of dense requirements indexed below $2^{\aleph_0}$, producing an increasing chain $\langle p_\alpha \mid \alpha<\kappa\rangle$ with $p_{\alpha+1} \in D_\alpha$ and the same filter $G=\{q:\exists \alpha\; p_\alpha \le q\}$ meeting all $D_\alpha$. In this sense, Event Selection plays the domain-specific role of an MA-like closure principle for the causal poset considered here.
\end{proof}


\begin{remark}[Scope]
This is \emph{not} a derivation of set-theoretic Martin’s 
Axiom inside ZFC. Rather, under the physical axioms of locally 
finite causality and Event Selection, the induced forcing-like 
poset of finite partial histories enjoys an MA-like property 
sufficient for our global-consistency arguments. In Chapter~\ref{chap:wave}, 
this is exactly the “Martin’s Condition” used to guarantee 
propagation/compatibility across overlaps. 
\end{remark}

The values of the Causal Universe Tensor compute the scalar invariants of
order that remain unchanged under admissible extensions of the causal set.
Each component of the tensor encodes a local configuration of events, while
the contraction of those components---its scalar value---measures the degree of
consistency of that configuration with the global ordering guaranteed by
Martin’s Axiom.  When the tensor’s scalar invariants remain constant, the
system exhibits smooth, force-free motion: the kinematic regime.

\section{Emergent Dynamics}
\label{sec:emergent-dynamics}

The discrete Causal Universe Tensor defines a finite informational measure
on admissible configurations.  When these configurations are refined, any
replacement of an admissible history by one with additional unrecorded
structure is forbidden by Axiom~\ref{ax:boltzmann}.  As a consequence,
the physical notion of ``dynamics’’ is not an independent postulate: it
arises only as the unique continuous shadow of informational extremality.

\subsection{Weak Formulation on Space--Time}
\label{sec:weak-formulation}

Let $\psi$ denote an admissible configuration consistent with a fixed set of
event anchors, and let $\phi$ be any test configuration sharing those
anchors.  Informational minimality requires that replacing $\psi$ by $\phi$
cannot decrease causal consistency.  In the finite domain, this condition
appears as the weak relation
\begin{equation}
\psi^{\!*}\,\mathcal{L}\,\psi \;\approx\; \psi^{\!*}\,\mathcal{L}\,\phi,
\label{eq:weak-form}
\end{equation}
where $\mathcal{L}$ counts distinguishable causal increments and
$\psi^{\!*}$ is the reciprocity dual.  No derivatives are assumed; smooth
structure enters only as the completion of refinement.

\subsection{Reciprocity and the Adjoint Map}
\label{sec:reciprocity-adjoint}

The weak extremality relation~\eqref{eq:weak-form} compares an admissible
configuration $\psi$ against a test configuration $\phi$ that shares the same
event anchors.  In the discrete domain, replacing $\psi$ by $\phi$ is encoded
by a \emph{selected update} of the event record: only those increments that
alter distinguishable curvature are allowed.  This update is represented by
the Selection Operator $\mathcal{S}$ of
Definition~\ref{def:selection-operator}, which maps admissible configurations
to admissible refinements.

To every such operator there is an associated \emph{reciprocity map}
$\psi^{\!*}$, defined as the adjoint of $\mathcal{S}$ with respect to the
informational measure $\mathcal{L}$:
\[
\psi^{\!*}\,\mathcal{L}\,\phi
\;=\;
\mathcal{L}\,\bigl(\mathcal{S}[\psi],\,\phi\bigr),
\]
for all admissible test configurations $\phi$.  Intuitively, $\psi^{\!*}$
records the ``shadow'' of an update when viewed from the perspective of
informational minimality: any component of $\phi$ that would introduce an
unobserved distinction is suppressed by the adjoint action.

Because $\mathcal{S}$ admits only refinements that do not create hidden
structure, the reciprocity map annihilates variations invisible at the event
anchors.  Formally, if $\phi$ and $\psi$ agree at the anchors and differ only
by an undetectable perturbation, then
\[
\psi^{\!*}\,\mathcal{L}\,\phi
\;=\;
\psi^{\!*}\,\mathcal{L}\,\psi.
\]
This is exactly the weak relation~\eqref{eq:weak-form}.  In this sense,
$\psi^{\!*}$ enforces closure: it guarantees that the extremal configuration
carries no latent curvature that would be revealed under refinement.

The ``variation'' of $\psi$ is therefore not a differential operation but a
selected refinement of the causal record.  The reciprocity map is the dual
constraint that removes any component of that refinement which would violate
informational minimality.  Together, they generate the weak Euler--Lagrange
structure entirely within the discrete domain, without assuming
differentiability or a continuum of states.

In this way, the reciprocity map guarantees that any admissible update of
$\psi$ corresponds to an interpolant $f(\psi)$ that introduces no new
distinguishable structure.
Under refinement, every such interpolant
converges to the same smooth closure $\Psi$.  Because the event tensor
defines a finite labeled partition of the causal domain, $\Psi$ preserves
anchor order and is injective on each partition element.  Its inverse
$\Psi^{-1}$ therefore exists trivially: applying $\Psi$ and then
$\Psi^{-1}$ recovers exactly the original discrete record $\psi$.  The
interpolant and its smooth limit are thus informationally equivalent
representations of the same causal structure.
\begin{equation}
f(\psi) \rightarrow \Psi^{-1}.
\end{equation}


\subsection{Dense Limit and Euler--Lagrange Closure}
\label{sec:euler-lagrange-closure}

In the classical calculus of variations, a weak extremum of a smooth functional implies the Euler--Lagrange equation in strong form; see Courant
\cite{courant1943var} or Ciarlet \cite{ciarlet1978}.  There, differentiability is assumed a priori and the weak form is obtained by integrating by parts.

In the present framework no differentiability is assumed.  The weak relation \eqref{eq:weak-form} is defined entirely in the discrete domain,
where each term counts distinguishable causal increments.  When the causal grid is refined, informational minimality forces cubic continuity at each
event anchor.  In the dense limit, the discrete extremal coincides with the classical Euler--Lagrange closure,
\[
U^{(4)} = 0,
\]
but this appears only as the smooth completion of a countable sequence of refinements, not as an assumed differential equation.

\begin{proposition}[Discrete extremality implies Euler--Lagrange closure]
\label{prop:discrete-to-euler}
Let $U$ be an admissible configuration on a finite causal grid, and assume
it satisfies the weak extremality condition~\eqref{eq:weak-form} against all
test configurations $\phi$ sharing the same event anchors.  Then $U$ is a
piecewise cubic interpolant with global $C^2$ continuity.  In the dense
refinement limit of the causal grid, the discrete extremal satisfies
\[
  U^{(4)} = 0.
  \]
  Thus the classical Euler--Lagrange closure arises as the smooth completion of
  a countable sequence of informational refinements, not as an assumed
  differential equation.
  \end{proposition}

  \begin{proof}[Proof sketch]
  The argument proceeds in four steps.

  \emph{(1) Discrete admissible configurations.}
  On a finite causal grid, $U$ is specified by its values on a countable set of
  event anchors.  Between consecutive anchors, any interpolant with hidden
  curvature would imply additional distinguishable events.  Therefore the
  admissible interpolant on each interval is a polynomial of minimal degree,
  and $U$ is piecewise polynomial.

  \emph{(2) Weak extremality and hidden curvature.}
  The weak relation~\eqref{eq:weak-form} forbids any replacement of $U$ by a
  test configuration $\phi$ that reduces informational consistency.  A
  polynomial of degree greater than three contains latent inflection points
  that would be detected at sufficient refinement.  Thus the extremal is
  piecewise cubic.

  \emph{(3) Matching conditions at anchors.}
  Informational minimality disallows jumps in value, slope, or bending moment
  at an anchor, since each would constitute a new observable event.  Hence the
  piecewise cubic segments glue together with continuous value, first
  derivative, and second derivative.  The third derivative is piecewise
  constant.

  \emph{(4) Dense limit and smooth closure.}
  As the grid is refined, the intervals shrink and the piecewise constant third
  derivative converges to a continuous function.  The only continuous function
  whose integral vanishes on every shrinking interval is zero.  Therefore the
  fourth derivative of the limit vanishes and the discrete extremal satisfies
  $U^{(4)} = 0$.

  This recovers the classical Euler--Lagrange form without assuming
  differentiability: the differential equation is the smooth shadow of finite
  informational constraints.
  \end{proof}

\begin{example}[Repeatability of Invisible Motion~\cite{bacon1620}]
\label{ex:repeatability}
Consider two independent observers, $A$ and $B$, who record the motion of a
particle between the same event anchors $x_i \prec x_{i+1}$.  Each observer
has finite resolution: any acceleration or inflection large enough to be
distinguishable produces a new event.  Both refine their instruments until
no further events are detected on the interval.

If hidden curvature existed between the anchors, further refinement would
create additional distinguishable records.  The absence of such records
forces each observer to recover the same polynomial of minimal degree.  Thus
both obtain a cubic patch on the interval.

Now let $A$ and $B$ exchange data and perform a joint refinement on a finer
grid.  Any disagreement in value, slope, or bending moment at a shared
anchor would itself generate an observable event.  To avoid contradiction,
the cubic patches must glue together with continuous $U$, $U'$, and $U''$.
In the dense refinement limit, the piecewise constant third derivative
converges to a continuous function whose integral vanishes on every
shrinking interval, yielding
\[
U^{(4)} = 0.
\]

Thus repeatability demands the Euler--Lagrange closure: if two observers can
refine their measurements indefinitely without producing new events, their
reconstructions must converge to the same cubic extremal.  Smooth dynamics
are therefore the unique histories that leave no trace.
\end{example}




\subsubsection{Interpretation: No Physics Assumed}
\label{sec:no-physics-assumed}

The quantity $\mathcal{L}$ is not a physical density but an informational
measure of distinguishable curvature.  The ``action'' is a cumulative count
of admissible distinctions, and its extremal is the only configuration that
introduces no unobserved structure.  Classical dynamics therefore arise as a
mathematical consequence of measurement, not as a physical postulate.

\section{Galerkin Solutions to Weak Equations}
\label{sec:galerkin-solutions}

The weak extremality condition~\eqref{eq:weak-form} can be interpreted in the
classical language of Galerkin methods.  In this formulation, admissible
variations are taken from a finite trial space of functions that agree with
the event anchors.  For the curvature functional
\begin{equation}
  \mathcal{J}[U] = \int (U''(x))^2 \, dx,
  \label{eq:curvature-functional}
\end{equation}
the Galerkin weak form is
\begin{equation}
  \int U''(x)\,\phi''(x)\,dx = 0,
  \label{eq:galerkin-weak}
\end{equation}
for all admissible $\phi$.  Integrating~\eqref{eq:galerkin-weak} by parts twice
and using the fact that the variations vanish at the anchors eliminates all
boundary terms and produces the strong Euler--Lagrange equation
\begin{equation}
  \frac{d^2}{dx^2}\bigl(2U''(x)\bigr) = 0,
  \label{eq:strong-euler}
\end{equation}
and therefore
\begin{equation}
  U^{(4)}(x) = 0.
  \label{eq:u4-zero}
\end{equation}
Thus, the Galerkin extremals of the curvature functional are exactly the cubic
polynomials on each interval of the partition.  This establishes the classical
equivalence between weak variational solutions and their strong differential
form.

\subsection{Weierstrass Convergence of Galerkin Extremals}
\label{sec:weierstrass-galerkin}

Let $[a,b]$ be compact and let $\{\mathcal{T}_n\}$ be a sequence of nested
partitions with mesh size $h_n \to 0$.  For each $n$, let $U_n$ be the
Galerkin extremal of the curvature functional
\begin{equation}
  \mathcal{J}[U] \;=\; \int_a^b \bigl(U''(x)\bigr)^2\,dx,
  \label{eq:curvature-functional-weierstrass}
\end{equation}
subject to the anchor constraints induced by the event record on $\mathcal{T}_n$.

\begin{theorem}
\label{thm:weierstrass-galerkin}
There exists a unique smooth closure $\Psi$ satisfying
\begin{equation}
  \Psi^{(4)}(x) \;=\; 0 \quad \text{on each element of every }\mathcal{T}_n,
  \label{eq:psi-four-zero}
\end{equation}
and the sequence of Galerkin extremals $\{U_n\}$ converges to $\Psi$
uniformly on $[a,b]$:
\begin{equation}
  \lim_{n\to\infty}\;\sup_{x\in[a,b]} \bigl|U_n(x) - \Psi(x)\bigr| \;=\; 0.
  \label{eq:uniform-convergence}
\end{equation}
\end{theorem}

\begin{proof}[Proof sketch]
Energy monotonicity and nonnegativity imply $\{\mathcal{J}[U_n]\}$ is bounded,
so $\{U_n''\}$ is bounded in $L^2(a,b)$.  In one dimension, cubic--spline trial
spaces are stable and yield uniform bounds on $U_n$ and $U_n'$.  Hence
$\{U_n\}$ is equicontinuous and uniformly bounded on $[a,b]$.  By
Arzel\`a--Ascoli, there exists a uniformly convergent subsequence.
Any uniform limit $U$ satisfies the weak form on every subinterval, and
integrating by parts recovers the strong Euler--Lagrange condition
\begin{equation}
  U^{(4)}(x) = 0,
  \label{eq:u-four-zero}
\end{equation}
together with the anchor constraints.  Uniqueness of the smooth closure $\Psi$
forces $U = \Psi$, so the full sequence converges uniformly, establishing
\eqref{eq:uniform-convergence}.
\end{proof}

This establishes Weierstrass (uniform) convergence of the Galerkin extremals
to the unique cubic spline closure dictated by informational minimality.

In particular, any admissible interpolant $f(\psi)$ refined through nested
Galerkin spaces converges uniformly to the unique smooth closure $\Psi$, and
the inverse $\Psi^{-1}$ recovers exactly the original anchor data $\psi$.
Thus $f(\psi) \to \Psi$ and $\Psi^{-1} = \psi$.

\begin{corollary}
For any admissible interpolant $f(\psi)$ consistent with the event anchors,
the Galerkin refinements satisfy
\begin{equation}
  \lim_{n\to\infty} f_n(\psi) = \Psi,
\end{equation}
and $\Psi^{-1}$ restricted to the anchors recovers $\psi$ exactly.  Hence
$f(\psi) \to \Psi^{-1}$ in the sense of uniform convergence on $[a,b]$.
\end{corollary}


\section{Point-wise Agreement of the Galerkin Closure}
\label{sec:pointwise-galerkin}

Let $[a,b]$ be compact and let $\{\mathcal{T}_n\}$ be a sequence of nested
partitions with mesh size $h_n \to 0$.  For each $n$, let $U_n$ be the
Galerkin extremal of the curvature functional
\begin{equation}
  \mathcal{J}[U] \;=\; \int_a^b \bigl(U''(x)\bigr)^2\,dx,
  \label{eq:curvature-functional-pwa}
\end{equation}
subject to the anchor constraints induced by the event record on
$\mathcal{T}_n$.

\begin{theorem}[Uniform convergence of Galerkin extremals]
\label{thm:uniform-galerkin}
There exists a unique smooth closure $\Psi$ satisfying
\begin{equation}
  \Psi^{(4)}(x) = 0
  \qquad \text{on each element of every } \mathcal{T}_n,
  \label{eq:psi-four-zero-pwa}
\end{equation}
and the Galerkin sequence $\{U_n\}$ converges to $\Psi$ uniformly:
\begin{equation}
  \lim_{n\to\infty}\;
    \sup_{x\in[a,b]}
      \bigl|U_n(x) - \Psi(x)\bigr|
      \;=\; 0.
  \label{eq:uniform-convergence-pwa}
\end{equation}
\end{theorem}

\begin{proof}[Proof sketch]
Energy monotonicity and nonnegativity imply $\{\mathcal{J}[U_n]\}$ is
bounded, so $\{U_n''\}$ is bounded in $L^2(a,b)$.  One-dimensional spline
spaces provide uniform bounds on $U_n$ and $U_n'$, so $\{U_n\}$ is
equicontinuous and uniformly bounded.  By Arzel\`a--Ascoli, a uniformly
convergent subsequence exists.  Any uniform limit must satisfy the weak form
on every subinterval, and integrating by parts recovers the strong condition
\eqref{eq:psi-four-zero-pwa}.  Uniqueness of the cubic closure forces the
entire sequence to converge uniformly to $\Psi$.
\end{proof}

We now show that agreement at the event anchors forces agreement everywhere.

\begin{proposition}[Point-wise uniqueness]
\label{prop:pointwise-unique}
Let $\Psi$ and $\Phi$ be smooth closures of admissible interpolants of the
same event record $\psi$.  If
\begin{equation}
  \Psi(x_i) = \Phi(x_i)
  \qquad\text{for all event anchors } \{x_i\},
  \label{eq:agreement-anchors-pwa}
\end{equation}
then
\begin{equation}
  \Psi(x) = \Phi(x)
  \qquad\text{for all } x \in [a,b].
  \label{eq:agreement-global-pwa}
\end{equation}
\end{proposition}

\begin{proof}[Proof sketch]
On each interval $[x_i,x_{i+1}]$, both $\Psi$ and $\Phi$ satisfy
\eqref{eq:psi-four-zero-pwa} and are therefore cubic polynomials.  A cubic
is determined by its value, first derivative, and second derivative at a
point.  Informational minimality forbids discontinuities of $U$, $U'$, or
$U''$ at the anchors, so $\Psi$ and $\Phi$ match these quantities at every
$x_i$.  They must therefore coincide on each interval, giving
\eqref{eq:agreement-global-pwa}.
\end{proof}

Finally, since $\Psi$ is cubic on each interval, all derivatives above third
order vanish point-wise.

\begin{corollary}[Point-wise agreement of derivatives]
\label{cor:taylor-pointwise}
For every anchor $x_i$ and for every integer $k \ge 4$,
\begin{equation}
  \Psi^{(k)}(x_i) = 0,
  \label{eq:higher-derivatives-zero}
\end{equation}
and on each interval $[x_i,x_{i+1}]$,
\begin{equation}
  \Psi(x)
  \;=\;
  \Psi(x_i)
  + \Psi'(x_i)(x-x_i)
  + \tfrac{1}{2}\Psi''(x_i)(x-x_i)^2
  + \tfrac{1}{6}\Psi'''(x_i)(x-x_i)^3.
  \label{eq:cubic-taylor}
\end{equation}
Thus $\Psi$ and its Taylor expansion agree to all orders point-wise at each
anchor.
\end{corollary}

Together, \eqref{eq:uniform-convergence-pwa},
\eqref{eq:agreement-global-pwa}, and \eqref{eq:cubic-taylor} show that every
admissible interpolant converges to the same cubic closure $\Psi$, and that
$\Psi^{-1}$ recovers the original anchor data~$\psi$.

\subsection{$C^{2}$ and Piecewise Analytic Solutions}
\label{sec:c2-analytic}

The uniform convergence in
Section~\ref{sec:pointwise-galerkin} shows that the Galerkin sequence
$\{U_n\}$ has a unique smooth limit $\Psi$ satisfying $\Psi^{(4)}(x)=0$ on
each element of the partition.  Since a function with vanishing fourth
derivative is a cubic polynomial on that interval, the closure $\Psi$ is
given by
\begin{equation}
  \Psi(x)
  =
  \Psi(x_i)
  + \Psi'(x_i)(x-x_i)
  + \tfrac{1}{2}\Psi''(x_i)(x-x_i)^2
  + \tfrac{1}{6}\Psi'''(x_i)(x-x_i)^3
  \label{eq:cubic-local}
\end{equation}
on every subinterval $[x_i,x_{i+1}]$.

Because each such polynomial is infinitely differentiable on the open
interval, $\Psi$ is analytic on $(x_i,x_{i+1})$.  Moreover, cubic continuity
at the anchors enforces agreement of value, slope, and curvature across
interval boundaries, so $\Psi$ is globally $C^{2}$:
\begin{equation}
  \Psi \in C^{2}([a,b]).
  \label{eq:c2-global}
\end{equation}
Higher derivatives exist piecewise but need not be continuous across
anchors, and for all $k\ge 4$
\begin{equation}
  \Psi^{(k)}(x) = 0
  \qquad \text{for } x\in(x_i,x_{i+1}).
  \label{eq:higher-derivatives-zero-analytic}
\end{equation}

Thus the Galerkin limit is a classical $C^{2}$ solution of the strong
Euler--Lagrange form, and is analytic on each element of the partition.  No
additional smoothness or structure is present beyond the cubic representation,
and every admissible interpolant converges to this same piecewise analytic
closure.

\subsection{Equivalence of Discrete and Smooth Representations}
\label{sec:equivalence-principle}

Let $\psi$ denote an admissible discrete record supported on event anchors
$\{x_i\}$, and let $f(\psi)$ be any admissible interpolant that introduces no
new distinguishable structure between anchors.  Refining the interpolant over
nested partitions $\{\mathcal{T}_n\}$ produces a Galerkin sequence
$\{U_n\}$.  By Theorem~\ref{thm:uniform-galerkin},
\begin{equation}
  U_n \;\longrightarrow\; \Psi
  \quad\text{uniformly on } [a,b],
  \label{eq:fn-to-psi}
\end{equation}
where $\Psi$ satisfies the classical closure condition
\begin{equation}
  \Psi^{(4)}(x) = 0
  \quad\text{on each element of every } \mathcal{T}_n.
  \label{eq:psi-four-zero-equivalence}
\end{equation}

By Proposition~\ref{prop:pointwise-unique}, any two smooth closures that
agree at the anchors coincide point-wise on $[a,b]$.  Thus the limit
$\Psi$ is uniquely determined by the anchor data of $\psi$:
\begin{equation}
  \Psi(x_i) = \psi(x_i)
  \quad\text{for every anchor } x_i.
  \label{eq:psi-matches-psi}
\end{equation}

Since $\Psi$ is cubic on each interval, all higher-order derivatives vanish on
$(x_i,x_{i+1})$, and $\Psi$ is analytic there.  Cubic continuity across the
anchors implies
\begin{equation}
  \Psi \in C^{2}([a,b]).
  \label{eq:psi-c2-equivalence}
\end{equation}

Finally, $\Psi$ preserves the anchor ordering and is strictly monotone on each
interval.  Therefore its inverse exists on $[a,b]$ and, when restricted to the
anchor set, satisfies
\begin{equation}
  \Psi^{-1}(x_i) = x_i,
  \qquad
  \text{so }
  \Psi^{-1} = \psi
  \text{ on the event record}.
  \label{eq:psi-inverse-recovers-psi}
\end{equation}

Together, \eqref{eq:fn-to-psi}--\eqref{eq:psi-inverse-recovers-psi} show that
any admissible interpolant $f(\psi)$ refined by Galerkin methods converges to
the same $C^{2}$, piecewise analytic closure $\Psi$, and that $\Psi^{-1}$
recovers the original discrete record.  In this sense the discrete and smooth
representations are informationally equivalent: refinement introduces no
additional structure, and the smooth closure contains exactly the information
encoded in $\psi$.

\subsection{Recovery of the Euler--Lagrange Equation}
\label{sec:recovered-euler-lagrange}

The previous sections established that any admissible interpolant of the
event record, when refined over nested partitions, converges uniformly to a
unique $C^{2}$ closure $\Psi$.  On each element of the partition, this
closure satisfies
\begin{equation}
  \Psi^{(4)}(x) = 0,
  \label{eq:psi-u4-reveal}
\end{equation}
and is therefore cubic between anchors.

The corresponding weak extremality condition,
\begin{equation}
  \int \Psi''(x)\,\phi''(x)\,dx = 0
  \qquad\text{for all admissible }\phi,
  \label{eq:weak-var-reveal}
\end{equation}
was obtained directly from refinements of the discrete event record.
Integrating~\eqref{eq:weak-var-reveal} by parts twice eliminates boundary
contributions at the anchors and yields the strong Euler--Lagrange form
\begin{equation}
  \frac{d^2}{dx^2}\bigl(2\Psi''(x)\bigr) = 0
  \quad\Leftrightarrow\quad
  \Psi^{(4)}(x) = 0.
  \label{eq:strong-euler-reveal}
\end{equation}

No differentiability was assumed a priori; smoothness appears only after the
Galerkin limit exists and is unique.  Thus, from a discrete record and the
requirement that refinements introduce no new distinguishable structure, we
can safely infer the Euler--Lagrange equation.  The strong differential form
follows as a consequence of measurement and refinement, rather than as an
assumed property of the underlying system.

\section{Inference Without Assumption}
\label{sec:inference-without-assumption}

The analysis above does not derive the Euler--Lagrange equation from the
axioms of the discrete calculus of measurement.  Rather, it shows that the
Euler--Lagrange form can be inferred without violating those axioms.  From a
finite event record and admissible refinements, the Galerkin sequence
converges uniformly to a unique $C^{2}$ closure $\Psi$ that satisfies
\begin{equation}
  \Psi^{(4)}(x) = 0
  \qquad\text{on each element of the partition,}
  \label{eq:inference-u4}
\end{equation}
and therefore admits the classical weak relation
\begin{equation}
  \int \Psi''(x)\,\phi''(x)\,dx = 0
  \qquad\text{for all admissible }\phi.
  \label{eq:inference-weak}
\end{equation}
Integrating~\eqref{eq:inference-weak} by parts twice produces the strong
Euler--Lagrange form
\begin{equation}
  \frac{d^2}{dx^2}\bigl(2\Psi''(x)\bigr) = 0,
  \label{eq:inference-strong}
\end{equation}
with no additional assumptions.  Smoothness and differentiability arise only
after the Galerkin limit exists and is unique; neither is introduced as an
axiom of the theory.

Thus, the Euler--Lagrange equation is not postulated, but can be recovered
consistently from the refinement of discrete measurements.  The continuum is
compatible with the axioms: if one wishes to represent the discrete record by
a smooth function, the resulting closure obeys the classical variational
condition.  The framework allows the Euler--Lagrange equation to be inferred
from measurement, while remaining agnostic about any underlying differential
structure.

\section{The Free Parameter of the Cubic Spline}

A cubic spline appears, at first glance, to introduce three independent
degrees of freedom at each point: the value of the function, its slope, and
its curvature. In classical analysis these are treated as arbitrary boundary
data. In the present framework they have a different meaning: each arises as
a finite record of measurement.

Let $u(x)$ be the smooth limit of a countable refinement of finite
measurements. The discrete extremality principle established earlier shows
that any interpolant with unrecorded curvature violates informational
minimality. In the dense limit this forces

\begin{equation}
u^{(4)}(x) = 0.
\end{equation}

Every admissible smooth function is therefore locally a cubic polynomial. A
general solution to (2.?) takes the form

\begin{equation}
u(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 .
\end{equation}

The coefficients $a_0, a_1, a_2, a_3$ are determined by three local
parameters: the value $u$, the slope $u'$, and the curvature $u''$. The
derivative of curvature,

\begin{equation}
u'''(x) = 6 a_3 ,
\end{equation}

is piecewise constant. This $u'''$ is the only quantity that may vary from
interval to interval without introducing fourth–order structure.

Locally this suggests three degrees of freedom. Globally this is not the
case. Because adjacent spline pieces must meet with no unrecorded
structure, they agree in value, slope, and curvature at every shared
boundary. All but one parameter are fixed by the causal structure of
measurement itself. The apparent local freedom collapses to a single global
scale factor: the magnitude of the consistent curvature field.

Thus the cubic spline does not introduce three physical constants; it
produces a single degree of freedom that expresses how strongly the record
of measurement bends. In this framework the continuum contains only one
free parameter: the global curvature scale that allows a countable record of
distinctions to be represented as a smooth function with no unrecorded
features. All subsequent quantities—second derivatives, wave speeds, stress
tensors, and curvature—are determined by this single parameter.



\section{Coda: Navier--Stokes as a Finite Third Parameter}
\addcontentsline{toc}{section}{Coda: Navier--Stokes as a Finite Third Parameter}

We do not derive the Navier--Stokes equations. Rather, we show how the
measurement calculus constrains any smooth limit of finite records to a
cubic-spline structure and thereby recasts the regularity question as the
finiteness of a single quantity: the third parameter of the spline.

\subsection*{1. Statement of the classical problem}
Let $v(x,t)$ be a velocity field and $p(x,t)$ a pressure satisfying the
incompressible Navier--Stokes system on $\mathbb{R}^3$ (or a smooth domain
with suitable boundary conditions):
\begin{equation}
\label{eq:NSE}
\partial_t v + (v\cdot\nabla)v + \nabla p = \nu \Delta v + f, 
\qquad \nabla\cdot v = 0,
\end{equation}
with smooth initial data $v_0$. The Millennium Problem asks whether smooth
solutions remain smooth for all time or may develop singularities in finite
time.

\subsection*{2. Measurement-to-spline reduction}
Chapter 2 established that admissible smooth limits of finite records obey
a local cubic constraint. Along any coordinate line (and likewise along any
admissible selection chain) each component admits a representation whose
fourth derivative vanishes in the limit:
\begin{equation}
\label{eq:quarticzero}
U^{(4)} = 0 \quad \text{(componentwise along admissible lines)}.
\end{equation}
Hence the only freely varying local quantity is the \emph{third parameter}
(the derivative of curvature). In one dimension this is $U'''$. In three
dimensions we package the idea as the third spatial derivatives of $v$:
\begin{equation}
\label{eq:thirdparam}
\Theta(x,t) := \nabla(\nabla^2 v)(x,t) \quad \text{(a third-derivative tensor)}.
\end{equation}
Informally: $v$, $\nabla v$, and $\nabla^2 v$ are glued continuously by the
spline closure; only $\Theta$ may vary piecewise without introducing
fourth-order structure.

\subsection*{3. Regularity as finiteness of the third parameter}
\begin{quote}
\emph{Principle.} If the third parameter $\Theta$ stays finite at all
scales allowed by measurement, the smooth spline limit persists and no
singularity can occur within the calculus of measurement.
\end{quote}
A practical surrogate is a scale-invariant boundedness criterion on $\Theta$
(or a closely related norm tied to enstrophy growth):
\begin{equation}
\label{eq:criterion}
\sup_{0\le t\le T}\ \|\Theta(\cdot,t)\|_{X} < \infty
\quad \Longrightarrow \quad \text{no blow-up on } [0,T],
\end{equation}
where $X$ is chosen to control the admissible refinements (e.g. an
$L^\infty$-type or Besov/H\"older proxy along selection chains). In words:
the only obstruction to global smoothness is unbounded third-parameter
amplitude.

\subsection*{4. Heuristic link to classical controls}
Energy and enstrophy inequalities control $\|v\|_{L^2}$ and $\|\nabla v\|_{L^2}$.
Vorticity $\omega=\nabla\times v$ monitors the first derivative. Growth of
$\nabla\omega$ involves $\nabla^2 v$; the \emph{onset} of non-smoothness is
therefore detected by $\Theta=\nabla(\nabla^2 v)$, the next rung. Thus the
finite-third-parameter condition \eqref{eq:criterion} plays the same role in
this framework that classical blow-up criteria play in PDE analyses: it is
the minimal spline-compatible guardrail against curvature concentration.

\subsection*{5. Non-classical dependency is not invoked}
No dependency (cause-effect) is asserted. The argument is purely
informational: as long as the admissible record does not force the third
parameter to diverge, the cubic-spline closure remains valid and the smooth
limit inferred earlier continues to apply.

\subsection*{6. The rephrased question}
\begin{quote}
\textbf{Navier--Stokes, reframed.} Given smooth initial data and forcing,
must the third parameter $\Theta$ in \eqref{eq:thirdparam} remain finite
for all time under \eqref{eq:NSE}? Equivalently, can measurement-consistent
refinement generate unbounded third-parameter amplitude in finite time?
\end{quote}
If $\Theta$ stays finite, the spline structure persists, and the calculus
of measurement supports global smoothness. If $\Theta$ diverges, the smooth
continuum description ceases to be representable as a limit of admissible
records, and the measurement calculus no longer licenses Euler--Lagrange
inference on that interval.

\subsection*{7. What we have and have not done}
We have not solved the Millennium Problem. We have shown that within this
program the obstruction to smoothness is concentrated in a single quantity,
the third parameter of the cubic spline representation. The classical
regularity question is thus equivalent, in this calculus, to the finiteness
of $\Theta$.



