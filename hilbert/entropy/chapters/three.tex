\chapter{The Algebra of Events}
\label{chap:algebra}
\section{Simultaneity}

Relativistic simultaneity is therefore not a geometric postulate but a
consequence of the informational structure.  With time reduced to ordinal
successor count, two observers moving differently will, in general, generate
non-isomorphic refinements of their ledgers.  What one observer calls
simultaneous corresponds to different ordinal positions in another’s record.
The relativity of simultaneity follows from the impossibility of sharing a
single refinement sequence across distinct causal paths.

\begin{example}[Relativistic Simultaneity~\cite{einstein1905}.]
\NB{See Phenomenon~ref{ph:rel-sim} for a rigorous treatment.}
Two laboratories, $A$ and $B$, perform independent procedures, each producing
a finite measurement record.  Because the experiments are independent, their
events commute: no record in $A$ constrains the order of any record in $B$.
Both notebooks are internally consistent, but their events are mutually
unordered.

Now two observers, $C$ and $D$, travel past the laboratories on different
trajectories, each at a velocity close to the speed of light.  Their
instruments register signals from $A$ and $B$ in different sequences.  Since
the events commute, both observers are free to assemble the two notebooks
into different global orders.  Observer $C$ concludes that certain events in
$A$ precede those in $B$, while observer $D$ concludes the opposite.  Each
construction is internally consistent, because commutativity permits the
reordering.

The discrepancy is not a contradiction, but the finite analogue of
relativistic simultaneity: different trajectories generate different
admissible orderings of commuting events.  The events themselves may be
reordered independently of each other, yet the invariants are preserved.
\end{example}


\section{The Causal Universe Tensor}
The axioms above determine the structure of the physical record: events form a
locally finite causal set, extensions of partial histories preserve causal
consistency, and informational minimality forbids unrecorded structure.  What
remains is to represent this record in a mathematical form that allows the
accumulation of distinctions.  We now construct such a representation.

\subsection{Sets of Events}
\label{sse:eventsets}

Let the set of all events accessible to an observer be denoted $E$\footnote{
The symbol $E$ here denotes the \emph{set of distinguishable events}---it is
not the energy operator or expectation value familiar from mechanics.
Throughout this work, $E$ indexes discrete occurrences in the causal order,
while quantities such as energy, momentum, or stress appear only later as
\emph{derived measures} on this set.
}, ordered by causal precedence $(\prec)$.  
Because any physically realizable region is finite, this order forms a locally finite partially ordered set (poset)~\cite{finkelstein1988causal}.

\begin{definition}[Causal Precedence~\cite{bombelli1987}]
\label{def:causalprecedence}
Let $E$ be the set of distinguishable events accessible to an observer.
For $e_i,e_j \in E$, we say that $e_i$ \emph{causally precedes} $e_j$,
written $e_i \prec e_j$, if the record of $e_j$ cannot be formed without
already having distinguished $e_i$.  Equivalently, $e_j$ refines the
admissible outcomes of $e_i$.  The relation $\prec$ is a strict partial
order: it is irreflexive ($e \not\prec e$), antisymmetric, and transitive.

\NB{The term ``causal'' is used only in the sense of ordering:
$e_i \prec e_j$ asserts that $e_j$ depends on the distinctions recorded
in $e_i$.  No geometric notion of signal propagation or physical
influence is assumed.}
\end{definition}


Each admissible set of events may be represented as a locally finite
partially ordered structure~\cite{bombelli1987,sorkin1991},
whose links record only those relations that are causally admissible.
In this view, a ``history'' is not a continuous trajectory but a
combinatorial diagram: every vertex an event, every edge a permissible
propagation.

This discrete formulation generalizes the intuition behind
Feynman's space--time approach to quantum mechanics, in which the
amplitude of a process is obtained by summing over all consistent
histories~\cite{feynman1948,feynman1965}.
The Feynman diagram thus motivates a special case of the causal
network itself---a pictorial reduction of the full tensor of event
relations---and the path integral becomes a statement of global
consistency across all measurable causal connections.

\begin{example}[Feynman Diagrams (classical)~\cite{feynman1965}]
\NB{This is a classical simplification of the highly specialized notation of
the Feynman diagram.  See Thought Experiment~\ref{te:feynman-full} for a
more rigorous treatment.}

In conventional quantum field theory, a Feynman diagram depicts a sum
over interaction histories connecting initial and final particle states.
Each vertex represents an elementary event---an interaction that renders
previously indistinguishable outcomes distinct---and each propagator
represents the possibility of causal influence between events.

In the present formulation, such a diagram is naturally interpreted as a
finite \emph{causal network}.  The set of vertices corresponds to the event
set $E$, and the directed edges encode the order relation $\prec$ defined
by Axiom~\ref{ax:cantor}.  To each event $e_k$ we associate a representation
$\mathbf{E}_k$ that records the admissible refinement induced by that
event, and the directed structure describes which refinements must
precede others.  The composition of these event tensors gives the Causal
Universe Tensor of the inertial frame:
\begin{equation}
\mathbf{U}_n = \prod_{k=1}^{n} \mathbf{E}_k.
\end{equation}

At this stage, $\mathbf{U}_n$ is a classical accumulator: it records the
count and structure of distinguishable events without assigning amplitudes
or phases.  This is deliberate.  The present framework concerns only the
logical bookkeeping of distinctions.  The full quantum structure---including
complex amplitudes, superposition, and interference---appears only after
the informational gauge is introduced.  In that setting, the classical
accumulator becomes the coarse projection of a richer amplitude algebra,
much as a Feynman diagram may be viewed as the combinatorial skeleton of
a path integral.  That generalization is deferred until
Chapter~\ref{chap:mass}, where the amplitude-bearing form of $\mathbf{U}$
is constructed.

Summing over all consistent diagrams is therefore equivalent to enumerating
all admissible orderings of distinguishable events.  The path integral
itself becomes a statement of \emph{global consistency} across the entire
causal network: every measurable amplitude corresponds to a possible
embedding of finite causal order into the continuous limit.  In this sense,
a Feynman diagram is not merely a pictorial tool, but a discrete
representation of the causal tensor algebra from which continuum physics
emerges.
\end{example}


This identification is pedagogically useful.  From this point onward, every
construction may be viewed as an algebraic generalization of the familiar
Feynman diagram:  the event tensors are its vertices, the causal relations
its edges, and the Cauasl Universe Tensor the cumulative sum over all consistent
orderings.  The remainder of the monograph simply formalizes this graphical
intuition in set--theoretic and tensorial language, rather than using calculus.

Every event $e \in E$ corresponds to an irreducible distinction in the
experimental record.  Under the measurable embedding
$\Psi : E \rightarrow \mathcal{T}$ introduced in Thought
Experiment~\ref{ex:psi-lab}, each logical event is mapped to an algebraic
object $\mathbf{E}_e$ in the tensor algebra.  These objects compose
whenever their corresponding events are compatible in the causal order,
so the accumulation of observed events yields a record that reflects the
ordered refinement of the causal set.

The goal of this section is to define a cumulative object $\mathbf{U}_n$
---the \emph{Causal Universe Tensor}---that embodies the total
informational content of all events observed up to step $n$ in the
current inertial reference frame.  This tensor is not a dynamical
evolution. 
It is the bookkeeping device that records how refinements have survived
admissibility by accumulating exactly those features that remain invariant
under all allowed extensions of the record.

It is crucial to emphasize that no background time parameter is introduced.
There is no external clock and no continuous variable $t$ against which
events are measured.  Instead, Axiom~\ref{ax:cantor} guarantees that the
causal set admits a linear extension: the events can be listed in a
sequence that respects causal precedence.  In this framework, \emph{time}
is merely the ordinal index of an event in such a sequence.  It is not a
physical field or metric quantity, but a bookkeeping device that labels
the relative order of observations.

With this viewpoint, accumulating the event tensors in order is not
evaluating a function of time.  It is forming the ordered product of
distinctions that have occurred.  The resulting object, the Causal
Universe Tensor, represents the total recorded history up to any chosen
ordinal position in the list of events.

\subsection{Refinement}

This observation motivates the first physical axiom: that time is not an
independent scalar field but an ordinal index on the partially ordered set of
distinguishable events.  Each admissible refinement increments this ordinal
by one count, and an observer’s “clock’’ is simply a local parametrization of
that count within their own causal domain.  When two observers’ causal
domains overlap, their records admit a common refinement: the locally finite
structure ensures that their rank assignments agree up to order-isomorphism
on the shared events.  What differs is only the density with which each
observer samples the causal order.  The apparent continuity of time is thus
the smooth shadow of many closely spaced refinements, not an underlying
continuum of duration.

\begin{definition}[Rank time~\cite{bombelli1987,davey2002}]\label{def:rank-time}
Let $(E,\prec)$ be a locally finite \emph{partially ordered set of events}. A rank time is an order-embedding
\[
\tau : E \to \mathrm{Ord}
\]
satisfying $e \prec f \implies \tau(e) < \tau(f)$. Local finiteness implies that for any observer's causal domain $D \subseteq E$, $\tau(D)$ is order-isomorphic to an initial segment of $\mathbb{N}$. We therefore define the \emph{duration}, $|\delta t|$, between anchors $a \prec b$ by
\[
|\delta t|(a,b) \;=\; \#\{\, e \in E \mid a \prec e \prec b \,\}\in \mathbb{N}.
\]
Two rank functions $\tau,\tau'$ are \emph{equivalent} if there exists an order-isomorphism $\phi$ with $\tau'=\phi\circ\tau$; equivalent ranks yield identical durations.
\end{definition}

A finite observer never encounters the world as a continuum.  What is
available are discrete, distinguishable outcomes recorded one at a time.
The informational content of the record grows only when a new measurement
produces a distinction that was not previously present.  Such an addition is
a \emph{refinement}: an admissible strengthening of the observer’s causal
ledger that preserves all earlier distinctions while adding a new one.  

Refinements are the fundamental units of temporal structure.  The ordinal
indexing of time (Definition~\ref{def:rank-time}) arises because each
refinement appends a successor in the causal order.  When two observers’
causal domains overlap, their records admit a common refinement: any
discrepancy in their descriptions can be resolved by adding further
distinctions until both records agree on all shared events.  
Refinement---the very act of observation---
therefore functions as the basic consistency operation—the procedure that
allows independent descriptions of the world to be compared, merged, and
extended without contradiction.

\subsection{On the Structure of Measurement}

In this formulation, a measurement is not the evaluation of a continuous
quantity against an external time parameter.  No clock, ruler, or metric is
assumed.  Instead, the Axioms of Planck and Cantor assert that an observer's
record is a locally finite, causally ordered set of distinguishable events.
To extract a numerical value from such a record, one must identify which
events satisfy a specified property and count how many of them occur between
two anchors in the causal order.

This viewpoint treats measurement as a purely combinatorial act: the
\emph{value} of a measurement is the number of admissible distinctions
satisfying a predicate inside a finite causal interval.  The result is always
an integer, and continuity---when it appears---arises only as the smooth
limit of increasingly refined counts.  We formalize this as follows.


\begin{definition}[Measurement~\cite{wheeler1990}]
\label{def:measurement}
Let $(E,\prec)$ be a locally finite partially ordered set of events, and let
$P:E\to\{0,1\}$ be a predicate designating which events satisfy a specified
property.  For two anchor events $a,b\in E$ with $a\prec b$, the
\emph{measurement of $P$ between $a$ and $b$} is the finite integer
\[
M_P[a,b]
\;:=\;
\bigl|\{\,e\in E:\; a\prec e\prec b \text{ and } P(e)=1\,\}\bigr|
\;\in\;\mathbb{N}.
\]
That is, a measurement is a count of distinguished events satisfying $P$
within the causal interval $(a,b)$.
\end{definition}

A measurement in this setting is therefore nothing more than a count of
distinguished events between anchors.  Numerical values arise only when such
counts are compared against a conventional scale.  No continuous quantity is
assumed \emph{a priori}; continuity is inferred from the refinement of a
finite causal record.  In practice, every physical “number” depends on a
calibration that relates discrete counts to a chosen system of units.

The analysis concerns only the \emph{structure of measurement itself}:
the mathematical relations among counts of distinguishable events that
underlie all physical observations.  In this framing, physics is viewed
as a grammar of distinctions.  The familiar constants and fields---mass,
charge, curvature, temperature---arise as \emph{derived measures} within a
finite causal order, not as independent entities.

\begin{phenomenon}[The Chomsky Effect~\cite{chomsky1956,chomsky1957}]
\label{ex:bnf-measurement}
\NB{Measurement is a formal writing system. Each observation selects a
symbol from a finite alphabet, and a record is the word formed by these
selections. No physical semantics are assumed; the structure is purely
syntactic in the Backus--Naur sense~\cite{backus1959,naur1963}. In the
spirit of Wheeler's dictum that information is fundamental~\cite{wheeler1990},
the act of measurement is treated here as the creation of symbolic
distinctions, nothing more.}

Because measurement produces distinguishable outcomes, each observation
selects a symbol from a finite or countable alphabet
\[
\Sigma = \{\sigma_1, \sigma_2, \ldots \}.
\]
A record of $n$ measurements is therefore a word $w \in \Sigma^n$.  When
an instrument is refined—by increasing precision or reducing noise—any
coarse symbol $\sigma_k$ may be replaced by a finite set of more precise
symbols,
\[
\sigma_k \;\Rightarrow\; \sigma_{k,1} \;\big|\; \sigma_{k,2} \;\big|\;
\cdots \;\big|\; \sigma_{k,r},
\]
just as in a Backus--Naur Form (BNF) production rule
\cite{backus1959,naur1963}.  Not all replacements are admissible: they
must remain compatible with every other measurement that overlaps in
time or causal order.  Two refined histories that disagree on an
overlapping interval cannot both represent valid records.

Thus admissible measurement histories form a formal language generated by
the allowed refinement rules.  The ``law'' governing measurement is the
constraint that only globally consistent extensions of a record may be
generated.  This is not an analogy: it is the standard formal structure
of symbol sequences in coding and information theory \cite{sipser1997}.
\end{phenomenon}

Measurements do not reveal an underlying continuum; they create
distinctions.  Each admissible event is a refinement that separates two
previously indistinguishable possibilities and appends a new token to the
observer's record.  As these refinements accumulate, they form a chain of
distinguishable outcomes, each one justified by an operation whose effects
leave a finite trace.  This chain is not optional: without it there is no
basis on which an observer can assert difference, change, or causality.

Because refinements are irreversible (Axiom~\ref{Kolmogorov}), and because each
refinement must be consistent with all earlier ones (Axiom~\ref{ax:boltzmann}), the
record grows in a definite order.  The resulting sequence of distinguishable
events is therefore well-founded and locally finite.  It is the only
structure every observer can agree upon: not a metric, not a geometry, but a
chain of distinctions that survived admissibility.

This chain is the backbone of the causal ledger.  All temporal notions,
all refinements, and all subsequent tensor representations derive from the
ordering and accumulation of these distinguishable events.

\begin{definition}[Distinguishability Chain~\cite{kolmogorov1933}]
Let $\Omega$ be a nonempty set.
A distinguishability chain on $\Omega$ is a sequence
$\mathcal{P}=\{P_n\}_{n\in\mathbb{Z}}$ of partitions $P_n\in\Part(\Omega)$ such that
$P_{n+1}$ \emph{refines} $P_n$ for all $n$ (every block of $P_{n+1}$ is contained in a block of $P_n$).
Write $\Blocks{P}$ for the set of blocks of a partition $P$
Each refinement step produces zero or more event.
\end{definition}

A finite observer cannot access the world continuously; they access it only
through operations that produce finite, irreversible traces.  Each such trace
marks a distinction that was not present before the operation was performed.
These distinctions are the primitive units of information: without them there
is no basis for asserting difference, change, or causality.  

What survives in the observer’s notebook is not the underlying process but
the residue of those operations that produced a new, admissible refinement.
This residue must be discrete (Axiom~\ref{ax:planck}), persistent (Axiom~\ref{ax:kolmogorov}), 
and compatible with all earlier residues (Axiom of~\ref{ax:boltzmann}).
It is therefore not a “state” of the world but the smallest unit of
distinguishability that can be justified by operational means.

We call such a justified, persistent, distinguishable token an \emph{event}.

\begin{definition}[Event~\cite{kolmogorov1933,sorkin2005}]\label{def:event}
Fix a distinguishability chain $\mathcal{P}=\{P_n\}$.
An event at index $n$ is a minimal refinement step:
a pair
\begin{equation}
\label{eq:eventdef}
e=(B,\{B_i\}_{i\in I},n)
\end{equation}
such that:
\begin{enumerate}
  \item $B\in\Blocks{P_n}$;
  \item $\{B_i\}_{i\in I}\subseteq \Blocks{P_{n+1}}$ is the family of all blocks of $P_{n+1}$ contained in $B$,
        with $|I|\ge2$ (a nontrivial split);
  \item (\emph{minimality}) there is no proper subblock $C\subsetneq B$ with $C\in\Blocks{P_n}$ for which
        the family $\Blocks{P_{n+1}}\cap\mathcal{P}(C)$ is nontrivial.
\end{enumerate}
Let $E$ denote the set of all such events.
We define a strict order on events by
$e\prec f \iff n_e<n_f$, where $n_e$ denotes the index of $e$
\end{definition}

All temporal structure in this framework arises from refinement.  An
observer’s clock does not measure a flowing background parameter; it counts
the distinguishable refinements that occur along the observer’s own causal
path.  This count is intrinsic: no other observer can directly access or
modify the sequence of refinements recorded within a given worldline, and no
external synchronization procedure can force two observers to share the same
refinement density.

The ordinal rank provided by Definition~\ref{def:rank-time} therefore acquires
a special status when restricted to a single causal thread.  Along such a
thread, refinements occur in a fixed order, with no ambiguity or
branching.  The resulting sequence forms the unique, locally defined measure
of temporal progression available to the observer.  It is immune to
coordinate choices, independent of any geometric embedding, and invariant
under all admissible reparametrizations of the global causal set.

This observer-specific refinement count is what we call \emph{proper time}.
It is the intrinsic temporal measure of a causal path: the duration encoded
by the observer’s own chain of distinguishable events, not the duration
assigned by any external chart or coordinate system.

\begin{definition}[Proper Time~\cite{misner1973}]
\label{def:proper-time}
Let $E$ be the set of events generated by a distinguishability chain $P=\{P_n\}$. 
For any two events $a,b\in E$ with $a\prec b$, the \emph{proper time} between them is
\[
\tau(a,b)
=
\max\Bigl\{
\,|C|:\; C=\{c_0,\dots,c_k\}\subseteq E,\;
a=c_0\prec c_1\prec\cdots\prec c_k=b
\Bigr\}.
\]
That is, $\tau(a,b)$ is the cardinality of a maximal chain of strictly refinable
events between $a$ and $b$. Local finiteness of the distinguishability chain
guarantees $\tau(a,b)\in\mathbb{N}$.
\end{definition}

Once proper time is understood as the intrinsic count of refinements along a
causal thread, it follows that an observer cannot refine all aspects of a
measurement record arbitrarily.  Each admissible event consumes part of the
finite informational budget supplied by the axioms: every refinement increases
distinguishability in one direction while limiting the refinement capacity
available to its conjugate descriptions.  In the smooth shadow, these
dual directions appear as position and momentum, slope and curvature, or more
generally, a variable and its rate of change.  The constraint is purely
combinatorial: a ledger with finite precision cannot allocate unlimited
distinguishability to both simultaneously.  This is the informational origin
of the Heisenberg effect.

\begin{phenomenon}[The Heisenberg Effect~\cite{heisenberg1927}]
\label{ph:heisenberg}
A refinement ledger with finite precision cannot simultaneously resolve both
a quantity and the variations of that quantity with arbitrarily high
accuracy.  Increasing the precision of a measurement consumes refinement
capacity that would otherwise distinguish how that measurement changes across
successive refinements.  Perfect specification of a value therefore requires
an unbounded refinement cost in its variation.

Every admissible refinement encodes a finite, irreversible distinction.  
To sharpen the measured value of a
quantity, the ledger must allocate refinements to its instantaneous
distinguishability.  To resolve how that value changes---its rate, slope, or
local variation---the ledger must allocate refinements to successive
differences in the same causal neighborhood.  These two informational tasks
draw from the same finite refinement budget.  Allocating refinements to fix a
value exhausts the capacity needed to record its variability, and allocating
refinements to variability reduces the capacity available to specify the

The Heisenberg Effect expresses the structural tradeoff between measuring a
quantity and measuring how it changes.  The familiar uncertainty relations of
continuum physics arise as the smooth shadow of this discrete bookkeeping
constraint: a finite ledger cannot support unbounded precision in both value
and variation at once.
\end{phenomenon}

It is obvious that related measurements must constrain each other.  We now turn
our attention to unreleasted measurements.
The notion of \emph{uncorrelant events} formalizes the idea that two recorded
distinctions may be independent of one another.  In causal set theory,
incomparability under the causal order corresponds to physical independence
of events \cite{bombelli1987}.  The same conceptual separation appears in
quantum theory, where observables acting on independent subsystems commute
and their measurement outcomes do not influence each other
\cite{dirac1958,peres1995}.  Classical discussions of separated systems, from
Einstein--Podolsky--Rosen and Schr\"odinger to Wheeler's formulation of
complementarity \cite{einstein1935,schrodinger1935,wheeler1983}, frame the
same idea operationally: when no physical procedure can distinguish the
relative order of two events, their ordering has no empirical content.  The
definitions below captures this in the minimal set-theoretic language of the
causal poset.


\begin{definition}[Uncorrelant~\cite{bombelli1987,sorkin1991}]
\label{def:uncorrelant}
Let $(E,\prec)$ be a locally finite partially ordered set of events. Two
events $e,f\in E$ are said to be \emph{uncorrelant} if they are incomparable
under the causal order; that is,
\[
\neg(e\prec f)\quad\text{and}\quad \neg(f\prec e).
\]
The uncorrelant relation partitions $E$ into equivalence classes of events
whose relative order carries no operational consequence for any admissible
measurement or refinement.  In particular, no experimentally distinguishable
difference follows from interchanging the positions of uncorrelant events
in any linear extension of $(E,\prec)$.
\end{definition}

A single observer’s ledger records only the refinements that occur along one
causal path.  But the physical world is not built from one thread of
refinement; it is a tapestry of many locally generated records, each
produced by a finite observer interacting with its own environment.  Whenever
two observers can exchange signals or compare outcomes, the distinctions they
record must cohere: refinements in one ledger must not contradict refinements
in another.  The structure that collects these many partial records into a
globally consistent object is the causal network.

A causal network arises from stitching together locally finite chains of
distinguishable events—each chain representing the refinement history along a
particular worldline—and enforcing the rule that shared events must appear in
the same order in every ledger that records them.  This requirement of
overlap consistency ensures that independently produced descriptions of the
world can be merged into a single, coherent partial order.  The resulting
network is not a manifold or a geometry but a combinatorial object: a web of
refinement relations encoding which events can influence which others.

Before introducing continuous shadows or dynamical laws, we must give a
precise definition of this network, for it is the primitive structure from
which all temporal, kinematic, and geometric notions will eventually emerge.


\begin{definition}[Causal Network~\cite{bombelli1987}]
\label{def:causal-network}
Let $E$ be a finite set of admissible events and let $\triangleright$ denote
the \emph{immediate causal cover}: $e \triangleright f$ if and only if $e < f$
and there exists no $g \in E$ such that $e < g < f$.  The \emph{causal network}
is the directed graph $(E, \triangleright)$ whose vertices are the events in
$E$ and whose directed edges record the immediate causal relations.
\end{definition}

This network is the combinatorial diagram of the event record: each vertex is
a distinguishable event, and each directed edge $e \triangleright f$ certifies
that $f$ cannot be observed without first observing $e$.  Its transitive
closure recovers the full causal order $<$ of Definition~\ref{def:causal-order}.
See Phenomenon~{ph:feynman-diagram} for a rigorous treatment.

Each observer’s ledger records a locally generated sequence of refinements:
a chain of distinguishable events ordered by the succession in which they were
justified.  But physical claims cannot depend on a single observer’s record.
Whenever two observers interact, exchange signals, or jointly participate in
an experiment, their ledgers must agree wherever their domains overlap.  This
overlap consistency requires that any event witnessed by both observers appear
in the same relative order in both records.

The only structure capable of enforcing such universal compatibility is a
global causal order: a partial order that extends every observer’s local
refinement chain while preserving all shared precedence relations.  Local
threads become linearly ordered segments of a single, globally coherent
network; disagreements in refinement density are permitted, but disagreements
in causal order are not.  The global order contains exactly those precedence
relations that survive all admissible mergers of observational records.

Before we can speak of continuous shadows, tensor embeddings, or dynamical
laws, we must formalize this universal ordering relation.  It is the minimal
structure that any coherent universe must admit.


\begin{definition}[Causal Order~\cite{bombelli1987}]
\label{def:causal-order}
Let $P=\{P_n\}_{n\in\mathbb{Z}}$ be a distinguishability chain of partitions, and let an
event be $e=(B,\{B_i\}_{i\in I},n)$ as in Definition~\ref{def:event}, where $B\in\mathrm{Bl}(P_n)$ splits
nontrivially into child blocks $\{B_i\}\subset\mathrm{Bl}(P_{n+1})$.

For $m>n$ and $C\in\mathrm{Bl}(P_m)$, let $\pi_{m\to n}(C)\in\mathrm{Bl}(P_n)$ denote the unique
ancestor block in $P_n$ containing $C$ (well-defined because $P_{n+1}$ refines $P_n$).
Define the \emph{immediate causal cover} relation $e\triangleright f$ between events
$e=(B,\{B_i\},n)$ and $f=(C,\{C_j\},m)$ by
\[
n<m
\quad\text{and}\quad
\pi_{m\to n+1}(C)\subseteq B_i\ \text{for some child}\ B_i\ \text{created by } e.
\]
The \emph{causal order} $\prec$ on the event set $E$ is the transitive closure of
$\triangleright$:
\[
e\prec f \iff \text{there exist events } e=e_0,e_1,\dots,e_k=f \text{ with } e_i\triangleright e_{i+1}\ \text{for all }i.
\]
Then $(E,\prec)$ is a locally finite partially ordered set (reflexivity suppressed for strictness),
where incomparability is allowed: it may happen that neither $e\prec f$ nor $f\prec e$.
\end{definition}

As an illustration, recall the twin paradox of the previous chapter\footnote{See Coda: The Twin Paradox, Chapter 1.}.
In the informational gauge, proper time is not a geometric interval but the
work of reconciling distinguishable events.  The traveling twin accrues a
denser log of refinements---engine burns, course corrections, telemetry---while
the stay-at-home twin records a coarser sequence.  When their notebooks are
merged into a single coherent history, the richer record requires strictly
greater informational effort to reconcile.  Equivalently, the proper time of
the unaccelerated twin is necessarily longer, because her history contains
fewer distinctions and therefore a larger merge is required to absorb those
recorded by her sibling.  In the smooth limit this appears as a shorter
proper time along the curved worldline, but the effect is not mysterious:
it is the discrete fact that one history contains more recorded distinctions
than the other.  Geometry only codifies what measurement already certified.


\begin{definition}[Event Tensor~\cite{golub2013}]
\label{def:eventtensor}
Let $V$ be a finite-dimensional real vector space of measurable quantities.
An event tensor $\mathbf{E}_k \in \mathcal{T}(V)$ encodes the
distinguishable contribution of the $k$th event $e_k \in E$ to the
cumulative record.  It is related to the logical event by a measurable
embedding
\begin{equation}
\Psi : E \to \mathcal{T}(V), \qquad \mathbf{E}_k = \Psi(e_k).
\end{equation}
No algebraic relations are assumed beyond those required by linearity:
$\mathbf{E}_k$ is simply the algebraic image of the $k$th logical
distinction.
\end{definition}

An individual event tensor records a single admissible refinement of the
measurement record.  To represent the cumulative effect of many events, we
must specify how these algebraic objects combine.  Because the causal set is
ordered only up to informational precedence, the combination rule must
respect a chosen linear extension of the partial order and must make no
assumptions of commutativity.  This leads naturally to a left--multiplicative
update: each new event contracts the admissible record of all that precede
it, and the cumulative history is represented by the product of these
restricted increments along any finite prefix of the causal chain.

The combination rule corresponds directly to the set--theoretic refinement
of admissible outcomes.  At each step, the new logical event is not taken in
isolation, but restricted against all prior observations:
\[
e_{k+1}' := e_{k+1} \cap \bigcap_{j=1}^{k} \hat{R}(e_j),
\]
where $\hat{R}$ is the operator that removes outcomes incompatible with the
existing record.  In this framework, physical laws appear nowhere
else: they are encoded entirely in the restriction operator.  What survives
admissibility is physical; what is removed was never a possible history.

In the
algebraic domain this restriction is represented by
\[
\mathbf{U}_{k+1}
:= \Psi(e_{k+1}')\,\mathbf{U}_k
= \Psi\!\bigl(e_{k+1} \cap \hat{R}(e_k)\bigr)\,\mathbf{U}_k,
\]
where $\Psi$ embeds the surviving distinctions into the tensor algebra.
Each new event therefore contracts the admissible history by left
multiplication.  The cumulative record is the product of these restricted
increments along any finite prefix of the causal chain.

Formally, the measurable embedding $\Psi$ sends the set--theoretic
restriction to a multiplicative update in the tensor algebra.  Instead of
embedding the raw event $e_{k+1}$, we embed only the portion that survives
all prior admissibility constraints:
\[
\mathbf{E}_{k+1}
=
\Psi\!\Bigl(
e_{k+1} \cap \bigcap_{j=1}^{k} \hat{R}(e_j)
\Bigr).
\]
Writing $\mathbf{R}(e) := \Psi(\hat{R}(e))$, the cumulative record evolves by
left multiplication:
\[
\mathbf{U}_{k+1}
=
\mathbf{R}(e_{k+1})\,\mathbf{U}_k
=
\Psi\!\bigl(e_{k+1} \cap \hat{R}(e_k)\bigr)\,\mathbf{U}_k,
\qquad 0 \le k < n.
\]
Thus the tensor update is the algebraic realization of the same logical
operation performed in $E$: a new event is applied only after its outcomes
have been restricted by all earlier observations.  The universe accumulates
consistency through products of restricted increments, not by additive
evolution.

\begin{definition}[Partition of the Event Set~\cite{halmos1974naive}]
\label{def:partition}
Let $(E,\prec)$ be a locally finite partially ordered set of distinguishable
events.  A \emph{partition} of $E$ is a collection of disjoint subsets
$\{E_\alpha\}_{\alpha\in A}$ such that
\[
E = \bigcup_{\alpha\in A} E_\alpha,
\qquad
E_\alpha \cap E_\beta = \varnothing
\quad\text{for}\;\alpha\neq\beta.
\]
Each $E_\alpha$ is an informationally independent component: no event in
$E_\alpha$ refines or is refined by an event in $E_\beta$.  Correlant
events therefore lie within the same partition element, while uncorrelants
lie in distinct elements of the partition.
\end{definition}

\begin{definition}[Restriction Operator]
\label{def:restriction}
Let $(E,\prec)$ be a partially ordered set of events, and let
$e \in E$ be a newly recorded event.  The \emph{restriction operator}
\[
\hat{R}(e) : E \to E
\]
acts on the event record by removing any outcomes that are incompatible
with $e$.  For $f \in E$,
\[
\hat{R}(e)(f) =
\begin{cases}
f, & \text{if $f$ is admissible given $e$,} \\
\varnothing, & \text{otherwise.}
\end{cases}
\]
Equivalently, if $E_\alpha$ is the partition element containing $e$,
then
\[
\hat{R}(e)
\;:\; E_\alpha \mapsto E_\alpha',
\qquad
E_\alpha' = \{\,f \in E_\alpha \mid f \text{ is compatible with } e\,\}.
\]
Thus $\hat{R}(e)$ contracts the event domain by discarding outcomes that
contradict the new distinction.
\end{definition}

We now present the \emph{Causal Universe Tensor}.

\begin{proposition}[The Existence of a Causal Universe Tensor]
\label{prop:universe-tensor}
Let $(E,\prec)$ be a locally finite partially ordered set of events, and let
$\Psi : E \to \mathcal{T}(V)$ be the measurable embedding.  For each event
$e\in E$, define its admissible factor by
\[
\mathbf{F}(e) \;:=\; \Psi\!\big(\hat{R}(e)\big).
\]
Fix a finite linear extension $e_1 \prec \cdots \prec e_n$ of $(E,\prec)$ and
set $\mathbf{U}_0 := \mathbf{I}$ (the multiplicative identity in
$\mathcal{T}(V)$).  Define the left recursion
\begin{equation}
\label{eq:left-update}
\mathbf{U}_{k+1}
:= \mathbf{E}_{k+1} \,\mathbf{U}_k
= \Psi\!\big(e_{k+1} \cap \hat{R}(e_k)\big)\,\mathbf{U}_k,
\qquad 0 \le k < n,
\end{equation}
Then:
\begin{enumerate}
\item \emph{(Naturality of restriction)}
Writing
\[
  R(e) \;:=\; \Psi\!\big(\hat{R}(e)\big),
\]
the recursion \eqref{eq:left-update} can be written purely in terms of the
restriction operator as
\[
  \mathbf{U}_{k+1}
  \;=\; R(e_{k+1})\,\mathbf{U}_k.
\]
In other words, the tensor update is exactly the image under $\Psi$ of the
same discrete restriction that acts on the event record.  On ${\rm im}\,\Psi$
this is expressed by the commuting relation
\[
  R \circ \Psi \;=\; \Psi \circ \hat{R},
\]
which is the naturality of restriction.

Moreover, this restriction is the informational inverse of merging along
uncorrelant events, up to the permutation of uncorrelant factors: uncorrelant
segments commute, so the order in which they are removed or reintroduced
does not affect the admissible tensor.  Thus the relation
$R\circ\Psi=\Psi\circ\hat R$ holds modulo the natural reordering of
uncorrelant components.


\item \emph{(Causal uniqueness)} The recursion \eqref{eq:left-update} is
uniquely determined by the chosen linear extension.  Any two linear
extensions differ only by permutations of informationally independent
events (partition elements of $E$), so once the order is fixed the product
is mechanically well-defined.

\item \emph{(Independence under commuting factors)} If a subset
$S\subset\{1,\dots,n\}$ indexes events whose admissible factors pairwise
commute, $\mathbf{F}(e_i)\mathbf{F}(e_j)=\mathbf{F}(e_j)\mathbf{F}(e_i)$ for
$i,j\in S$, then any permutation of $\{\mathbf{F}(e_i)\}_{i\in S}$ leaves
$\mathbf{U}_n$ invariant under all cyclic scalar functionals (e.g., traces
of contractions).

\item \emph{(Fully commutative case)} If all admissible factors commute, then
\[
\mathbf{U}_n \;=\; \prod_{k=1}^{n} \mathbf{F}(e_k)
\]
is independent of the linear extension; the product reduces to the
order-insensitive accumulation of factors.
\end{enumerate}
\end{proposition}

Categorically, the structure underlying this result is the
naturality of a monoidal functor in the sense of
Mac~Lane~\cite{maclane1971}, with further development in
Kelly~\cite{kelly1982} and Leinster~\cite{leinster2014}.  The proof sketch
below follows this diagrammatic perspective; the fully explicit ZFC
realization appears in Appendix~\ref{app:proofs}.

\begin{proofsketch}{universe-tensor}
Let $\mathcal{E}$ be the refinement category of admissible event records,
with objects the event sequences and morphisms the refinement maps
$\widehat{R} : \mathbf{i} \to \widehat{R}(\mathbf{i})$.
Let $T(V)$ be the tensor algebra regarded as a \emph{symmetric monoidal
category} under the tensor product.

The embedding $\Phi : E \to T(V)$ extends uniquely to a monoidal functor
\[
\Phi^{(\bullet)} : \mathcal{E} \longrightarrow T(V)^{(\bullet)},
\qquad
\mathbf{i} = (i_1,\dots,i_n) \longmapsto
\bigl(\Phi(e_{i_1}),\dots,\Phi(e_{i_n})\bigr),
\]
sending refinement maps to componentwise restriction on the image.

A refinement $\widehat{R} : \mathbf{i} \to \mathbf{j}$ in $\mathcal{E}$ is a
morphism expressing that $\mathbf{j}$ is the universal solution to a finite
cone of compatibility conditions.  Under the monoidal functor
$\Phi^{(\bullet)}$, this induces a canonical morphism
\[
  \Phi^{(\bullet)}(\widehat{R}) :
  \Phi^{(\bullet)}(\mathbf{i})
  \longrightarrow
  \Phi^{(\bullet)}(\mathbf{j}).
\]
By functoriality of $\Phi^{(\bullet)}$, the diagram
\[
\begin{tikzcd}
  \mathbf{i} \ar[r, "\widehat{R}"] \ar[d, "\Phi^{(\bullet)}"'] &
  \mathbf{j} \ar[d, "\Phi^{(\bullet)}"] \\
  \Phi^{(\bullet)}(\mathbf{i})
    \ar[r, "\Phi^{(\bullet)}(\widehat{R})"'] &
  \Phi^{(\bullet)}(\mathbf{j})
\end{tikzcd}
\]
commutes.  This is the naturality condition expressing that refinement and
embedding commute.


To obtain the Causal Universe Tensor, form the \emph{monoidal accumulation}
of the embedded sequence:
\[
U(\mathbf{i})
   := \Phi(e_{i_1}) \otimes \cdots \otimes \Phi(e_{i_n}).
\]
Since $T(V)$ is symmetric monoidal, any two linear extensions of a finite
event poset differ by braidings of incomparable events, and such braidings
commute with the tensor structure.  Hence $U(\mathbf{i})$ is well defined up
to the canonical symmetry of the monoidal category.

Thus the Causal Universe Tensor is the monoidal image of a refinement diagram under a
functor preserving both the tensor product and the naturality of
refinement. 
\end{proofsketch}

The existence of the Causal Universe Tensor gives rise to the appearance of
stability in long sequences of refinement.  Because each admissible update is
not free to evolve arbitrarily, but must remain compatible with the unique
globally coherent extension of the record, deviations cannot accumulate
without bound.  Local inconsistencies are absorbed through restriction and
embedding, producing the observable effect of bounded variation in the
measurement ledger.  This structural stability is not enforced by physical
feedback or control, but by the logical necessity of coherent refinement
itself.  This gives rise to the following informational phenomenon.

\begin{phenomenon}[The Statistical Process Effect~\cite{shewhart1931}]
\label{ph:spc}
A sequence of measurements refined under admissible updates exhibits
structural stability.  Local deviations are smoothed by the unique coherent
extension enforced by restriction and embedding.  The resulting record
remains bounded, not by physical forces, but by the logical requirement of
global consistency.  This informational stability is the phenomenon known in
classical practice as statistical process control.
\end{phenomenon}




With the ordinal structure of events established, we now formalize how 
these measurements combine algebraically within a finite vector space.


\subsection{Formal Structure of Event and Universe Tensors}
\label{se:formaluniverse}

We now specify the algebraic structure of the quantities introduced above.
Let $\V$ denote a finite--dimensional real vector space representing
the independent channels of measurable quantities (e.g.\ energy, momentum,
charge).  Define the tensor algebra~\cite{halmos1958,lang2002}
\begin{equation}
\label{eq:tensoralg}
\Talg = \bigoplus_{r=0}^\infty \V^{\otimes r},
\end{equation}
whose elements are finite sums of $r$--fold tensor products over $\mathbb{R}$.
Each \emph{event tensor} $E_k$ is a member of $\Talg$
encoding the distinguishable contribution of the $k$--th event to the global
state.  We write
\begin{equation}
\label{eq:eventalgebra}
\E_k \in \Talg, \qquad
\U_n = \prod_{k=1}^{n} \E_k \in \Talg).
\end{equation}
Addition is understood componentwise in the direct sum and preserves the
ordering of indices guaranteed by the Axiom of~Order~\cite{bombelli1987,halmos1958}.  In this setting the
``universe tensor'' $\U_n$ is the cumulative history of all event tensors up to
ordinal~$n$.

\begin{definition}[Tensor Algebra~\cite{golub2013}]\label{def:tensoralgebra}
The tensor algebra on a vector space $\V$ is
\[
\Talg=\bigoplus_{r=0}^{\infty}\V^{\otimes r}
\]
with componentwise addition and associative tensor product
\end{definition}


\begin{remark}
\label{rem:posetfrontier}
Each logical event $e_k$ in the partially ordered set $(E,\prec)$
induces a tensor $\E_k = \Psi(e_k)$ in $\Talg$.
The mapping $\Psi$ translates causal structure into algebraic contribution,
ensuring that causal precedence corresponds to index ordering in $\U_n$.
\end{remark}

Because $\Talg$ is a free associative algebra, all
operations on $\U_n$ are well defined using the standard linear maps,
contractions, and bilinear forms of~$\V$.  The subsequent analysis
of variation and measurement therefore proceeds entirely within conventional
linear--operator theory.

From the definition of the Universe Tensor
\begin{equation}
U_n = \prod_{k=1}^{n} E_k,
\end{equation}
we may regard an \emph{uncorrelant} as any subset of events whose local order can be permuted without altering the global scalar invariants of \(U_n\). 
Formally, a subset \(S \subseteq \{E_1, \ldots, E_n\}\) is uncorrelant if, for every permutation \(\pi\) of \(S\),
\begin{equation}
\prod_{E_i \in S} E_i = \prod_{E_i \in S} E_{\pi(i)}.
\end{equation}
In this case, all contractions or scalar traces derived from \(U_n\) remain unchanged by reordering the elements of \(S\), even though the operator sequence itself may differ.

\begin{definition}[Commutator and Commutator Ideal~\cite{dummit2004}]
Let $\mathcal{A}$ be an algebra over a field $\mathbb{F}$ with bilinear
multiplication $(x,y)\mapsto xy$.  For $x,y\in\mathcal{A}$, the
\emph{commutator} of $x$ and $y$ is the element
\[
[x,y] \;:=\; xy - yx \;\in\; \mathcal{A}.
\]
The set of all finite $\mathbb{F}$-linear combinations of commutators,
\[
[\mathcal{A},\mathcal{A}]
\;:=\;
\left\{\,\sum_{i=1}^{m}\alpha_i [x_i,y_i]
:\alpha_i\in\mathbb{F},\;x_i,y_i\in\mathcal{A}\,\right\},
\]
is called the \emph{commutator ideal}.  It is the smallest two-sided ideal
of $\mathcal{A}$ that contains every element $xy-yx$; equivalently, it is
the smallest linear subspace of $\mathcal{A}$ closed under left and right
multiplication by arbitrary elements of $\mathcal{A}$.
\end{definition}



\begin{remark}[Algebraic Characterization of Informational Independence]
\label{rem:uncorrelant-algebraic}
Let $\Psi : E \to \mathcal{T}(V)$ be the event embedding and
$\mathbf{E}_e := \Psi(e)$.  If $S \subseteq E$ lies in distinct elements of
the partition of $E$ (Definition~\ref{def:partition}), then the admissible
increments $\{\mathbf{E}_e\}_{e \in S}$ pairwise commute.  Consequently,
any reordering of these factors within a linear extension of $(E,\prec)$
produces the same value of $\mathbf{U}_n$ under all cyclic scalar
functionals (e.g., traces of contractions).  In this algebraic sense,
informational independence corresponds exactly to order-insensitive
contribution to the invariants derived from $\mathbf{U}$.
\end{remark}

\begin{phenomenon}[Non-commutative Event Pair~\cite{hawking1973}]
\NB{Non-commutative event tensors often signal a \emph{dependency}:
one update must precede the other for the restricted outcome set to
remain consistent.  Reversing such events changes the operator state,
even though measurable scalar invariants remain the same.}

Let $V=\mathbb{R}^2$ and let event tensors act as $2\times 2$ matrices
under the usual (non-commutative) multiplication.  Define
\[
E_A=\begin{pmatrix}1 & 1\\[4pt] 0 & 1\end{pmatrix},
\qquad
E_B=\begin{pmatrix}1 & 0\\[4pt] 1 & 1\end{pmatrix}.
\]
A direct computation gives
\[
E_AE_B=\begin{pmatrix}2 & 1\\[4pt] 1 & 1\end{pmatrix}
\;\neq\;
\begin{pmatrix}1 & 1\\[4pt] 1 & 2\end{pmatrix}=E_BE_A,
\quad\text{so } [E_A,E_B]\neq 0.
\]

Thus, applying the updates in different orders leads to different operator
states.  However, cyclic scalar invariants agree:
\[
\mathrm{tr}(E_AE_B)=\mathrm{tr}(E_BE_A)=3,
\qquad
\det(E_AE_B)=\det(E_A)\det(E_B)=1.
\]
In this sense, noncommutativity affects the internal operator record but
not the measurable quantities obtained by cyclic scalar functionals.
\end{phenomenon}


\begin{phenomenon}[Independent Event Chains~\cite{langevin1911}]
\NB{This is analogous to the inertial segment of the twin paradox.  During
coasting, neither twin exchanges signals with the other, so no event on one
worldline refines or restricts events on the other.  The two chains are
informationally independent until a causal interaction occurs.}

Consider two finite event chains
\[
A_1 \prec A_2,
\qquad
B_1 \prec B_2,
\]
with no causal relation between any $A_i$ and any $B_j$.  Let their event
tensors act on $V=\mathbb{R}^2$ as
\[
E_{A1}=\begin{pmatrix}1&0\\0&0\end{pmatrix},
\quad
E_{A2}=\begin{pmatrix}0&1\\0&0\end{pmatrix},
\qquad
E_{B1}=\begin{pmatrix}0&0\\1&0\end{pmatrix},
\quad
E_{B2}=\begin{pmatrix}0&0\\0&1\end{pmatrix}.
\]

Because the $A$-events refine only the $A$-chain and the $B$-events refine
only the $B$-chain, their admissible factors commute:
\[
E_{A2}E_{B2} = E_{B2}E_{A2}.
\]
Thus, any linear extension of the partial order may place the $A$- and $B$-
events in either interleaving without changing cyclic scalar invariants.  For
example, applying the four events in the order
\[
A_1,\, A_2,\, B_1,\, B_2
\quad\text{or}\quad
A_1,\, B_1,\, A_2,\, B_2
\]
gives operator states that differ, but
\[
\mathrm{tr}(E_{A2}E_{B2}) = \mathrm{tr}(E_{B2}E_{A2}) = 1,
\qquad
\det(E_{A2}E_{B2}) = \det(E_{B2}E_{A2}) = 0.
\]

This illustrates the algebraic meaning of independence: when two event chains
are partitioned into disjoint informational domains, their admissible
increments commute.  Order affects the internal operator record but leaves
measurable cyclic scalars unchanged, exactly as in the coasting phase of the
twin paradox.
\end{phenomenon}


\begin{coda}{Achilles and the Tortoise}
\NB{For a rich treatment of this paradox, see Hofstadter~\cite{hofstadter1979}.}
Zeno’s paradox of Achilles and the tortoise~\cite{plato1996} is one of the oldest arguments
against the possibility of motion. Achilles, swift of foot, gives a tortoise
a small head start. Because the tortoise begins ahead, Achilles must first
reach the tortoise’s initial position. By that time, the tortoise has advanced
a little farther; Achilles must then reach that new position, and by the time
he arrives, the tortoise has advanced again, and so on without end. Zeno’s
conclusion is that Achilles can never overtake the tortoise, for he must
complete an infinite sequence of tasks to do so.

Formally, one can express the argument in familiar modern notation. Suppose
the tortoise begins one unit ahead. Achilles covers half the remaining
distance on his first stride, then half of what remains on the next stride,
then half again, producing the well-known geometric series
\[
1 = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + \cdots .
\]
More generally, one may express the same identity as
\[
1 = \sum_{n=1}^{\infty} \frac{1}{2^{\,n}}.
\]
Zeno’s reasoning is now captured in a single line: if Achilles must perform
an infinite number of sub-journeys to reach the tortoise, and if completing
infinitely many tasks requires infinite time, then Achilles never arrives.

The mathematics appears to sharpen the paradox. The right-hand side contains
infinitely many terms, and yet their sum is finite. An infinite decomposition
and a finite limit uneasily coexist. From a purely symbolic viewpoint, Zeno
is correct: the path to the finish line can be written as a countable infinity
of smaller and smaller segments. Nothing in the algebra forbids infinitely
many subdivisions of the interval.

The difficulty lies not in the mathematics, but in the hidden assumption that
every subdivision corresponds to a physically meaningful event. Zeno imagines
that the runner physically performs each of these infinitesimal subpaths, as
though each term in the series corresponds to an actual step. In reality, the
decomposition exists only on paper. It is an artifact of representation, not
an element of the physical world.

In the information gauge, motion is not defined by a continuous geometric
parameter, but by the accumulation of admissible distinctions---measurable,
irreversible updates of state. A notebook of observations does not record
symbolic halvings of distance; it records physical events that are detectable
by an instrument. Proper time is not the integral of infinitesimal steps, but
the count of such admissible distinctions.

Viewed in this light, the identity
\[
1 = \sum_{n=1}^{\infty} \frac{1}{2^{\,n}}
\]
does not imply that Achilles performs infinitely many physical actions. It
states only that a continuous model permits infinitely many subdivisions,
should one choose to write them down. The infinite chain is a mathematical
convenience, not a physical ledger.

The resolution is found in precision. Achilles does not detect every possible
subinterval of his path; no instrument possesses infinite resolving power. His
step length, his stride cadence, and the sensor that records his position
determine a finite resolution. If the act of stepping advances him by
$10^{-2}$ units, there are at most $100$ admissible distinctions in a one-unit
race. Even if the instrumentation resolves position to $10^{-6}$ units, the
notebook contains no more than one million recorded distinctions. Once this
finite notebook is reconciled, Achilles is at the finish line. The race
consumes a finite count of admissible distinctions because the physical
process does not instantiate an actual infinity of subevents.

Zeno’s paradox relies on treating every symbolic refinement of the interval
as physically real. The information gauge rejects that assumption. A
measurement records only what can be stably distinguished. Achilles’s
``infinite'' steps are not steps at all; they are possible refinements of a
mathematical model. Precision is the gatekeeper. The paradox dissolves when
we recall that Achilles’s motion is measured, not imagined, and that every
measurement has finite resolution. Refinement does not create motion; it
reveals it.

\end{coda}

